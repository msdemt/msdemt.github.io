[{"content":"介绍 在 macos 上使用 vmware fusion 13 安装使用 ubuntu 18.04 虚拟机\n问题 fusion 13 安装 ubuntu 18.04 后，ubuntu 打开后黑屏，无法正常显示\n解决：虚拟机 - 设置 - 显示器 - 关闭 加速3D图形\nubuntu 虚拟机安装 vmware tools\n安装vmware tools\n1 sudo apt -y install open-vm-tools 如果要实现文件共享，需要安装 open-vm-tools-dkms\n1 sudo apt -y install open-vm-tools-dkms 如果使用桌面环境，实现粘贴板共享和托放文件，需要安装 open-vm-tools-desktop\n1 sudo apt -y install open-vm-tools-desktop 参考：\nhttps://blog.csdn.net/hhdhz/article/details/87922794\n","date":"2023-09-18T00:00:00Z","permalink":"https://msdemt.github.io/p/macos-fusion-ubuntu-18.04/","title":"fusion 安装 ubuntu 18.04"},{"content":"介绍 因为目前企业微信没有 linux 版本，希望在 ubuntu 18.04 上使用企业微信，所以探索使用 wine 来在 ubuntu 上运行企业微信。\nubuntu 18.04 安装 wine 启用 32 位架构\n1 sudo dpkg --add-architecture i386 配置 wine 仓库\n1 2 sudo wget -nc -O /usr/share/keyrings/winehq-archive.key https://dl.winehq.org/wine-builds/winehq.key sudo sh -c \u0026#34;echo \u0026#39;deb [arch=amd64,i386 signed-by=/usr/share/keyrings/winehq-archive.key] https://mirrors.tuna.tsinghua.edu.cn/wine-builds/ubuntu/ bionic main\u0026#39; \u0026gt; /etc/apt/sources.list.d/winehq.list\u0026#34; 修改 /usr/share/keyrings/winehq-archive.key 权限\n1 sudo chmod 644 /usr/share/keyrings/winehq-archive.key 更新镜像源\n1 sudo apt update 安装 wine 最新稳定版\n1 sudo apt -y install --install-recommends winehq-stable 查看 wine 版本\n1 wine --version 使用32位模式启动 winecfg\n1 WINEARCH=win32 WINEPREFIX=~/.wine winecfg 因为 wine 缺少语言包，所以中文显示会乱码，解决：将 windows 系统 C:\\Windows\\Fonts 中的语言文件拷贝到 ~/.wine/drive_c/windows/Fonts/ 目录\n1 2 sudo unzip Fonts.zip sudo cp ./Fonts/* ~/.wine/drive_c/windows/Fonts/ winecfg 启动是提示安装 wine-mono 和 wine-gecko，如果在线安装失败，可以使用离线安装\n下载 wine-mono 和 wine-gecko\n1 2 wget http://mirrors.ustc.edu.cn/wine/wine/wine-mono/7.4.0/wine-mono-7.4.0-x86.msi wget http://mirrors.ustc.edu.cn/wine/wine/wine-gecko/2.47.4/wine-gecko-2.47.4-x86.msi 安装 wine-mono 和 wine-gecko\n1 2 wine start wine-mono-7.4.0-x86.msi wine start wine-gecko-2.47.4-x86.msi 安装 winetricks\n1 2 3 wget https://raw.githubusercontent.com/Winetricks/winetricks/master/src/winetricks sudo chmod +x winetricks sudo mv winetricks /usr/local/bin 使用32位模式启动 winetricks\n1 WINEARCH=win32 WINEPREFIX=~/.wine winetricks 使用 winetricks 安装组件时，如果安装失败，经常是因为下载的文件不完整（SHA256 mismatch!），所以需要我们单独下载文件，拷贝到相应的位置\n使用 winetricks 安装 windows 组件\n安装 riched20 安装 riched20 时，需要提前安装 cabextract\n1 sudo apt-get -y install cabextract 使用 winetrick 下载 W2KSP4_EN.EXE 文件不完整\n手动下载，地址：http://x3270.bgp.nu/download/specials/W2KSP4_EN.EXE 将 W2KSP4_EN.EXE 拷贝到 ~/.cache/winetricks/win2ksp4/ 目录 使用 winetrick 下载 InstMsiW.exe 文件不完整\n手动下载，地址：https://web.archive.org/web/20160710055851if_/http://download.microsoft.com/download/WindowsInstaller/Install/2.0/NT45/EN-US/InstMsiW.exe 将 InstMsiW.exe 拷贝到 ~/.cache/winetricks/msls31 目录 安装 riched20\n安装 riched30 使用 winetrick 下载 InstMsiA.exe 文件不完整 手动下载，地址：https://web.archive.org/web/20060720160141/https://download.microsoft.com/download/WindowsInstaller/Install/2.0/W9XMe/EN-US/InstMsiA.exe 将 InstMsiA.exe 拷贝到 ~/.cache/winetricks/riched30 安装 riched30 安装 richtx32 提前安装 7zip ubuntu 安装 7zip: sudo apt-get install p7zip-full 安装 richtx32 安装 windowscodecs 若使用 winetrick 下载 wic_x86_enu.exe 文件不完整 手动下载，地址：https://web.archive.org/web/20200810071051if_/https://download.microsoft.com/download/f/f/1/ff178bb1-da91-48ed-89e5-478a99387d4f/wic_x86_enu.exe 将 wic_x86_enu.exe 拷贝到 ~/.cache/winetricks/windowscodecs 安装 windowscodecs 安装企业微信 1 WINEARCH=win32 WINEPREFIX=~/.wine wine WeCom_3.1.6.3605.exe 经过测试\n企业微信-3.1.6 可以正常使用，这个版本也是 ukylin-wxwork_1.0_amd64.deb 中对应的版本 企业微信-3.1.10 可以正常使用，但是无法使用 WXDriver.exe 企业微信-3.1.12、企业微信-3.1.15、 企业微信-3.1.16，提示wemail不可用，应该是内置的邮箱无法使用。无法正常使用 企业微信-3.1.18.6007 虽然可以登录，但是经常崩溃 企业微信安装成功后，在收藏夹中存在两个企业微信图标，位置：\n1 2 ~/.local/share/applications/wine/Programs/企业微信/企业微信.desktop ~/.local/share/applications/wine/企业微信.desktop 删掉一个即可\n1 rm -rf ~/.local/share/applications/wine/企业微信.desktop 安装 topicons 使用 wine 安装企业微信后，企业微信图标会以悬浮窗的形式显示，可以安装Gnome Shell插件 TopIcons Plus 解决问题，将 wine 中软件的图标整合到 ubuntu gnome 托盘。\n安装方式一（推荐）：\n安装 gnome shell 扩展\n1 sudo apt install gnome-shell-extension-top-icons-plus 安装方式二：\n编译安装\n根据 ubuntu 使用的 GONME 版本，下载对应的 topicons ubuntu 18.04.6 使用的 GNOME 版本为 3.28.2 topicons 下载地址：https://extensions.gnome.org/extension/1031/topicons/ Download 3.28 22 安装 make 编译工具 1 sudo apt-get -y install make 编译安装 1 sudo make install 安装后重启gnome alt+f2 输入 r 重启 gnome\n问题：无法显示企业微信图标\n问题： sudo echo 权限不够\n希望将文本写入到某个文件中（若这个文件不存在，自动创建该文件）\n使用 sudo echo \u0026quot;\u0026quot; \u0026gt; file 时提示权限不够\n1 2 $ sudo echo \u0026#34;deb [arch=amd64,i386 signed-by=/usr/share/keyrings/winehq-archive.key] https://mirrors.tuna.tsinghua.edu.cn/wine-builds/ubuntu/ bionic main\u0026#34; \u0026gt; /etc/apt/sources.list.d/winehq.list bash: /etc/apt/sources.list.d/winehq.list: 权限不够 解决：\n使用 sh -c \u0026quot;sudo echo '' \u0026gt; file\u0026quot;，如 1 $ sudo sh -c \u0026#34;echo \u0026#39;deb [arch=amd64,i386 signed-by=/usr/share/keyrings/winehq-archive.key] https://mirrors.tuna.tsinghua.edu.cn/wine-builds/ubuntu/ bionic main\u0026#39; \u0026gt; /etc/apt/sources.list.d/winehq.list\u0026#34; 使用 echo \u0026quot;\u0026quot; | sudo tee file，如： 1 $ echo \u0026#34;deb [arch=amd64,i386 signed-by=/usr/share/keyrings/winehq-archive.key] https://mirrors.tuna.tsinghua.edu.cn/wine-builds/ubuntu/ bionic main\u0026#34; | sudo tee /etc/apt/sources.list.d/winehq.list 使用 echo \u0026quot;\u0026quot; | sudo tee -a file，进行追加文本，等同于 \u0026gt;\u0026gt; 使用 wine 安装微信时提示 ntlm_check_version ntlm_auth was not found\nwine 安装微信\n1 WINEARCH=win32 wine ./WeChatSetup.exe 错误信息：\n1 03f0:err:winediag:ntlm_check_version ntlm_auth was not found. Make sure that ntlm_auth \u0026gt;= 3.0.25 is in your path. Usually, you can find it in the winbind package of your distribution. 解决：\n1 sudo apt-get install -y winbind Cannot find cabextract. Please install it (e.g. 'sudo apt-get install cabextract' or 'sudo yum install cabextract').\n解决： 安装 cabextract\n1 apt-get install cabextract Note: command cabextract -q --directory=/home/hekai/.wine/dosdevices/c:/windows/temp /home/hekai/.cache/winetricks/msls31/InstMsiW.exe returned status 1. Aborting.\n原因：\nwinetricks 自动下载的 InstMsiW.exe 文件不完整\n解决：\n手动下载 InstMsiW.exe，然后拷贝到 ~/.cache/winetricks/msls31\nNote: command cabextract -q --directory=/home/ctyun/.wine/dosdevices/c:/windows/temp /home/ctyun/.cache/winetricks/riched30/InstMsiA.exe returned status 1. Aborting.\n原因：\nwinetricks 自动下载的 InstMsiA.exe 文件不完整\n解决：\n手动下载 InstMsiA.exe，然后拷贝到 ~/.cache/winetricks/riched30\n使用 wine 安装微信失败\n1 2 3 4 $ WINEARCH=win32 wine ./WeChatSetup.exe 0118:fixme:seh:WerRegisterMemoryBlock (530AA498 6144) stub 0118:fixme:seh:WerRegisterMemoryBlock (530A4000 4) stub 0118:err:ole:apartment_getclassobject DllGetClassObject returned error 0x80040154 for dll L\u0026#34;C:\\\\windows\\\\system32\\\\windowscodecs.dll\u0026#34; 解决： 使用 winetricks 安装 windowscodecs\n更新apt源报错\n1 2 3 4 5 $ sudo apt update 获取:1 http://security.debian.org/debian-security buster/updates InRelease [34.8 kB] 获取:2 https://mirrors.tuna.tsinghua.edu.cn/wine-builds/ubuntu bionic InRelease [6,263 B] 错误:2 https://mirrors.tuna.tsinghua.edu.cn/wine-builds/ubuntu bionic InRelease 由于没有公钥，无法验证下列签名： NO_PUBKEY 76F1A20FF987672F 参考： https://blog.csdn.net/weixin_44172434/article/details/89160720\n1 $ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 76F1A20FF987672F 执行后，还是报错\n发现 /usr/share/keyrings/winehq-archive.key 文件权限是 660，同目录下其他文件权限是644，将 winehq-archive.key 文件权限修改为 644 后就可以执行 sudo apt update 了。\n参考：\nhttps://wiki.winehq.org/Ubuntu\nhttps://mirrors-i.tuna.tsinghua.edu.cn/help/wine-builds/\nhttps://cloud.tencent.com/developer/article/1626683\nhttps://mirrors-i.tuna.tsinghua.edu.cn/help/wine-builds/\nhttps://blog.csdn.net/amnesiagreen/article/details/116791833\nhttps://blog.csdn.net/cxrshiz7890/article/details/106185468\nhttps://blog.csdn.net/qq_45945548/article/details/124123820\nhttps://blog.csdn.net/cxrshiz7890/article/details/106042837\nhttps://blog.csdn.net/Hsin96/article/details/119147144\n","date":"2023-09-18T00:00:00Z","permalink":"https://msdemt.github.io/p/ubuntu-wine/","title":"ubuntu 安装 wine"},{"content":"介绍 docker 中安装 sshd，这样就可以 ssh 进入docker内远程开发了\n安装 安装 openssh-server，会同时安装 openssh\n1 yum -y install openssh-server 修改root密码\n1 echo \u0026#39;root:root\u0026#39;|chpasswd 配置host密钥\n1 2 3 ssh-keygen -q -t rsa -b 2048 -f /etc/ssh/ssh_host_rsa_key -N \u0026#39;\u0026#39; ssh-keygen -q -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key -N \u0026#39;\u0026#39; ssh-keygen -q -t dsa -f /etc/ssh/ssh_host_ed25519_key -N \u0026#39;\u0026#39; 前台启动sshd\n1 /usr/sbin/sshd 问题 执行sshd，失败\n1 2 [root@linux0 /]# sshd sshd re-exec requires execution with an absolute path 解决：需要使用sshd全路径\n1 [root@linux0 /]# /usr/sbin/sshd Could not load host key\n1 2 3 4 5 [root@linux0 /]# /usr/sbin/sshd Could not load host key: /etc/ssh/ssh_host_rsa_key Could not load host key: /etc/ssh/ssh_host_ecdsa_key Could not load host key: /etc/ssh/ssh_host_ed25519_key sshd: no hostkeys available -- exiting. 解决：\n1 2 3 ssh-keygen -q -t rsa -b 2048 -f /etc/ssh/ssh_host_rsa_key -N \u0026#39;\u0026#39; ssh-keygen -q -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key -N \u0026#39;\u0026#39; ssh-keygen -q -t dsa -f /etc/ssh/ssh_host_ed25519_key -N \u0026#39;\u0026#39; Failed to get D-Bus connection: Operation not permitted\n在容器里使用 systemd 来管理启动服务，虽然centos 7版本中的基础镜像存在 systemd，但是使用 systemctl 启动服务时就会报如下的错误：\n1 Failed to get D-Bus connection: Operation not permitted 这是因为 Docker 的设计理念是在容器里面不运行后台服务，容器本身就是宿主机上的一个独立的主进程，也可以间接的理解为就是容器李运行服务的应用进程。一个容器的生命周期是围绕这个主进程存在的，所以正确的使用容器的方法是将里面的服务运行在前台。\n再说 systemd，这个套件已经成为主流Linux发行版默认的服务管理，取代了传统的 SystemV 风格服务管理。systemd维护系统服务程序，它需要特权才能够去访问Linux内核。而容器并不是一个完整的操作系统，只有一个文件系统，而默认启动只是普通用户这样的权限访问Linux内核，也就是没有特权，所以自然就用不了！\n因此，请遵守容器设计原则，一个容器里运行一个前台服务！\n说了这么多，如何解决上面的报错呢？\n1. 以特权的模式运行容器 创建容器： ```bash docker run -d -name centos7 --privileged=true centos:7 /usr/sbin/init ``` 进入容器： ```bash docker exec -it centos7 /bin/bash #表示登录进容器后，自己又新开一个shell（/bin/bash），所以使用子进程的当时登录容器退出后，不会影响其它shell ``` 这样可以使用systemctl启动服务了。 /etc/ssh/sshd_config中的参数\nusePam参数：https://unix.stackexchange.com/questions/673153/sshd-what-are-the-practical-effects-of-setting-usepam-no\nPermitRootLogin 默认为yes，作用：https://blog.csdn.net/huigher/article/details/52972013\nPubkeyAuthentication 默认为yes\n参考:\nhttps://blog.csdn.net/cxs_123/article/details/116276838\nhttps://unix.stackexchange.com/questions/109380/why-does-sshd-requires-an-absolute-path\n","date":"2023-09-08T00:00:00Z","permalink":"https://msdemt.github.io/p/docker-install-sshd/","title":"docker安装sshd"},{"content":"匿名访问openldap openldap默认都是可以进行匿名访问的，这个我们可以通过ldapadmin或者phpldapadmin等工具来进行查看。在这我们使用ldapadmin工具进行查看，如下：\n通过上图，我们可以很明显的看出，openldap在匿名情况下是可以被访问的。而且openldap的相关信息，除了用户的密码信息之外，其他openldap的信息完全被呈现出来。\n禁止openldap匿名访问 从安全的角度考虑，这种情况是不被允许的，所以我们要取消openldap的匿名访问功能。\n要取消openldap的匿名访问功能，操作方法也比较简单。我们只需要把以下openldap信息导入openldap中即可，而且是无需重启openldap服务即时生效的。\n编辑disable_anon.ldif文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 dn: cn=config changetype: modify add: olcDisallows olcDisallows: bind_anon dn: cn=config changetype: modify add: olcRequires olcRequires: authc dn: olcDatabase={-1}frontend,cn=config changetype: modify add: olcRequires olcRequires: authc 使用ldapadd命令导入到openldap\n1 ldapadd -Y EXTERNAL -H ldapi:/// -f disable_anon.ldif 可以通过openldap服务器上的文件查看做了哪些发动：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 [admin@localhost openldap]$ sudo cat /etc/openldap/slapd.d/cn\\=config.ldif [sudo] password for admin: # AUTO-GENERATED FILE - DO NOT EDIT!! Use ldapmodify. # CRC32 2848f698 dn: cn=config objectClass: olcGlobal cn: config olcArgsFile: /var/run/openldap/slapd.args olcPidFile: /var/run/openldap/slapd.pid olcTLSCACertificatePath: /etc/openldap/certs olcTLSCertificateFile: \u0026#34;OpenLDAP Server\u0026#34; olcTLSCertificateKeyFile: /etc/openldap/certs/password structuralObjectClass: olcGlobal entryUUID: b4bd6c2e-b215-103a-90af-1f89b5f560bc creatorsName: cn=config createTimestamp: 20201103114442Z olcDisallows: bind_anon olcRequires: authc entryCSN: 20201103141650.871705Z#000000#000#000000 modifiersName: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth modifyTimestamp: 20201103141650Z [admin@localhost openldap]$ sudo cat /etc/openldap/slapd.d/cn\\=config/olcDatabase\\=\\{-1\\}frontend.ldif # AUTO-GENERATED FILE - DO NOT EDIT!! Use ldapmodify. # CRC32 7eeb2ffa dn: olcDatabase={-1}frontend objectClass: olcDatabaseConfig objectClass: olcFrontendConfig olcDatabase: {-1}frontend structuralObjectClass: olcDatabaseConfig entryUUID: b4bdf64e-b215-103a-90b2-1f89b5f560bc creatorsName: cn=config createTimestamp: 20201103114442Z olcRequires: authc entryCSN: 20201103141650.873590Z#000000#000#000000 modifiersName: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth modifyTimestamp: 20201103141650Z 验证openldap匿名访问 通过上面配置后，现在我们再来通过ldapadmin工具，验证openldap是否还可以被匿名访问。\n问题 将 ldap 配置为禁止匿名访问后，ldap client (nslcd) 就无法连接到 ldap server了。\n解决：\nldap 添加一个只读用户，配置 ldap client (nslcd) 服务的配置文件 /etc/nslcd.conf ，使用只读用户访问 ldap server\nldap 添加只读用户见：ldap添加只读用户\n如：ldap 存在只读用户，用户名：readonly，用户密码 passwd，将用户名添加到 nslcd.conf 中 binddn 中，将用户密码添加到 bindpw 中，如下\n1 2 3 4 5 6 7 8 9 10 # The distinguished name to bind to the server with. # Optional: default is to bind anonymously. #binddn cn=proxyuser,dc=example,dc=com binddn cn=readonly,dc=example,dc=org # The credentials to bind with. # Optional: default is no credentials. # Note that if you set a bindpw you should check the permissions of this file. #bindpw secret bindpw passwd 修改完　nslcd.conf 文件后，需要重启　nslcd　服务\n1 systemctl restart nslcd 参考：\nhttps://chenzhonzhou.github.io/2020/11/03/openldap-jin-zhi-ni-ming-fang-wen/\nhttps://blog.csdn.net/baidu_38844729/article/details/107200232\nhttps://docs.nvidia.com/networking-ethernet-software/cumulus-linux-43/System-Configuration/Authentication-Authorization-and-Accounting/LDAP-Authentication-and-Authorization/\nhttps://linux.die.net/man/5/nslcd.conf\n","date":"2023-09-08T00:00:00Z","permalink":"https://msdemt.github.io/p/ldap-forbidden-anonymous/","title":"ldap禁止匿名用户访问"},{"content":"创建ldap只读帐号 生成只读文件 readOnly.ldif\n1 2 3 4 5 6 7 8 9 10 11 12 13 #密码 LDAP_READONLY_USER_PW=\u0026#39;passwd\u0026#39; #Base DN LDAP_BASE_DN=\u0026#39;dc=example,dc=org\u0026#39; cat \u0026lt;\u0026lt;EOF \u0026gt; ./readOnly.ldif dn: cn=readonly,${LDAP_BASE_DN} cn: readonly objectClass: simpleSecurityObject objectClass: organizationalRole description: LDAP read only user userPassword: ${LDAP_READONLY_USER_PW} EOF 将只读文件添加到 ldap\n1 ldapadd -x -D cn=Manager,dc=example,dc=org -w \u0026#39;passwd\u0026#39; -f ./readOnly.ldif 配置只读帐号权限 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 LDAP_BASE_DN=\u0026#39;dc=example,dc=org\u0026#39; cat \u0026lt;\u0026lt;EOF \u0026gt; readonly-user-acl.ldif dn: olcDatabase={2}hdb,cn=config changetype: modify delete: olcAccess - add: olcAccess olcAccess: {0}to attrs=userPassword,shadowLastChange by dn=\u0026#34;cn=Manager,dc=example,dc=org\u0026#34; write by anonymous auth by self write by dn=\u0026#34;cn=readonly,dc=example,dc=org\u0026#34; read by * none olcAccess: {1}to dn.base=\u0026#34;\u0026#34; by * read olcAccess: {2}to * by dn=\u0026#34;cn=Manager,dc=example,dc=org\u0026#34; write by * read EOF 1 ldapmodify -Y EXTERNAL -H ldapi:/// -f readonly-user-acl.ldif 参考：　https://www.cnblogs.com/husbandmen/p/13307381.html　","date":"2023-09-08T00:00:00Z","permalink":"https://msdemt.github.io/p/ldap-add-readonly-user/","title":"ldap添加只读用户"},{"content":"安装qt 参考：\nhttps://www.tal.org/tutorials/building-qt-515-lts-raspberry-pi-raspberry-pi-os\n下载 qt 源码包\n下载地址：https://download.qt.io/archive/qt/5.15/5.15.10/single/qt-everywhere-opensource-src-5.15.10.tar.xz\n安装qt编译依赖库\n1 sudo apt-get install -y build-essential libfontconfig1-dev libfreetype6-dev libx11-dev libxext-dev libxfixes-dev libxi-dev libxrender-dev libxcb1-dev libxcb-glx0-dev libxcb-keysyms1-dev libxcb-image0-dev libxcb-shm0-dev libcups2-dev zlib1g-dev 解压源码包并进入目录\n1 2 tar -xf qt-everywhere-src-5.15.10.tar.xz cd qt-everywhere-src-5.15.10/ 配置编译选项\n1 ./configure -opensource -confirm-license -nomake examples -nomake tests -prefix /opt/app/qt-5.15.10 -opensource: 表示使用开源许可证 -confirm-license: 表示自动确认许可证 -nomake examples -nomake tests: 表示不编译示例和测试程序 -prefix: 指定安装位置，默认安装到 /usr/local/Qt-5.15.10 下 编译源码\n因为源码编译耗时特别长，所以最好加上 -j 参数，并行编译，加快编译速度\n1 make -j8 安装qt\n1 sudo make install 配置环境变量\n需要将Qt添加到PATH中，以便在终端中使用Qt命令行工具。可以编辑.bashrc文件，在末尾添加以下内容：\n1 2 export QTDIR=/opt/app/qt-5.15.10 export PATH=QTDIR/bin:PATH 保存并退出文件后，执行以下命令使其生效：\n1 source ~/.bashrc 也可以添加全局环境变量配置，新增 /etc/profile.d/qt.sh，内容如下\n1 2 3 4 5 6 #!/bin/bash export QTDIR=/opt/app/qt-5.15.10 case \u0026#34;:$PATH:\u0026#34; in *\u0026#34;:$QTDIR/bin:\u0026#34;*) :;; # already there *) PATH=\u0026#34;$QTDIR/bin:$PATH\u0026#34;;; # or PATH=\u0026#34;$PATH:$new_entry\u0026#34; esac 安装 qt-creator 下载最新版的 qt-creator\n下载地址：https://download.qt.io/official_releases/qtcreator/11.0/11.0.2/\n1 2 chmod +x qt-creator-opensource-linux-x86_64-11.0.2.run ./qt-creator-opensource-linux-x86_64-11.0.2.run 问题 配置编译选项时出错：ERROR: The OpenGL functionality tests failed!\n1 ./configure -opensource -confirm-license -nomake examples -nomake tests 错误如下：\n1 2 3 ERROR: The OpenGL functionality tests failed! You might need to modify the include and library search paths by editing QMAKE_INCDIR_OPENGL[_ES2], QMAKE_LIBDIR_OPENGL[_ES2] and QMAKE_LIBS_OPENGL[_ES2] in the mkspec for your platform. 添加 -no-opengl，可以正常通过配置\n1 ./configure -opensource -confirm-license -nomake examples -nomake tests -no-opengl 猜测：系统没有安装opengl\n安装 opengl\n参考：\nhttps://crainyday.gitee.io/Ubuntu_004.html\nhttps://en.wikibooks.org/wiki/OpenGL_Programming/Installation/Linux\n问题：安装 libgl1-mesa-dev 失败，提示无法安装libx11-xcb-dev\n手动安装 libx11-xcb-dev\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 hekai@00bafcjc-dUrwEMo9N5:~/Downloads$ sudo apt install libx11-xcb-dev 正在读取软件包列表... 完成 正在分析软件包的依赖关系树 正在读取状态信息... 完成 有一些软件包无法被安装。如果您用的是 unstable 发行版，这也许是 因为系统无法达到您要求的状态造成的。该版本中可能会有一些您需要的软件 包尚未被创建或是它们已被从新到(Incoming)目录移出。 下列信息可能会对解决问题有所帮助： 下列软件包有未满足的依赖关系： libx11-xcb-dev : 依赖: libx11-xcb1 (= 2:1.6.4-3ubuntu0.4) 但是 2:1.6.4-3ubuntu0.5 正要被安装 E: 无法修正错误，因为您要求某些软件包保持现状，就是它们破坏了软件包间的依赖关系。 hekai@00bafcjc-dUrwEMo9N5:~/Downloads$ sudo apt list --installed | grep libx11-xcb1 WARNING: apt does not have a stable CLI interface. Use with caution in scripts. libx11-xcb1/now 2:1.6.4-3ubuntu0.5 amd64 [已安装，本地] 由上可知，本系统已经安装了 libx11-xcb1 2:1.6.4-3ubuntu0.5，但是从仓库中安装 libx11-xcb-dev 时，仓库中的 libx11-xcb-dev 依赖 libx11-xcb1 2:1.6.4-3ubuntu0.4\n查看仓库中 libx11-xcb-dev 的版本，可以看到仓库中的 libx11-xcb-dev 版本是 2:1.6.4-3ubuntu0.4 amd64\n1 2 3 4 5 6 hekai@00bafcjc-dUrwEMo9N5:~/Downloads$ sudo apt search libx11-xcb-dev 正在排序... 完成 全文搜索... 完成 libx11-xcb-dev/bionic-updates,bionic-security 2:1.6.4-3ubuntu0.4 amd64 Xlib/XCB interface library (development headers) hekai@00bafcjc-dUrwEMo9N5:~/Downloads$ 有两个方法\n卸载本机中的 libx11-xcb1 2:1.6.4-3ubuntu0.5 ，安装低版本的 libx11-xcb1 2:1.6.4-3ubuntu0.4，然后继续安装仓库中的 libx11-xcb-dev 找找有没有 2:1.6.4-3ubuntu0.5 版本的 libx11-xcb-dev 第一个方法风险有点大，因为看到很多软件都依赖了 libx11-xcb1\n幸好找到了 2:1.6.4-3ubuntu0.5 版本的 libx11-xcb-dev，所以使用第二个方法。\nlibx11-xcb-dev 2:1.6.4-3ubuntu0.5 下载地址：\nhttps://launchpad.net/ubuntu/bionic/amd64/libx11-xcb-dev/2:1.6.4-3ubuntu0.5\nlibx11-xcb-dev 2:1.6.4-3ubuntu0.5 本地下载\n安装 libx11-xcb-dev 2:1.6.4-3ubuntu0.5\n1 2 3 4 5 6 7 8 hekai@00bafcjc-dUrwEMo9N5:~/Downloads$ sudo dpkg -i libx11-xcb-dev_1.6.4-3ubuntu0.5_amd64.deb 正在选中未选择的软件包 libx11-xcb-dev:amd64。 (正在读取数据库 ... 系统当前共安装有 285619 个文件和目录。) 正准备解包 libx11-xcb-dev_1.6.4-3ubuntu0.5_amd64.deb ... 正在解包 libx11-xcb-dev:amd64 (2:1.6.4-3ubuntu0.5) ... 正在设置 libx11-xcb-dev:amd64 (2:1.6.4-3ubuntu0.5) ... 正在处理用于 man-db (2.8.3-2ubuntu0.1) 的触发器 ... hekai@00bafcjc-dUrwEMo9N5:~/Downloads$ 然后可以安装 opengl 了\n1 sudo apt-get install build-essential libgl1-mesa-dev configure配置时由于存在缓存导致失败\n缓存可能会导致执行 ./configure 时失败\n解决办法：删除 configure.cache ，然后再执行 ./configure\n启动 qtcreator ，没有响应\n查看日志 journalctl -f\n1 qtcreator: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.28\u0026#39; not found 安装 glibc_2.28\n参考：\nhttp://www.xbhp.cn/news/54783.html\n查看当前系统支持的 glibc : strings /lib/x86_64-linux-gnu/libc.so.6 | grep GLIBC_\n在 /etc/apt/source.list 文件新增源\n1 deb http://security.debian.org/debian-security buster/updates main 刷新软件包的缓存\n1 sudo apt update apt-get update之后若出现下面提示：\n1 由于没有公钥，无法验证下列签名： NO_PUBKEY 112695A0E562B32A NO_PUBKEY 54404762BBB6E853 执行如下命令\n1 2 3 4 5 6 7 sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A 54404762BBB6E853 `` 其中后面的112695A0E562B32A 54404762BBB6E853就是上面提到的NO_PUBKEY 112695A0E562B32A NO_PUBKEY 54404762BBB6E853中的公钥，替换成对应的即可。然后重新apt-get update。 查看软件包可更新列表 ```bash sudo apt list --upgradable 安装libc6\n1 sudo apt install libc6-dev /sudo apt install libc6 查看服务器当前glibc版本：\n1 strings /lib/x86_64-linux-gnu/libc.so.6 | grep GLIBC_ ","date":"2023-09-08T00:00:00Z","permalink":"https://msdemt.github.io/p/ubuntu-install-qt/","title":"ubuntu安装qt"},{"content":"ubuntu 的 GNOME 桌面可以将多个 Application 图标合并到一个图标文件夹中。\n系统图标 ubuntu 的图标位于以下位置\n对所有用户有效: /usr/share/applications 以及 /usr/local/share/applications 仅当前用户有效: ~/.local/share/applications 如果图标文件放到相应位置，但是还无法显示，请检查图标文件的文件权限是否为644\n图标文件以 .desktop 为后缀\n1 2 3 4 5 6 7 8 9 10 hekai@00bafcjc-dUrwEMo9N5:/usr/share/applications$ ll total 908 drwxr-xr-x 2 root root 12288 9月 3 10:53 ./ drwxr-xr-x 287 root root 12288 9月 2 10:15 ../ -rw-r--r-- 1 root root 291 4月 13 01:53 apport-gtk.desktop -rw-r--r-- 1 root root 125 5月 20 2016 apturl.desktop -rw-r--r-- 1 root root 484 4月 12 2019 bluetooth-sendto.desktop -rw-r--r-- 1 root root 510 3月 21 2018 cheese.desktop -rw-r--r-- 1 root root 214 8月 21 13:42 clash-for-windows.desktop -rwxrwxr-x 1 root root 469 8月 10 06:17 code.desktop* 当前文件夹 ubuntu 18.04 的 GNOME 桌面自带两个预定义文件夹 “Utilities” 和 “Sundry”, ubuntu 20.04 不带任何图标文件夹\n查看当前 App 文件夹:\n1 gsettings get org.gnome.desktop.app-folders folder-children 结果\n1 [\u0026#39;Utilities\u0026#39;, \u0026#39;Sundry\u0026#39;, \u0026#39;YaST\u0026#39;] 创建文件夹 命令格式: gsettings set org.gnome.desktop.app-folders folder-children \u0026quot;['folder', ...]\u0026quot;\n示例\n1 gsettings set org.gnome.desktop.app-folders folder-children \u0026#34;[\u0026#39;Utilities\u0026#39;, \u0026#39;Sundry\u0026#39;, \u0026#39;YaST\u0026#39;, \u0026#39;JetBrains\u0026#39;]\u0026#34; 除了新创建的 JetBrains， 之前已存在的文件夹也要加上, 否则视为删除\n设置展示的名称为 “JetBrains”, 格式: gsettings set org.gnome.desktop.app-folders.folder:/org/gnome/desktop/app-folders/folders/folder/ name \u0026quot;name\u0026quot;\n示例：\n1 gsettings set org.gnome.desktop.app-folders.folder:/org/gnome/desktop/app-folders/folders/JetBrains/ name \u0026#34;JetBrains\u0026#34; 因为文件夹内没有任何应用, 暂时该文件夹还不可见\n添加图标 命令格式: gsettings set org.gnome.desktop.app-folders.folder:/org/gnome/desktop/app-folders/folders/folder/ apps \u0026quot;['app.desktop', ...]\u0026quot;\n在 JetBrains 文件夹下放置 4 个应用图标，示例\n1 gsettings set org.gnome.desktop.app-folders.folder:/org/gnome/desktop/app-folders/folders/JetBrains/ apps \u0026#34;[\u0026#39;jetbrains-clion.desktop\u0026#39;, \u0026#39;jetbrains-goland.desktop\u0026#39;, \u0026#39;jetbrains-idea.desktop\u0026#39;, \u0026#39;jetbrains-pycharm.desktop\u0026#39;]\u0026#34; 参考：\nhttps://blog.csdn.net/jiang_huixin/article/details/107092622\n","date":"2023-09-08T00:00:00Z","permalink":"https://msdemt.github.io/p/ubuntu-app-folder/","title":"ubuntu添加图标文件夹"},{"content":"ubuntu 18.04 安装 wps 2019，安装后打开 wps，提示如下错误\n解决：\n将相关字体拷贝到 /usr/share/fonts/wps-office 目录\n注意：字体文件权限应该为644\n拷贝后，更新字体缓存\n1 sudo fc-cache -fv 其中 WINGDNG2.TTF、WINGDNG3.TTF、symobol.ttf、wingding.ttf 可以从windows系统中的 C:\\Windows\\Fonts 获取\nMTEXTRA.TTF 需要从网络下载\n字体附件：\nubuntu wps 缺失字体下载\n","date":"2023-09-08T00:00:00Z","permalink":"https://msdemt.github.io/p/ubuntu-wps-fonts/","title":"wps在ubuntu上缺少字体"},{"content":"dockerhub 获取 token 登录　dockerhub，获取token，如下\n将 dockerhub token 添加到 github repo 中\ngithub 仓库添加 action github 代码仓库页面中选择 Actions\n点击 Docker image Action 的 Configure\n编辑action配置文件.github/workflows/docker-image.yml 内容如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 name: Docker Image CI on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: build: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 - name: Login to Docker Hub uses: docker/login-action@v2 with: username: ${{ secrets.DOCKERHUB_USERNAME }} password: ${{ secrets.DOCKERHUB_TOKEN }} - name: Set up QEMU uses: docker/setup-qemu-action@v2 - name: Set up Docker Buildx uses: docker/setup-buildx-action@v2 - name: Build and push uses: docker/build-push-action@v4 with: context: . file: ./Dockerfile platforms: | linux/amd64 linux/arm64 push: true tags: ${{ secrets.DOCKERHUB_USERNAME }}/${{ env.GITHUB_REPOSITORY_NAME_PART }}:latest buildx 依赖 qemu\n以下对该文件内容分别进行解释：\nname: 流程名，定义了这个流程的名称，可以与配置文件名不同。只要与其他流程配置文件中的流程名不同即可。 on: 触发条件，定义了在何种条件下触发该流程。这里定义的是在　main 分支提交时触发该流程。 env: 环境变量，定义了静态可公开环境变量，一般来说可以将应用的名称、镜像的名称写在这个部分。 jobs: 任务，定义了流程所需要执行的各项任务，可以是一个或多个。 这里定义了 ５ 个任务，从前到后分别是 检出代码 登录到github，其中　${{ secrets.DOCKERHUB_USERNAME }}　和　${{ secrets.DOCKERHUB_TOKEN }} 分别是　dockerhub　的用户名和token，需要在dockerhub生成，然后配置在仓库-Settings-Security-Securets and variables - Actions中 安装 qemu （buildx 依赖　qemu） 安装　buildx，支持构建更多架构的惊喜 构建docker镜像，并推送到dockerhub仓库 file: 指定在项目仓库中的Dockerfile文件位置。 platforms：指定构建镜像所需要兼容支持的平台架构 tags: 将要构建的镜像标签，这里每次构建latest镜像，${{ env.GITHUB_REPOSITORY_NAME_PART }}表示仓库名 注：docker/setup-qemu-action@v2 对应的就是 https://github.com/docker/setup-qemu-action 分支v2\n参考：\nhttps://lisz.me/tech/docker/github-action.html\nhttp://www.ruanyifeng.com/blog/2019/09/getting-started-with-github-actions.html\nhttps://dmesg.app/github-actions-docker-image.html\nhttps://juejin.cn/post/7088959261870391332\n","date":"2023-09-08T00:00:00Z","permalink":"https://msdemt.github.io/p/github-action-build-docker/","title":"使用github action自动构建镜像并推送到dockerhub"},{"content":" 参考：\nhttps://www.zctou.com/2158.html\nhttps://www.cnblogs.com/xuanmanstein/p/10576476.html\n在 docker-compose.yml 文件中为容器分配固定IP，一般有两种方法：\n利用 docker ipam 功能在同一 yml 文件中分配固定IP 先在外部创建一个网络（external），然后在想要用这网络的容器指定IP 利用 docker ipam 分配固定 IP docker ipam 就是 IP Address Management Driver ，docker 官方文档地址如下：\nhttps://docs.docker.com/engine/reference/commandline/network_create/\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 version: \u0026#39;3.1\u0026#39; services: db: image: mariadb:5.5.60 restart: always environment: MYSQL_ROOT_PASSWORD: root MYSQL_ROOT_HOST: \u0026#34;%\u0026#34; TZ: Asia/Shanghai ports: - 3306:3306 volumes: - .data:/var/lib/mysql - .conf:/etc/mysql/conf.d networks: mynet1: ipv4_address: 172.15.0.2 adminer: image: adminer restart: always environment: TZ: Asia/Shanghai ports: - 18080:8080 networks: mynet1: ipv4_address: 172.15.0.3 networks: mynet1: ipam: config: - subnet: 172.15.0.0/16 可以看到用 ipam 指定一个内部网络，容器用 ipv4_address 获取固定IP。\n所有的容器都需要配置固定IP，否则容器IP位于不同网段，导致同一个yml中的容器网络不通。\n但这些 IP 只能用于这个内部网络容器间相互访问，要打通与其他网络间的访问，至少要有一个容器要同时在两个网络内。\n说得更白一点就是：这样分配的IP，是以这个yml为单位的小局域网，只能是这个yml中创建的容器间能互相访问。其他yml创建的容器访问不到这网络里面的容器。\n若要不同docker-compose.yml创建的网络互通，在yml中添加一个external为true的网络\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 version: \u0026#39;3.1\u0026#39; services: db: image: mariadb:5.5.60 restart: always environment: MYSQL_ROOT_PASSWORD: root MYSQL_ROOT_HOST: \u0026#34;%\u0026#34; TZ: Asia/Shanghai ports: - 3306:3306 volumes: - .data:/var/lib/mysql - .conf:/etc/mysql/conf.d networks: mynet1: ipv4_address: 172.15.0.2 mynet2: adminer: image: adminer restart: always environment: TZ: Asia/Shanghai ports: - 18080:8080 networks: mynet1: ipv4_address: 172.15.0.3 networks: mynet1: ipam: config: - subnet: 172.15.0.0/16 mynet2: external: true 先建外部网络，再给容器分配IP 先定义一个外部网络，再分别在每个 docker-compose 中用 ipv4_address 固定IP。\n创建外部网络\n1 2 #创建proxy网络 docker network create --driver bridge --subnet=172.18.0.0/24 mynet2 为容器指定 ip\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 version: \u0026#39;3.1\u0026#39; services: db: image: mariadb:5.5.60 restart: always environment: MYSQL_ROOT_PASSWORD: root MYSQL_ROOT_HOST: \u0026#34;%\u0026#34; TZ: Asia/Shanghai ports: - 3306:3306 volumes: - .data:/var/lib/mysql - .conf:/etc/mysql/conf.d networks: mynet2: ipv4_address: 172.20.0.2 adminer: image: adminer restart: always environment: TZ: Asia/Shanghai ports: - 18080:8080 networks: mynet2: ipv4_address: 172.20.0.3 networks: mynet2: external: true 问题 docker-compose up 首先会创建network 注意之前如果已经运行过多个不同工程的docker-compose 可能已经自动创建了很多network\n这样如果IP网段已经分配过了，就会失败:\n1 ERROR: Pool overlaps with other one on this address space 类似地，此外如果已经创建了network mynet1的网段 为 172.28.0.0，但是想改成172.19.0.1，也会失败\n这样都需要清理一下无效的network\n1 docker network prune 清除各种不用的docker相关东西 参考 https://blog.csdn.net/wennuanddianbo/article/details/78453325\n操作记录 network 定义在 docker-compose.yml 文件内\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ cat docker-compose.yml version: \u0026#39;3.1\u0026#39; services: db: image: mariadb:5.5.60 restart: always environment: MYSQL_ROOT_PASSWORD: root MYSQL_ROOT_HOST: \u0026#34;%\u0026#34; TZ: Asia/Shanghai ports: - 3306:3306 volumes: - .data:/var/lib/mysql - .conf:/etc/mysql/conf.d networks: mynet1: ipv4_address: 172.15.0.2 adminer: image: adminer restart: always environment: TZ: Asia/Shanghai ports: - 18080:8080 networks: mynet1: ipv4_address: 172.15.0.3 networks: mynet1: ipam: config: - subnet: 172.15.0.0/16 hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker network ls NETWORK ID NAME DRIVER SCOPE 7350be8b3ad2 bridge bridge local 0d7795b17742 docker-centos7-slurm-cluster_default bridge local 666586e51a5b host host local 97ca9cb8d2ea none null local hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker compose up -d [+] Building 0.0s (0/0) [+] Running 3/3 ✔ Network mariadb_mynet1 Created 0.1s ✔ Container mariadb-adminer-1 Started 1.7s ✔ Container mariadb-db-1 Started 0.8s hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker network ls NETWORK ID NAME DRIVER SCOPE 7350be8b3ad2 bridge bridge local 0d7795b17742 docker-centos7-slurm-cluster_default bridge local 666586e51a5b host host local 40ffa94e1ab4 mariadb_mynet1 bridge local 97ca9cb8d2ea none null local hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 49caff9a1d15 mariadb:5.5.60 \u0026#34;docker-entrypoint.s…\u0026#34; About a minute ago Up About a minute 0.0.0.0:3306-\u0026gt;3306/tcp, :::3306-\u0026gt;3306/tcp mariadb-db-1 127e6317a80a adminer \u0026#34;entrypoint.sh php -…\u0026#34; About a minute ago Up About a minute 0.0.0.0:18080-\u0026gt;8080/tcp, :::18080-\u0026gt;8080/tcp mariadb-adminer-1 64a701a17667 hekai/centos7.9-slurm22 \u0026#34;/tini -- /usr/local…\u0026#34; 9 hours ago Up 9 hours 22/tcp, 3306/tcp, 6817-6820/tcp docker-centos7-slurm-cluster-slurm-compute-1-1 e9762ead7456 hekai/centos7.9-slurm22 \u0026#34;/tini -- /usr/local…\u0026#34; 9 hours ago Up 9 hours 22/tcp, 3306/tcp, 6817-6820/tcp docker-centos7-slurm-cluster-slurm-compute-2-1 1fc423ffcf00 hekai/centos7.9-slurm22 \u0026#34;/tini -- /usr/local…\u0026#34; 9 hours ago Up 9 hours 22/tcp, 3306/tcp, 0.0.0.0:389-\u0026gt;389/tcp, :::389-\u0026gt;389/tcp, 6817-6819/tcp, 0.0.0.0:6820-\u0026gt;6820/tcp, :::6820-\u0026gt;6820/tcp docker-centos7-slurm-cluster-slurm-master-1 hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker inspect 49caff9a1d15 | grep IPAddress \u0026#34;SecondaryIPAddresses\u0026#34;: null, \u0026#34;IPAddress\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.15.0.2\u0026#34;, hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker inspect 127e6317a80a | grep IPAddress \u0026#34;SecondaryIPAddresses\u0026#34;: null, \u0026#34;IPAddress\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.15.0.3\u0026#34;, hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker compose down [+] Running 3/3 ✔ Container mariadb-adminer-1 Removed 0.4s ✔ Container mariadb-db-1 Removed 5.3s ✔ Network mariadb_mynet1 Removed 0.2s hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker network ls NETWORK ID NAME DRIVER SCOPE 7350be8b3ad2 bridge bridge local 0d7795b17742 docker-centos7-slurm-cluster_default bridge local 666586e51a5b host host local 97ca9cb8d2ea none null local hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 66a097a109ef mariadb:5.5.60 \u0026#34;docker-entrypoint.s…\u0026#34; 8 seconds ago Up 5 seconds 0.0.0.0:3306-\u0026gt;3306/tcp, :::3306-\u0026gt;3306/tcp mariadb-db-1 b9188a6e2cf6 adminer \u0026#34;entrypoint.sh php -…\u0026#34; 8 seconds ago Up 6 seconds 0.0.0.0:18080-\u0026gt;8080/tcp, :::18080-\u0026gt;8080/tcp mariadb-adminer-1 64a701a17667 hekai/centos7.9-slurm22 \u0026#34;/tini -- /usr/local…\u0026#34; 9 hours ago Up 9 hours 22/tcp, 3306/tcp, 6817-6820/tcp docker-centos7-slurm-cluster-slurm-compute-1-1 e9762ead7456 hekai/centos7.9-slurm22 \u0026#34;/tini -- /usr/local…\u0026#34; 9 hours ago Up 9 hours 22/tcp, 3306/tcp, 6817-6820/tcp docker-centos7-slurm-cluster-slurm-compute-2-1 1fc423ffcf00 hekai/centos7.9-slurm22 \u0026#34;/tini -- /usr/local…\u0026#34; 9 hours ago Up 9 hours 22/tcp, 3306/tcp, 0.0.0.0:389-\u0026gt;389/tcp, :::389-\u0026gt;389/tcp, 6817-6819/tcp, 0.0.0.0:6820-\u0026gt;6820/tcp, :::6820-\u0026gt;6820/tcp docker-centos7-slurm-cluster-slurm-master-1 hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker inspect 1fc423ffcf00 | grep IPAddress \u0026#34;SecondaryIPAddresses\u0026#34;: null, \u0026#34;IPAddress\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.19.0.2\u0026#34;, hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker exec -ti 66a097a109ef bash root@66a097a109ef:/# ping 172.19.0.2 PING 172.19.0.2 (172.19.0.2) 56(84) bytes of data. ^C --- 172.19.0.2 ping statistics --- 7 packets transmitted, 0 received, 100% packet loss, time 6129ms root@66a097a109ef:/# ping www.baidu.com PING www.a.shifen.com (220.181.38.149) 56(84) bytes of data. 64 bytes from 220.181.38.149: icmp_seq=1 ttl=48 time=10.6 ms 64 bytes from 220.181.38.149: icmp_seq=2 ttl=48 time=10.6 ms ^C --- www.a.shifen.com ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1001ms rtt min/avg/max/mdev = 10.639/10.646/10.654/0.103 ms root@66a097a109ef:/# exit exit hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ network 定义在 docker-compose.yml 文件外\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker network ls NETWORK ID NAME DRIVER SCOPE 7350be8b3ad2 bridge bridge local 0d7795b17742 docker-centos7-slurm-cluster_default bridge local 666586e51a5b host host local 97ca9cb8d2ea none null local hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker network create --driver bridge --subnet=172.20.0.0/24 mynet2 2bc1739b9484c6f7b640f84b711c5618cc80d2f98fcb794c037abcf299bf7be1 hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ cat docker-compose.yml version: \u0026#39;3.1\u0026#39; services: db: image: mariadb:5.5.60 restart: always environment: MYSQL_ROOT_PASSWORD: root MYSQL_ROOT_HOST: \u0026#34;%\u0026#34; TZ: Asia/Shanghai ports: - 3306:3306 volumes: - .data:/var/lib/mysql - .conf:/etc/mysql/conf.d networks: mynet2: ipv4_address: 172.20.0.2 adminer: image: adminer restart: always environment: TZ: Asia/Shanghai ports: - 18080:8080 networks: mynet2: ipv4_address: 172.20.0.3 networks: mynet2: external: true hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker compose up -d [+] Building 0.0s (0/0) [+] Running 2/2 ✔ Container mariadb-adminer-1 Started 0.8s ✔ Container mariadb-db-1 Started 1.8s hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker network ls NETWORK ID NAME DRIVER SCOPE 7350be8b3ad2 bridge bridge local 0d7795b17742 docker-centos7-slurm-cluster_default bridge local 666586e51a5b host host local 2bc1739b9484 mynet2 bridge local 97ca9cb8d2ea none null local hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 04c55ef43d94 mariadb:5.5.60 \u0026#34;docker-entrypoint.s…\u0026#34; 9 seconds ago Up 7 seconds 0.0.0.0:3306-\u0026gt;3306/tcp, :::3306-\u0026gt;3306/tcp mariadb-db-1 36af8aae907c adminer \u0026#34;entrypoint.sh php -…\u0026#34; 9 seconds ago Up 8 seconds 0.0.0.0:18080-\u0026gt;8080/tcp, :::18080-\u0026gt;8080/tcp mariadb-adminer-1 64a701a17667 hekai/centos7.9-slurm22 \u0026#34;/tini -- /usr/local…\u0026#34; 9 hours ago Up 9 hours 22/tcp, 3306/tcp, 6817-6820/tcp docker-centos7-slurm-cluster-slurm-compute-1-1 e9762ead7456 hekai/centos7.9-slurm22 \u0026#34;/tini -- /usr/local…\u0026#34; 9 hours ago Up 9 hours 22/tcp, 3306/tcp, 6817-6820/tcp docker-centos7-slurm-cluster-slurm-compute-2-1 1fc423ffcf00 hekai/centos7.9-slurm22 \u0026#34;/tini -- /usr/local…\u0026#34; 9 hours ago Up 9 hours 22/tcp, 3306/tcp, 0.0.0.0:389-\u0026gt;389/tcp, :::389-\u0026gt;389/tcp, 6817-6819/tcp, 0.0.0.0:6820-\u0026gt;6820/tcp, :::6820-\u0026gt;6820/tcp docker-centos7-slurm-cluster-slurm-master-1 hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker inspect 04c55ef43d94 | grep IPAddress \u0026#34;SecondaryIPAddresses\u0026#34;: null, \u0026#34;IPAddress\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.20.0.2\u0026#34;, hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker inspect 36af8aae907c | grep IPAddress \u0026#34;SecondaryIPAddresses\u0026#34;: null, \u0026#34;IPAddress\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.20.0.3\u0026#34;, hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker inspect 1fc423ffcf00 | grep IPAddress \u0026#34;SecondaryIPAddresses\u0026#34;: null, \u0026#34;IPAddress\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.19.0.2\u0026#34;, hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker exec -ti 04c55ef43d94 bsah OCI runtime exec failed: exec failed: unable to start container process: exec: \u0026#34;bsah\u0026#34;: executable file not found in $PATH: unknown hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker exec -ti 04c55ef43d94 bash root@04c55ef43d94:/# ping 172.20.0.3 PING 172.20.0.3 (172.20.0.3) 56(84) bytes of data. 64 bytes from 172.20.0.3: icmp_seq=1 ttl=64 time=0.232 ms 64 bytes from 172.20.0.3: icmp_seq=2 ttl=64 time=0.115 ms ^C --- 172.20.0.3 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1027ms rtt min/avg/max/mdev = 0.115/0.173/0.232/0.059 ms root@04c55ef43d94:/# ping 172.19.0.2 PING 172.19.0.2 (172.19.0.2) 56(84) bytes of data. ^C --- 172.19.0.2 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 1029ms root@04c55ef43d94:/# ping www.baidu.com PING www.a.shifen.com (220.181.38.149) 56(84) bytes of data. 64 bytes from 220.181.38.149: icmp_seq=1 ttl=48 time=18.5 ms ^C --- www.a.shifen.com ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 18.512/18.512/18.512/0.000 ms root@04c55ef43d94:/# exit exit hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker compose down [+] Running 2/2 ✔ Container mariadb-db-1 Removed 2.2s ✔ Container mariadb-adminer-1 Removed 0.4s hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker network ls NETWORK ID NAME DRIVER SCOPE 7350be8b3ad2 bridge bridge local 0d7795b17742 docker-centos7-slurm-cluster_default bridge local 666586e51a5b host host local 2bc1739b9484 mynet2 bridge local 97ca9cb8d2ea none null local hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ docker network rm mynet2 mynet2 hekai@00bafcjc-dUrwEMo9N5:/opt/workspace/msdemt/docker-collection/docker-compose/mariadb$ ","date":"2023-09-07T00:00:00Z","permalink":"https://msdemt.github.io/p/docker-compose-add-ip/","title":"docker compose 指定容器 ip"},{"content":" docker镜像配置了entrypoint.sh脚本，无法直接进入容器\n覆盖entrypoint启动容器，如：\n1 docker run -ti --entrypoint \u0026#34;\u0026#34; hekai/centos7.9-slurm22 bash https://blog.csdn.net/qq_38250124/article/details/85075768\n将多个RUN指令合并为一个，能不能减少镜像体积\n如果在一个 RUN 指令里进行了文件下载，另一个RUN里删除了文件，那么，镜像体积是会变大的 如：\n1 2 RUN curl -O https://test.com/file RUN rm -rf file 如果在一个RUN里进行文件下载和删除，那么镜像体积是不变的 如：\n1 RUN curl -O https://test.com/file \u0026amp;\u0026amp; rm -rf file shell中的\u0026amp;\u0026amp;用法：https://blog.csdn.net/u011630575/article/details/97613695\n精简镜像体积\n在同一个RUN指令中下载文件后，然后删除不用的文件 删除缓存，如 rm -rf /var/log/* /var/cache/* /tmp/* 删除不需要的软件包，如 yum autoremove -y 使用多阶段构建镜像 使用echo将脚本写入到文件\nhttps://blog.csdn.net/xukai871105/article/details/35834703 https://zhuanlan.zhihu.com/p/451994783\n1 2 hekai@00bafcjc-dUrwEMo9N5:~/Videos$ echo -e \u0026#34;#!/bin/bash\\nexport JAVA_HOME=/usr/local/jdk\\n\u0026#34; \u0026gt; a bash: !/bin/bash\\nexport: event not found 是由于 H - histexpand 模式打开了导致。 命令行下，双引号里面用了 ! 的话，Shell 会以为要执行历史展开，从而导致报错。\n解决方法，将双引号替换为单引号\n1 echo -e \u0026#39;#!/bin/bash\\nexport JAVA_HOME=/usr/local/jdk\\n\u0026#39; \u0026gt; a https://blog.csdn.net/h952520296/article/details/112625995\n","date":"2023-09-07T00:00:00Z","permalink":"https://msdemt.github.io/p/docker-skills/","title":"docker 技巧"},{"content":"介绍 希望将 jdk-8u202-linux-x64.tar.gz (186M) 上传到 github ，从而生成 jdk-8u202-linux-x64.tar.gz 的直链，用于构建包含 jdk 的 docker 镜像\ngithub 参考：\nhttps://docs.github.com/zh/repositories/working-with-files/managing-large-files/about-large-files-on-github\ngithub 文件大小限制\nGitHub 限制存储库中允许的文件大小。 如果尝试添加或更新大于 50 MiB 的文件，您将从 Git 收到警告。 更改仍将成功推送到仓库，但您可以考虑删除提交，以尽量减少对性能的影响。 如果通过浏览器将文件添加到存储库，该文件不得大于 25 MiB GitHub 阻止大小超过 100 MiB 的文件。要跟踪超出此限制的文件，必须使用 Git Large File Storage (Git LFS) Git LFS 处理大文件的方式是存储对仓库中文件的引用，而不实际文件本身。 为满足 Git 的架构要求，Git LFS 创建了“指针文件”，充当对实际文件（存储在其他位置）的引用。 GitHub 在仓库中管理此指针文件。 克隆仓库时，GitHub 使用指针文件作为映射来查找大文件。\u0026ndash;\u0026gt; 无法生成文件直链 Git LFS 的不同最大大小限制取决于 GitHub 计划，免费版文件大小上线为2 如果需要在存储库中分发大文件，则可以在 GitHub.com 上创建版本，而不是跟踪文件。参阅 分发大型二进制文件 如果需要在存储库内分发大型文件，可以在 GitHub.com 上创建发行版。 发行版允许您打包软件、发行说明和指向二进制文件的链接，以供其他人使用。 有关详细信息，请访问“关于发行版” 不限制二进制发行版文件的总大小，也不限制用于传递它们的带宽。 但每个文件必须小于 2 GiB。 所以，无法直接将体积为 186MB 的 jdk-8u202-linux-x64.tar.gz 上传到仓库，可行的方式如下\n使用 git lfs，问题：无法生成直链（点击链接即可下载） 使用 发行版 将 jdk 拆分为最大100MB的子包，上传到 github 获取直链，然后在 Dockerfile 中下载所有子包后，将子包合并为完整包 拆分子包命令：tar -czf - jdk-8u202-linux-x64.tar.gz | split -b 100m -d - jdk8u202.tar.gz 合并子包：cat jdk8u202.tar.gz* | tar -zxf - git lfs 上传文件介绍 github 使用 git lfs 上传大于 100MB 文件\nubuntu 安装 git lfs 安装 git lfs 软件仓库： curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash 安装 git lfs: sudo apt-get install -y git-lfs 进入 git 项目目录： cd large_file_test 追踪待上传的大文件： git lfs track files/jdk-8u202-linux-x64.tar.gz 执行 git lfs track 命令后，会生成 .gitattribute 文件，文件内记录了待上传文件的信息，将 .gitattribute 文件上传后，才可以上传大文件 将 .gitattribute 文件上传 git add .gitattribute git commit -m \u0026quot;add .gitattribute\u0026quot; git push origin main 上传大文件 git add files/jdk-8u202-linux-x64.tar.gz git commit -m \u0026quot;add jdk-8u202-linux-x64.tar.gz\u0026quot; git push origin main 需要注意的是，通过git-lfs上传文件是有空间限制的，免费用户如果上传的文件超过了1G，账号就会被冻结，所以大家在上传前一定要检查一下自己还剩多少空间（Settings - Billing and plans - Plans and usage - Git LFS Data）。\n问题 batch response: Git LFS is disabled for this repository.\n如果在上传过程中出现如下报错：\n1 2 batch response: Git LFS is disabled for this repository. Uploading LFS objects: 0% (0/1), 0 B | 0 B/s, done 就说明你的账号被冻结了，需要在GitHub后台提交解封申请。\nhttps://support.github.com/contact\ngitee 使用 git lfs上传失败\n1 2 3 4 $ git push origin mainwarning: Authentication error: Authentication required: LFS only supported repository in paid or trial enterprise. batch response: LFS only supported repository in paid or trial enterprise. Uploading LFS objects: 0% (0/1), 0 B | 0 B/s, done. error: failed to push some refs to \u0026#39;https://gitee.com/msdemt/large-files.git\u0026#39; 解决：\n删除 .git/hooks/pre-push\n1 rm .git/hooks/pre-push 然后执行上传\n1 git push origin main 参考：\nhttps://cloud.tencent.com/developer/article/1677003\n","date":"2023-09-07T00:00:00Z","permalink":"https://msdemt.github.io/p/github-large-files/","title":"github 上传大文件"},{"content":" 转载：\nhttps://www.techiedelight.com/zh-tw/sort-list-of-objects-using-comparable-java/\nhttps://www.techiedelight.com/zh-tw/sort-list-of-objects-using-comparator-java/\n使用 Comparable 对对象进行排序 要在 Java 中对对象集合(使用某些属性)进行排序，我们可以使用 java.lang.Comparable 接口，它对实现它的每个类的对象施加自然排序。因此，如果一个对象实现 Comparable 接口，那么该对象的列表(和数组)可以使用 Collections.sort （和 Arrays.sort）进行自动排序。\n实现此接口的对象也可以用作排序映射中的键（TreeMap） 或作为有序集合中的元素 (TreeSet)，无需指定比较器。\n此类的实现者需要重写抽象方法， compareTo() 定义在 java.util.Comparable，它将对象与指定对象进行比较，由 compareTo() 方法的返回值决定对象相对于指定对象的位置。\n如果 compareTo() 返回一个负整数，该对象小于指定对象。 如果 compareTo() 返回一个零，该对象等于指定对象。 如果 compareTo() 返回一个正整数，该对象大于指定对象。 以下是我们如何对列表进行排序， Employee 对象使用Java中的 Comparable 接口进行排序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 package com.example.demo.testdemo; import java.util.*; class Employee implements Comparable\u0026lt;Employee\u0026gt; { private String name; private int age; public Employee(String name, int age) { this.name = name; this.age = age; } @Override public String toString() { return \u0026#34;{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } public String getName() { return name; } public int getAge() { return age; } @Override public int compareTo(Employee o) { return o.getAge() - this.age; } } class Main { public static void main(String[] args) { List\u0026lt;Employee\u0026gt; employees = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(new Employee(\u0026#34;John\u0026#34;, 15), new Employee(\u0026#34;Sam\u0026#34;, 20), new Employee(\u0026#34;Joe\u0026#34;, 10))); Collections.sort(employees); System.out.println(employees); } } 输出：\n1 [{name=\u0026#39;Joe\u0026#39;, age=10}, {name=\u0026#39;John\u0026#39;, age=15}, {name=\u0026#39;Sam\u0026#39;, age=20}] 上面的代码将仅按 age 排序，如果两个员工的年龄相同，那么他们在排序列表中的相对位置是不固定的，因此，最好使用多个字段比较对象以避免这种情況。\n比较对象的多个字段 我们可以首先对员工列表使用 age 进行排序，然后使用 name 进行排序， 如下所示。现在对于年龄相同的员工，排序顺序由员工的姓名决定。\n1 2 3 4 5 6 7 @Override public int compareTo(Employee o) { if (this.age != o.getAge()) { return this.age - o.getAge(); } return this.name.compareTo(o.getName()); } 注意，我们对int类型的aget进行比较，对于name属性，使用的是String对象内置的比较方法。该比较方法可以继续进一步包括其他属性。\n完整代码如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 import java.util.*; class Employee implements Comparable\u0026lt;Employee\u0026gt; { private String name; private int age; public Employee(String name, int age) { this.name = name; this.age = age; } @Override public String toString() { return \u0026#34;{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } public String getName() { return name; } public int getAge() { return age; } @Override public int compareTo(Employee o) { if (this.age != o.getAge()) { return this.age - o.getAge(); } return this.name.compareTo(o.getName()); } } class Main { public static void main(String[] args) { List\u0026lt;Employee\u0026gt; employees = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(new Employee(\u0026#34;John\u0026#34;, 15), new Employee(\u0026#34;Sam\u0026#34;, 20), new Employee(\u0026#34;Dan\u0026#34;, 20), new Employee(\u0026#34;Will\u0026#34;, 20), new Employee(\u0026#34;Joe\u0026#34;, 10))); Collections.sort(employees); System.out.println(employees); } } 输出：\n1 [{name=\u0026#39;Joe\u0026#39;, age=10}, {name=\u0026#39;John\u0026#39;, age=15}, {name=\u0026#39;Dan\u0026#39;, age=20}, {name=\u0026#39;Sam\u0026#39;, age=20}, {name=\u0026#39;Will\u0026#39;, age=20}] Guava - ComparisonChain Class 我们可以使用 Guava 的 ComparisonChain 用于在 compareTo() 方法，如下：\n1 2 3 4 5 6 7 @Override public int compareTo(Employee o) { return ComparisonChain.start() .compare(this.age, o.getAge()) .compare(this.name, o.getName()) .result(); } compareTo() 方法的返回值将与链中的地一个非零比较结果具有相同的符号，或者如果每个比较结果都为零，则该方法将为零。\n注意， 只要其中一个返回非零结果，ComparisonChain 就会停止调用后续的 compareTo 和 compare 方法。\n完整代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 import com.google.common.collect.ComparisonChain; import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; import java.util.List; class Employee implements Comparable\u0026lt;Employee\u0026gt; { private String name; private int age; public Employee(String name, int age) { this.name = name; this.age = age; } @Override public String toString() { return \u0026#34;{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } public String getName() { return name; } public int getAge() { return age; } @Override public int compareTo(Employee o) { return ComparisonChain.start().compare(this.age, o.getAge()).compare(this.name, o.getName()).result(); } } class Main { public static void main(String[] args) { List\u0026lt;Employee\u0026gt; employees = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(new Employee(\u0026#34;John\u0026#34;, 15), new Employee(\u0026#34;Sam\u0026#34;, 20), new Employee(\u0026#34;Dan\u0026#34;, 20), new Employee(\u0026#34;Will\u0026#34;, 20), new Employee(\u0026#34;Joe\u0026#34;, 10))); Collections.sort(employees); System.out.println(employees); } } 输出：\n1 [{name=\u0026#39;Joe\u0026#39;, age=10}, {name=\u0026#39;John\u0026#39;, age=15}, {name=\u0026#39;Dan\u0026#39;, age=20}, {name=\u0026#39;Sam\u0026#39;, age=20}, {name=\u0026#39;Will\u0026#39;, age=20}] Apache Commons 我们也可以使用 Apache Commons Lang 库的 CompareToBuilder 类来帮助实现 Comparable.compareTo(Object) 方法。要使用这个类，代码如下：\n1 2 3 4 5 6 7 @Override public int compareTo(Employee o) { return new CompareToBuilder() .append(this.age, o.getAge()) .append(this.name, o.getName()) .toComparison(); } 按照构造器的顺序进行比较，如果append方法返回非零结果，则该值将由 toComparison() 比较，并跳过后续的比较。\n完整代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 import org.apache.commons.lang3.builder.CompareToBuilder; import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; import java.util.List; class Employee implements Comparable\u0026lt;Employee\u0026gt; { private String name; private int age; public Employee(String name, int age) { this.name = name; this.age = age; } @Override public String toString() { return \u0026#34;{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } public String getName() { return name; } public int getAge() { return age; } @Override public int compareTo(Employee o) { return new CompareToBuilder().append(this.age, o.getAge()).append(this.name, o.getName()).toComparison(); } } class Main { public static void main(String[] args) { List\u0026lt;Employee\u0026gt; employees = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(new Employee(\u0026#34;John\u0026#34;, 15), new Employee(\u0026#34;Sam\u0026#34;, 20), new Employee(\u0026#34;Dan\u0026#34;, 20), new Employee(\u0026#34;Will\u0026#34;, 20), new Employee(\u0026#34;Joe\u0026#34;, 10))); Collections.sort(employees); System.out.println(employees); } } 输出：\n1 [{name=\u0026#39;Joe\u0026#39;, age=10}, {name=\u0026#39;John\u0026#39;, age=15}, {name=\u0026#39;Dan\u0026#39;, age=20}, {name=\u0026#39;Sam\u0026#39;, age=20}, {name=\u0026#39;Will\u0026#39;, age=20}] 使用 Comparator 对对象进行排序 Comparator 是一个接口，它为没有自然排序的对象集合提供排序。此类的实现者需要重写定义在 java.util.Comparator 的抽象方法 compare() 。由 compare() 方法返回的值决定地一个对象想对于第二个对象的位置。\n如果 compare() 返回一个负整数，第一个参数小于第二个。 如果 compare() 返回零，第一个参数等于第二个。 如果 compare() 返回一个正整数，第一个参数大于第二个。 在 Java 中有几种实现比较器的方法：\n将 Comparator 作为参数传递给 sort() 方法 将 Comparator 比较器传递给排序方法（例如 Collections.sort、 Arrays.sort），允许精确控制排序顺序。在下面的例子中，我们得到一个 Comparator 比较 Person 对象的年龄。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import java.util.*; class Person { private String name; private int age; public Person(String name, int age) { this.name = name; this.age = age; } @Override public String toString() { return \u0026#34;{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } public String getName() { return name; } public int getAge() { return age; } } class Main { public static void main(String[] args) { List\u0026lt;Person\u0026gt; persons = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(new Person(\u0026#34;John\u0026#34;, 15), new Person(\u0026#34;Sam\u0026#34;, 25), new Person(\u0026#34;Will\u0026#34;, 20), new Person(\u0026#34;Dan\u0026#34;, 20), new Person(\u0026#34;Joe\u0026#34;, 10))); Collections.sort(persons, new Comparator\u0026lt;Person\u0026gt;() { @Override public int compare(Person p1, Person p2) { return p1.getAge() - p2.getAge(); } }); System.out.println(persons); } } 输出：\n1 [{name=\u0026#39;Joe\u0026#39;, age=10}, {name=\u0026#39;John\u0026#39;, age=15}, {name=\u0026#39;Will\u0026#39;, age=20}, {name=\u0026#39;Dan\u0026#39;, age=20}, {name=\u0026#39;Sam\u0026#39;, age=25}] 因为 Comparator 是一个函数式接口，它可以用作 lambda 表达式或方法引用的赋值目标。所以，\n1 2 3 4 5 6 Collections.sort(persons, new Comparator\u0026lt;Person\u0026gt;() { @Override public int compare(Person p1, Person p2) { return p1.getAge() - p2.getAge(); } }); 可以改写为\n1 Collections.sort(persons, (p1, p2) -\u0026gt; p1.getAge() - p2.getAge()); Java 8 对 Comparator 增强。现在 Comparator 有静态方法，比如 comparing()，它可以很容易地创建比较器来比较对象中的一些特定值。例如，要获得一个 Comparator 比较 Person 对象的年龄，我们可以这样做：\n1 2 Comparator\u0026lt;Person\u0026gt; byAge = Comparator.comparing(Person::getAge); Collections.sort(persons, byAge); 上面的代码将仅按 age 比较，如果两个人的年龄相同，那么他们在排序列表中的相对顺序是不固定的。因此，最好使用多个字段比较对象以避免这种情况。\n比较对象的多个字段 可以先对 Persion 列表的 age 排序，然后对 name 排序，如下所示，对于相同年龄的人，排序由人名决定。\n1 2 3 4 5 6 7 8 9 10 Collections.sort(persons, new Comparator\u0026lt;Person\u0026gt;() { @Override public int compare(Person p1, Person p2) { if (p1.getAge() != p2.getAge()) { return p1.getAge() - p2.getAge(); } return p1.getName().compareTo(p2.getName()); } }); 注意，我们对int类型的aget进行比较，对于name属性，使用的是String对象内置的比较方法。该比较方法可以继续进一步包括其他属性。\n可以使用 lambda 表达式来做到这一点，使用 .thenComparing() 方法，有效地将两种比较合二为一：\n1 2 3 4 Comparator\u0026lt;Person\u0026gt; byAge = Comparator.comparing(Person::getAge); Comparator\u0026lt;Person\u0026gt; byName = Comparator.comparing(Person::getName); Collections.sort(persons, byAge.thenComparing(byName)); 也可以使用 Guava 的 ComparisonChain 用于执行链式比较语句，如下所示：\n1 2 3 4 5 6 7 8 9 10 Collections.sort(persons, new Comparator\u0026lt;Person\u0026gt;() { @Override public int compare(Person p1, Person p2) { return ComparisonChain.start() .compare(p1.getAge(), p2.getAge()) .compare(p1.getName(), p2.getName()) .result(); } }); compare() 方法的返回值，将与链中的地一个非零比较结果具有相同的符号，或者如果每个比较结果都为零，则该方法将为零。注意， 只要其中一个 compare 返回非零结果，ComparisonChain 停止调用后续的 compare 方法。\n也可以使用 Apache Commons Lang 库的 CompareToBuilder 类来实现 Comparator.compare() 方法。代码如下：\n1 2 3 4 5 6 7 8 9 10 Collections.sort(persons, new Comparator\u0026lt;Person\u0026gt;() { @Override public int compare(Person p1, Person p2) { return new CompareToBuilder() .append(p1.getAge(), p2.getAge()) .append(p1.getName(), p2.getName()) .toComparison(); } }); 按照 CompareToBuilder 构造器的顺序进行比较，如果任何比较返回非零结果，则该值将由 toComparison() 处理，并跳过所有后续比较。\n在单独的类中实现Comparator 可以在一个单独的类中实现 Comparator ，然后将该类的实例传送给 sort() 方法。如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 import java.util.*; class Person { private String name; private int age; public Person(String name, int age) { this.name = name; this.age = age; } @Override public String toString() { return \u0026#34;{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } public String getName() { return name; } public int getAge() { return age; } } class MyComparator implements Comparator\u0026lt;Person\u0026gt; { @Override public int compare(Person p1, Person p2) { if (p1.getAge() != p2.getAge()) { return p1.getAge() - p2.getAge(); } return p1.getName().compareTo(p2.getName()); } } class Main { public static void main(String[] args) { List\u0026lt;Person\u0026gt; persons = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(new Person(\u0026#34;John\u0026#34;, 15), new Person(\u0026#34;Sam\u0026#34;, 25), new Person(\u0026#34;Will\u0026#34;, 20), new Person(\u0026#34;Dan\u0026#34;, 20), new Person(\u0026#34;Joe\u0026#34;, 10))); Collections.sort(persons, new MyComparator()); System.out.println(persons); } } 输出：\n1 [{name=\u0026#39;Joe\u0026#39;, age=10}, {name=\u0026#39;John\u0026#39;, age=15}, {name=\u0026#39;Dan\u0026#39;, age=20}, {name=\u0026#39;Will\u0026#39;, age=20}, {name=\u0026#39;Sam\u0026#39;, age=25}] 将比较器 Comparator 传给 List.sort() 方法 从 Java 8 开始， List 可以使用 sort() 方法根据指定的顺序对列表进行排序，如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 import java.util.*; class Person { private String name; private int age; public Person(String name, int age) { this.name = name; this.age = age; } @Override public String toString() { return \u0026#34;{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } public String getName() { return name; } public int getAge() { return age; } } class Main { public static void main(String[] args) { List\u0026lt;Person\u0026gt; persons = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(new Person(\u0026#34;John\u0026#34;, 15), new Person(\u0026#34;Sam\u0026#34;, 25), new Person(\u0026#34;Will\u0026#34;, 20), new Person(\u0026#34;Dan\u0026#34;, 20), new Person(\u0026#34;Joe\u0026#34;, 10))); persons.sort(Comparator.comparing(Person::getAge).thenComparing(Comparator.comparing(Person::getName))); System.out.println(persons); } } 输出:\n1 [{name=\u0026#39;Joe\u0026#39;, age=10}, {name=\u0026#39;John\u0026#39;, age=15}, {name=\u0026#39;Dan\u0026#39;, age=20}, {name=\u0026#39;Will\u0026#39;, age=20}, {name=\u0026#39;Sam\u0026#39;, age=25}] 将比较器 Comparator 传给 Stream.sorted() 方法 可以將Comparator 比较其传送给Stream 类的 sorted() 方法，它返回一个由该該流的元素组成的流，示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 import java.util.ArrayList; import java.util.Arrays; import java.util.Comparator; import java.util.List; import java.util.stream.Collectors; class Person { private String name; private int age; public Person(String name, int age) { this.name = name; this.age = age; } @Override public String toString() { return \u0026#34;{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } public String getName() { return name; } public int getAge() { return age; } } class Main { public static void main(String[] args) { List\u0026lt;Person\u0026gt; persons = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(new Person(\u0026#34;John\u0026#34;, 15), new Person(\u0026#34;Sam\u0026#34;, 25), new Person(\u0026#34;Will\u0026#34;, 20), new Person(\u0026#34;Dan\u0026#34;, 20), new Person(\u0026#34;Joe\u0026#34;, 10))); persons = persons.stream() .sorted(Comparator.comparing(Person::getAge).thenComparing(Comparator.comparing(Person::getName))) .collect(Collectors.toList()); System.out.println(persons); } } 输出：\n1 [{name=\u0026#39;Joe\u0026#39;, age=10}, {name=\u0026#39;John\u0026#39;, age=15}, {name=\u0026#39;Dan\u0026#39;, age=20}, {name=\u0026#39;Will\u0026#39;, age=20}, {name=\u0026#39;Sam\u0026#39;, age=25}] ","date":"2023-09-07T00:00:00Z","permalink":"https://msdemt.github.io/p/java-comparable-comparator/","title":"java使用Comparable或Comparator对对象进行排序"},{"content":"本文主要讲解 Stream 对日期字段进行排序时的写法，以及当日期字段为 null 时的排序策略。或者对多个属性进行排序时的案例\nStream 对对象中的某个日期属性进行排序\nStudent 对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import lombok.Data; import java.util.Date; @Data public class Student { private String name; private int age; private Date birthday; public Student(String name, int age,Date birthday) { this.name = name; this.age = age; this.birthday = birthday; } } 排序\n1 2 3 4 5 6 7 8 9 List\u0026lt;Student\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); Student s1 = new Student(\u0026#34;a\u0026#34;, 11, new Date(2020, 1, 1)); Student s2 = new Student(\u0026#34;b\u0026#34;, 12, new Date(2020, 1, 2)); Student s3 = new Student(\u0026#34;c\u0026#34;, 13, new Date(2020, 1, 3)); list.add(s1); list.add(s2); list.add(s3); list = list.stream().sorted(Comparator.comparing(Student::getBirthday)).collect(Collectors.toList()); 注意：当 birthday 日期属性为空时，再使用 Comparator.comparing 排序会报空指针异常，此时需要指定策略，即当日期为空时排在最前面或排在最后面。\n对日期属性进行排序，并指定日期为空时的策略\n1 2 3 4 5 6 7 8 9 10 List\u0026lt;Student\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); Student s1 = new Student(\u0026#34;a\u0026#34;, 11, new Date(2020, 1, 1)); Student s2 = new Student(\u0026#34;b\u0026#34;, 12, new Date(2020, 1, 2)); Student s3 = new Student(\u0026#34;c\u0026#34;, 13, null); list.add(s1); list.add(s2); list.add(s3); list = list.stream().sorted(Comparator.comparing(Student::getBirthday,Comparator.nullsFirst(Comparator.naturalOrder()))).collect(Collectors.toList()); System.out.println(list); 执行结果：\n1 [Student(name=c, age=13, birthday=null), Student(name=a, age=11, birthday=Sun Feb 01 00:00:00 CST 3920), Student(name=b, age=12, birthday=Mon Feb 02 00:00:00 CST 3920)] 排序策略\nnullsFirst():为空时排在最前面，此方法返回比较器，其是空型比较，并认为空值小于非空。null首先通过以下逻辑进行操作： null元素被认为小于non-null（即值是null的小于非空的）。 当两个元素都为空时，则认为它们相等。 当两个元素都不为空时，指定的Comparator确定顺序。 如果指定的比较器为null，则返回的比较器将所有非null元素视为相等。 如果指定的比较器可序列化，则返回的比较器可序列化。 nullsLast():为空时排在最后面，方法返回比较器，其是空型比较，并认为比非空更大空值。null首先通过以下逻辑进行操作： null元素被认为大于非null。 当两个元素都为空时，则认为它们相等。 当两个元素都不为空时，指定的Comparator确定顺序。 如果指定的比较器为null，则返回的比较器将所有非null元素视为相等。 如果指定的比较器可序列化，则返回的比较器可序列化。 Comparator.naturalOrder 和 Comparator.reverseOrder：很多时候我们会面临这样的场景，那就是排序逻辑不变，一会儿根据升序排序，一会根据降序排序，这个时候如果我们的Comparable 中的排序逻辑可以满足上面的排序，就是排序类型(升序还是降序)是不满足的，这个时候我们就可以配合Comparator，来改变原来默认的排序类型(默认是升序) nullsFirst与naturalOrder的结合使用\n如下示例：当字段为空时排在最前面，剩下的升序排列\n1 2 3 4 5 6 7 8 9 List\u0026lt;Student\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); Student s1 = new Student(\u0026#34;a\u0026#34;, 11, new Date(2020, 1, 1)); Student s2 = new Student(\u0026#34;b\u0026#34;, 12, new Date(2020, 1, 2)); Student s3 = new Student(\u0026#34;c\u0026#34;, 13, null); list.add(s1); list.add(s2); list.add(s3); list = list.stream().sorted(Comparator.comparing(Student::getBirthday,Comparator.nullsFirst(Comparator.naturalOrder()))).collect(Collectors.toList()); Comparator.nullsFirst(Comparator.naturalOrder()): 空值放前面，剩下的升序排序 Comparator.nullsFirst(Comparator.reverseOrder()): 空值放前面，剩下的倒叙排序 Comparator.nullsLast(Comparator.naturalOrder()): 空值放最后，剩下的升序排序 Comparator.nullsLast(Comparator.reverseOrder()): 空值放最后，剩下的倒叙排序 对对象中的多个属性进行排序\n先根据生日排序，再根据年龄排序\n1 2 3 4 5 6 7 8 9 10 11 12 13 List\u0026lt;Student\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); Student s1 = new Student(\u0026#34;a\u0026#34;, 11, new Date(2020, 1, 1)); Student s2 = new Student(\u0026#34;b\u0026#34;, 12, new Date(2020, 1, 2)); Student s3 = new Student(\u0026#34;c\u0026#34;, 13, null); Student s4 = new Student(\u0026#34;d\u0026#34;, 13, null); list.add(s1); list.add(s2); list.add(s3); list.add(s4); list = list.stream().sorted(Comparator.comparing(Student::getBirthday,Comparator.nullsFirst(Comparator.naturalOrder())).thenComparing(Student::getAge)).collect(Collectors.toList()); System.out.println(list); 字符串日期排序\n写法一:\n1 2 //DateUtil.convertStringToDate为自封装的一个String转Date的方法 List\u0026lt;String\u0026gt; maxUpdateTime = updateTimeList.stream().sorted(Comparator.comparing(s -\u0026gt; DateUtil.convertStringToDate(s.toString(),\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;).getTime()).reversed()).collect(Collectors.toList()); 写法二：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 List\u0026lt;String\u0026gt; maxUpdateTime = updateTimeList.stream().sorted(new Comparator\u0026lt;String\u0026gt;() { @Override public int compare(String o1, String o2) { try { Date d1 = DateUtil.convertStringToDate(o1, \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); Date d2 = DateUtil.convertStringToDate(o2, \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); //正序 //return d1.compareTo(d2); //倒序 return d2.compareTo(d1); } catch (Exception e) { e.printStackTrace(); } return 0; } }).collect(Collectors.toList()); 对字段进行排序，考虑空值的其他写法\n请注意，根据单属性name进行排序，若需要将name为null的对象也参与排序，则需要：\n1 .sorted(Comparator.comparing(User::getName, Comparator.nullsLast((o1,o2)-\u0026gt;o1.compareTo(o2)))) 使用方法引用优化（注意name的类型是String）即为：\n1 voList = voList.stream().sorted(Comparator.comparing(User::getUserName,Comparator.nullsLast(String::compareTo))) .collect(Collectors.toList()); 参考：https://blog.csdn.net/weixin_45817985/article/details/129757307\n","date":"2023-09-07T00:00:00Z","permalink":"https://msdemt.github.io/p/java-stream-sort/","title":"java使用stream对日期进行排序"},{"content":" 删除除某个目录外的其他目录\n删除 /var/log 目录下除 slurm、mariadb 之外的其他文件\n1 find /var/log/* | grep -v -e slurm -e mariadb | xargs rm -rf grep -v 排除多个文件 https://geek-docs.com/linux/linux-basic/t_exclude-multiple-patterns-with-grep-on-linux.html\n查看当前目录下文件或文件夹体积\n1 du -ah --max-depth=1 ","date":"2023-09-07T00:00:00Z","permalink":"https://msdemt.github.io/p/linux-skills/","title":"linux 技巧"},{"content":" ius仓库不支持arm64架构\n使用github workflow流水线构建镜像时，若支持arm64架构，则构建镜像失败，github action workflow 如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 name: Docker Image CI on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: build: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 - name: Login to Docker Hub uses: docker/login-action@v2 with: username: ${{ secrets.DOCKERHUB_USERNAME }} password: ${{ secrets.DOCKERHUB_TOKEN }} - name: Set up QEMU uses: docker/setup-qemu-action@v2 - name: Set up Docker Buildx uses: docker/setup-buildx-action@v2 - name: Build and push uses: docker/build-push-action@v4 with: context: . file: ./Dockerfile platforms: | linux/amd64 linux/arm64 push: true tags: ${{ secrets.DOCKERHUB_USERNAME }}/centos7.9-slurm22:latest platforms里包含 linux/arm64 时，构建镜像失败\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026gt; [linux/arm64 2/7] RUN set -ex \u0026amp;\u0026amp; yum makecache fast \u0026amp;\u0026amp; yum -y update \u0026amp;\u0026amp; yum -y install https://repo.ius.io/ius-release-el7.rpm \u0026amp;\u0026amp; yum -y install munge munge-devel mariadb-server mariadb-devel mysql-devel gcc gcc-c++ python3 readline-devel perl-ExtUtils-MakeMaker pam-devel http-parser-devel json-c-devel libyaml-devel libjwt-devel wget git vim bzip2 make automake libtool supervisor psmisc openldap openldap-servers openldap-clients nss-pam-ldapd authconfig kde-l10n-Chinese glibc-common bash-completion openssh-server \u0026amp;\u0026amp; yum clean all \u0026amp;\u0026amp; rm -rf /var/cache/yum: 13528588.7 5. Configure the failing repository to be skipped, if it is unavailable. 13529588.7 Note that yum will try to contact the repo. when it runs most commands, 13530588.7 so will have to try and fail each time (and thus. yum will be be much 13531588.7 slower). If it is a very temporary problem though, this is often a nice 13532588.7 compromise: 13533588.7 13534588.7 yum-config-manager --save --setopt=ius.skip_if_unavailable=true 13535588.7 13536588.7 failure: repodata/repomd.xml from ius: [Errno 256] No more mirrors to try.13537 588.7 https://repo.ius.io/7/aarch64/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found ------ 13539Dockerfile:6 13540-------------------- 原因：ius仓库（https://repo.ius.io/ius-release-el7.rpm）不支持arm64架构， 解决：将workflow中的第31行 linux/arm64 删除\nERROR: failed to solve: circular dependency detected on stage: build\n原因： Dockerfile脚本问题，使用多阶段构建时，第二个FROM前面的语句末尾存在 \\\nDockerfile 构建时出现 command not found\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 $ cat Dockerfile FROM hekai/centos7.9-jdk8u202 RUN set -ex \\ \u0026amp;\u0026amp; yum makecache fast \\ \u0026amp;\u0026amp; yum -y update \\ \u0026amp;\u0026amp; yum -y install \\ mariadb-server \\ mariadb-devel \\ mysql-devel \\ \u0026amp;\u0026amp; yum clean all \\ \u0026amp;\u0026amp; rm -rf /var/cache/yum \\ # config mariadb \u0026amp;\u0026amp; sed -i \u0026#39;/\\[mysqld\\]/a\\innodb_buffer_pool_size=1024M\\ninnodb_log_file_size=64M\\ninnodb_lock_wait_timeout=900\u0026#39; /etc/my.cnf \\ \u0026amp;\u0026amp; /usr/bin/mysql_install_db --user=mysql \u0026amp;\u0026gt;/dev/null \\ \u0026amp;\u0026amp; /usr/bin/mysqld_safe --user=mysql \u0026amp; \u0026amp;\u0026gt;/dev/null \\ \u0026amp;\u0026amp; sleep 3s \\ \u0026amp;\u0026amp; mysql -e \u0026#34;CREATE USER \u0026#39;slurm\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;password\u0026#39;\u0026#34; \\ \u0026amp;\u0026amp; mysql -e \u0026#34;GRANT ALL ON slurm_acct_db.* to \u0026#39;slurm\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;password\u0026#39; with GRANT option\u0026#34; \\ \u0026amp;\u0026amp; mysql -e \u0026#34;CREATE DATABASE slurm_acct_db\u0026#34; CMD [\u0026#34;/bin/bash\u0026#34;] 构建镜像时出现错误\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 $ docker build -t mariadb:v1 -f Dockerfile.b . [+] Building 4.0s (5/5) FINISHED =\u0026gt; [internal] load build definition from Dockerfile.b 0.1s =\u0026gt; =\u0026gt; transferring dockerfile: 832B 0.0s =\u0026gt; [internal] load .dockerignore 0.1s =\u0026gt; =\u0026gt; transferring context: 109B 0.0s =\u0026gt; [internal] load metadata for docker.io/hekai/centos7.9-jdk8u202:latest 0.0s =\u0026gt; [1/2] FROM docker.io/hekai/centos7.9-jdk8u202 0.1s =\u0026gt; ERROR [2/2] RUN set -ex \u0026amp;\u0026amp; yum makecache fast \u0026amp;\u0026amp; yum -y update \u0026amp;\u0026amp; yum -y install mariadb-server ma 3.7s ------ \u0026gt; [2/2] RUN set -ex \u0026amp;\u0026amp; yum makecache fast \u0026amp;\u0026amp; yum -y update \u0026amp;\u0026amp; yum -y install mariadb-server mariadb-devel mysql-devel \u0026amp;\u0026amp; yum clean all \u0026amp;\u0026amp; rm -rf /var/cache/yum \u0026amp;\u0026amp; sed -i \u0026#39;/\\[mysqld\\]/a\\innodb_buffer_pool_size=1024M\\ninnodb_log_file_size=64M\\ninnodb_lock_wait_timeout=900\u0026#39; /etc/my.cnf \u0026amp;\u0026amp; /usr/bin/mysql_install_db --user=mysql \u0026amp;\u0026gt;/dev/null \u0026amp;\u0026amp; /usr/bin/mysqld_safe --user=mysql \u0026amp; \u0026amp;\u0026gt;/dev/null \u0026amp;\u0026amp; sleep 3s \u0026amp;\u0026amp; mysql -e \u0026#34;CREATE USER \u0026#39;slurm\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;password\u0026#39;\u0026#34; \u0026amp;\u0026amp; mysql -e \u0026#34;GRANT ALL ON slurm_acct_db.* to \u0026#39;slurm\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;password\u0026#39; with GRANT option\u0026#34; \u0026amp;\u0026amp; mysql -e \u0026#34;CREATE DATABASE slurm_acct_db\u0026#34;: #0 0.519 + yum makecache fast #0 1.193 Loaded plugins: fastestmirror, ovl #0 1.567 Determining fastest mirrors #0 2.744 * base: mirrors.huaweicloud.com #0 2.745 * extras: mirrors.huaweicloud.com #0 2.745 * updates: mirrors.huaweicloud.com #0 3.524 /bin/sh: mysql: command not found ------ Dockerfile.b:4 -------------------- 原因：可能是docker对RUN指令进行优化，解析到 mysql 指令时还未安装mysql\n解决：将mysql的安装和配置放在不同的RUN语句\n修改后如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 $ cat Dockerfile FROM hekai/centos7.9-jdk8u202 RUN set -ex \\ \u0026amp;\u0026amp; yum makecache fast \\ \u0026amp;\u0026amp; yum -y update \\ \u0026amp;\u0026amp; yum -y install \\ mariadb-server \\ mariadb-devel \\ mysql-devel \\ \u0026amp;\u0026amp; yum clean all \\ \u0026amp;\u0026amp; rm -rf /var/cache/yum \\ RUN sest -ex \\ # config mariadb \u0026amp;\u0026amp; sed -i \u0026#39;/\\[mysqld\\]/a\\innodb_buffer_pool_size=1024M\\ninnodb_log_file_size=64M\\ninnodb_lock_wait_timeout=900\u0026#39; /etc/my.cnf \\ \u0026amp;\u0026amp; /usr/bin/mysql_install_db --user=mysql \u0026amp;\u0026gt;/dev/null \\ \u0026amp;\u0026amp; /usr/bin/mysqld_safe --user=mysql \u0026amp; \u0026amp;\u0026gt;/dev/null \\ \u0026amp;\u0026amp; sleep 3s \\ \u0026amp;\u0026amp; mysql -e \u0026#34;CREATE USER \u0026#39;slurm\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;password\u0026#39;\u0026#34; \\ \u0026amp;\u0026amp; mysql -e \u0026#34;GRANT ALL ON slurm_acct_db.* to \u0026#39;slurm\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;password\u0026#39; with GRANT option\u0026#34; \\ \u0026amp;\u0026amp; mysql -e \u0026#34;CREATE DATABASE slurm_acct_db\u0026#34; CMD [\u0026#34;/bin/bash\u0026#34;] 构建镜像时出现错误，连不上mariadb\n1 ERROR 2002 (HY000): Can\u0026#39;t connect to local MySQL server through socket \u0026#39;/var/lib/mysql/mysql.sock\u0026#39; (2) 对应Dockerfile中的RUN指令\n1 2 3 4 5 6 7 8 9 10 11 12 13 RUN set -ex \\ ... ... # config mariadb \u0026amp;\u0026amp; sed -i \u0026#39;/\\[mysqld\\]/a\\innodb_buffer_pool_size=1024M\\ninnodb_log_file_size=64M\\ninnodb_lock_wait_timeout=900\u0026#39; /etc/my.cnf \\ \u0026amp;\u0026amp; /usr/bin/mysql_install_db --user=mysql \u0026amp;\u0026gt;/dev/null \\ \u0026amp;\u0026amp; /usr/bin/mysqld_safe --user=mysql \u0026amp; \u0026amp;\u0026gt;/dev/null \\ \u0026amp;\u0026amp; sleep 3s \\ \u0026amp;\u0026amp; mysql -e \u0026#34;CREATE USER \u0026#39;slurm\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;password\u0026#39;\u0026#34; \\ \u0026amp;\u0026amp; mysql -e \u0026#34;GRANT ALL ON slurm_acct_db.* to \u0026#39;slurm\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;password\u0026#39; with GRANT option\u0026#34; \\ \u0026amp;\u0026amp; mysql -e \u0026#34;CREATE DATABASE slurm_acct_db\u0026#34; \\ ... ... # clean \u0026amp;\u0026amp; rm -rf /var/log/* /var/cache/* /tmp/* sleep 设置了100s 也无法解决\n解决： 将mariadb单独抽出来，放在一个RUN中\n原因： 未知\n修改后如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 RUN set -ex \\ ... ... # clean \u0026amp;\u0026amp; rm -rf /var/log/* /var/cache/* /tmp/* RUN set -ex \\ # config mariadb \u0026amp;\u0026amp; sed -i \u0026#39;/\\[mysqld\\]/a\\innodb_buffer_pool_size=1024M\\ninnodb_log_file_size=64M\\ninnodb_lock_wait_timeout=900\u0026#39; /etc/my.cnf \\ \u0026amp;\u0026amp; /usr/bin/mysql_install_db --user=mysql \u0026amp;\u0026gt;/dev/null \\ \u0026amp;\u0026amp; /usr/bin/mysqld_safe --user=mysql \u0026amp; \u0026amp;\u0026gt;/dev/null \\ \u0026amp;\u0026amp; sleep 3s \\ \u0026amp;\u0026amp; mysql -e \u0026#34;CREATE USER \u0026#39;slurm\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;password\u0026#39;\u0026#34; \\ \u0026amp;\u0026amp; mysql -e \u0026#34;GRANT ALL ON slurm_acct_db.* to \u0026#39;slurm\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;password\u0026#39; with GRANT option\u0026#34; \\ \u0026amp;\u0026amp; mysql -e \u0026#34;CREATE DATABASE slurm_acct_db\u0026#34; 构建镜像出现错误，mysql启动失败\n1 2 3 4 5 6 7 8 9 10 11 \u0026gt; [stage-1 5/7] RUN set -ex \u0026amp;\u0026amp; sed -i \u0026#39;/\\[mysqld\\]/a\\innodb_buffer_pool_size=1024M\\ninnodb_log_file_size=64M\\ninnodb_lock_wait_timeout=900\u0026#39; /etc/my.cnf \u0026amp;\u0026amp; /usr/bin/mysql_install_db --user=mysql \u0026amp;\u0026gt;/dev/null \u0026amp;\u0026amp; /usr/bin/mysqld_safe --user=mysql \u0026amp; \u0026amp;\u0026gt;/dev/null \u0026amp;\u0026amp; sleep 3s \u0026amp;\u0026amp; mysql -e \u0026#34;CREATE USER \u0026#39;slurm\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;password\u0026#39;\u0026#34; \u0026amp;\u0026amp; mysql -e \u0026#34;GRANT ALL ON slurm_acct_db.* to \u0026#39;slurm\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;password\u0026#39; with GRANT option\u0026#34; \u0026amp;\u0026amp; mysql -e \u0026#34;CREATE DATABASE slurm_acct_db\u0026#34;: 257730.064 + sed -i \u0026#39;/\\[mysqld\\]/a\\innodb_buffer_pool_size=1024M\\ninnodb_log_file_size=64M\\ninnodb_lock_wait_timeout=900\u0026#39; /etc/my.cnf 257740.068 + /usr/bin/mysql_install_db --user=mysql 257750.251 + /usr/bin/mysqld_safe --user=mysql 257760.355 230905 03:18:57 mysqld_safe Logging to \u0026#39;/var/log/mariadb/mariadb.log\u0026#39;. 257770.386 230905 03:18:57 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql 257780.390 /usr/bin/mysqld_safe_helper: Can\u0026#39;t create/write to file \u0026#39;/var/log/mariadb/mariadb.log\u0026#39; (Errcode: 2) 257793.072 ERROR 2002 (HY000): Can\u0026#39;t connect to local MySQL server through socket \u0026#39;/var/lib/mysql/mysql.sock\u0026#39; (2) 25780------ 25781Dockerfile.2:141 25782-------------------- 原因是删掉了/var/log/mariadb目录，清理日志文件时，保留 mariadb 目录\n1 find /var/log/* | grep -v -e mariadb | xargs rm -rf 配置slurm\nslurm配置命令如下\n1 2 ./configure --prefix=/opt/slurm --sysconfdir=/opt/slurm/etc --enable-slurmrestd --with-mysql_config=/usr/bin --libdir=/usr/lib64 make install 安装时会将slurm的动态库文件放在 /usr/lib64/slurm下\n如果配置时不指定\u0026ndash;libdir，则会将动态库安装到prefix指定的目录下\n1 2 ./configure --prefix=/opt/slurm --sysconfdir=/opt/slurm/etc --enable-slurmrestd --with-mysql_config=/usr/bin 此时会将动态库安装到 /opt/slurm/lib64下\n为了正常使用动态库，需要将/opt/slurm/lib64的动态库链接到/usr/lib64下\n1 ln -s /opt/slurm/lib64 /usr/lib64/slurm 支持killall命令\n1 /usr/local/bin/docker-entrypoint.sh: line 77: killall: command not found 解决：安装 psmisc\n1 yum install -y psmisc centos7精简版（minimal）运行killall命令提示 command not found\n是由于没有安装psmisc所致，psmisc软件包包含三个帮助管理/proc目录的程序。\nfuser, killall,pstree和pstree.x11(到pstree的链接)\nfuser 显示使用指定文件或者文件系统的进程的PID。 killall 杀死某个名字的进程，它向运行指定命令的所有进程发出信号。 pstree 树型显示当前运行的进程。 pstree.x11 与pstree功能相同，只是在退出前需要确认。 安装git IDEA进入docker容器进行远程开发 提示：\n1 2 Unsupported Git Version 1.8.3.1 At least 2.17.0 is required 需要对yum源中的git进行升级\n在 centos7.9 的 docker 镜像中，是没有 git 的，所以有两种方式\n编译安装新版本 git 安装 yum 源中的 git \u0026gt; 2.17.0 的版本 IUS yum源中提供了 git 2.36.6 版本 注：安装 IUS yum 源时会自动安装 epel 源 安装 IUS 源： yum -y install https://repo.ius.io/ius-release-el7.rpm 查看 git ：yum search git|grep -E \u0026quot;^git\u0026quot; 查看 git 版本： yum info git236 安装 git 236 版本：yum -y install git236 endpoint yum源中提供了最新版本的 git 安装 endpoint 源：yum install https://packages.endpointdev.com/rhel/7/os/x86_64/endpoint-repo.x86_64.rpm 安装 git: yum -y install git 编译安装python3 https://www.jianshu.com/p/2cad40bc9e1b\n1 2 3 4 5 6 7 curl -O https://www.python.org/ftp/python/3.7.14/Python-3.7.14.tar.xz tar -xf Python-3.7.14.tar.xz cd Python-3.7.14 yum -y install make yum-builddep -y python ./configure --prefix=/opt/tools/python-3.7.14 make \u0026amp;\u0026amp; make install docker compose 挂root目录，导致环境变量无效\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 $ cat docker-compose.yml version: \u0026#39;3\u0026#39; services: slurm-master: image: hekai/centos7.9-slurm22 hostname: linux0 privileged: true stdin_open: true restart: always tty: true ports: - 389:389 - 6820:6820 environment: role: \u0026#34;master\u0026#34; TZ: Asia/Shanghai volumes: - .root:/root - .data/log:/var/log/slurm - etc_munge:/etc/munge - etc_slurm:/etc/slurm - spool_slurm:/var/spool/slurm - mysql:/var/lib/mysql slurm-compute-1: image: hekai/centos7.9-slurm22 hostname: linux1 privileged: true stdin_open: true restart: always tty: true environment: role: \u0026#34;compute\u0026#34; TZ: Asia/Shanghai volumes: - .data/log:/var/log/slurm - etc_munge:/etc/munge - etc_slurm:/etc/slurm depends_on: - \u0026#34;slurm-master\u0026#34; volumes: etc_munge: etc_slurm: spool_slurm: mysql: 如上，slurm-master 节点挂在了容器内的 /root 到本地，进入容器后，发现构建镜像时设置的环境变量没有了，在容器中执行下 source /etc/profile，然后可以将在 /etc/profile.d/jdk.sh 中定义的变量加载出来了\n在Dockerfile中添加 source /etc/profile 命令，无法解决 在entrypoint.sh中添加 source /etc/profile 命令，无法解决 不直接挂载容器中 /root，将/root下需要的文件单独挂载出来，可以解决该问题 希望先查ldap中的用户，若ldap中不存在，再查linux系统用户\n实现这种方案，需要修改 /etc/nsswitch.conf 中 passwprd、shadow、group 属性对应值的顺序\n怎么优雅地修改这些属性值呢？\n搜索了下，linux好像没有提供命令修改这些值的顺序，只能通过修改文本的方式 使用sed命令修改nsswitch.conf 中的用户搜索顺序\n1 2 3 sed -i \u0026#39;s/passwd: files ldap/passwd: ldap files/g\u0026#39; ./nsswitch.conf sed -i \u0026#39;s/shadow: files ldap/shadow: ldap files/g\u0026#39; ./nsswitch.conf sed -i \u0026#39;s/group: files ldap/group: ldap files/g\u0026#39; ./nsswitch.conf 参考：\nhttps://serverfault.com/questions/972401/try-ldap-authentication-before-local-authentication https://documents.uow.edu.au/~blane/netapp/ontap/nag/networking/concept/c_oc_netw_maintaining_host_name_search.html#c_oc_netw_maintaining_host_name_search\nhttps://superuser.com/questions/1417190/ why-do-i-need-to-change-the-order-of-hosts-in-nsswitch-conf\nhttps://man7.org/linux/man-pages/man5/nsswitch.conf.5.html\nhttps://unix.stackexchange.com/questions/140378/editing-nsswitch-conf-file-safely\n","date":"2023-09-07T00:00:00Z","permalink":"https://msdemt.github.io/p/docker-build-slurm/","title":"使用docker构造slurm镜像问题汇总"},{"content":"介绍 在不支持 cpu 虚拟化的 ubuntu 18.04 云主机上安装 vagrant + virtualbox，实现创建虚拟机实例。\n安装 virtualbox 参考： https://forums.virtualbox.org/viewtopic.php?t=108215\nvirtualbox 6 及以上版本开始依赖cpu虚拟化，如 vt-x，所以需要安装 virtualbox 5 版本\nvirtualbox 5 下载地址：https://www.virtualbox.org/wiki/Download_Old_Builds_5_2\n下载安装 virtualbox 5.2.44 deb 包后，右键使用ubuntu软件中心安装。\n卸载 virtualbox (ubuntu 软件中心中找不到已安装的virturalbox)\n1 sudo apt remove virtualbox virtualbox-* 安装 vagrant 参考：\nhttps://developer.hashicorp.com/vagrant/downloads\nhttps://stackoverflow.com/questions/24620599/error-vt-x-not-available-for-vagrant-machine-inside-virtualbox\n下载安装 vagrant\n1 2 3 wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg echo \u0026#34;deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\u0026#34; | sudo tee /etc/apt/sources.list.d/hashicorp.list sudo apt update \u0026amp;\u0026amp; sudo apt install vagrant 新建工作目录\n1 mkdir ~/vagrant-test 执行 vagrant init 命令初始化 VagrantFile，因为需要使用32位系统镜像，所以指定了 jasonc/centos7-32bit\n1 vagrant init jasonc/centos7-32bit jasonc/centos7-32bit 镜像地址 https://app.vagrantup.com/jasonc/boxes/centos7-32bit\n执行后，会生成 VagrantFile 文件\n修改 VagrantFile，配置 cpu 和 内存\n1 2 3 4 5 6 7 8 9 10 11 12 13 # -*- mode: ruby -*- # vi: set ft=ruby : Vagrant.configure(\u0026#34;2\u0026#34;) do |config| config.vm.box = \u0026#34;jasonc/centos7-32bit\u0026#34; config.vm.provider \u0026#34;virtualbox\u0026#34; do |v| v.memory = 1024 v.cpus = 1 end end 执行 vagrant up 命令，启动虚拟机实例\n1 vagrant up 进入虚拟机实例\n1 vagrant ssh 关闭虚拟机实例\n1 vagrant halt 销毁虚拟机实例\n1 vagrant destroy 查看已下载的镜像（box）\n1 vagrant box list vagrant 镜像查询：https://app.vagrantup.com\n错误汇总 无法启动 centos7 1 2 vagrant init centos/7 vagrant up 出现错误\n1 2 3 4 5 6 7 There was an error while executing `VBoxManage`, a CLI used by Vagrant for controlling VirtualBox. The command and stderr is shown below. Command: [\u0026#34;startvm\u0026#34;, \u0026#34;328357ce-9204-4c53-bbd1-279427c5350b\u0026#34;, \u0026#34;--type\u0026#34;, \u0026#34;headless\u0026#34;] Stderr: VBoxManage: error: VT-x is not available (VERR_VMX_NO_VMX) VBoxManage: error: Details: code NS_ERROR_FAILURE (0x80004005), component ConsoleWrap, interface IConsole virtual + vagrant 在没有vt-x的环境只能运行1核32位的系统。 https://app.vagrantup.com/jasonc/boxes/centos7-32bit\nvagrant 配置cpu和内存 https://talk.ninghao.net/t/vagrant-ru-he-pei-zhi-shi-yong-cpu-he-xin-yu-nei-cun/597/3\n启动vagrant实例时出现错误，找不到具体原因 启动虚拟机实例时超时，实例启动失败\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 default: SSH auth method: private key Timed out while waiting for the machine to boot. This means that Vagrant was unable to communicate with the guest machine within the configured (\u0026#34;config.vm.boot_timeout\u0026#34; value) time period. If you look above, you should be able to see the error(s) that Vagrant had when attempting to connect to the machine. These errors are usually good hints as to what may be wrong. If you\u0026#39;re using a custom box, make sure that networking is properly working and you\u0026#39;re able to connect to the machine. It is a common problem that networking isn\u0026#39;t setup properly in these boxes. Verify that authentication configurations are also setup properly, as well. If the box appears to be booting properly, you may want to increase the timeout (\u0026#34;config.vm.boot_timeout\u0026#34;) value. 找不到原因，是因为看不到虚拟机的启动过程。在Vagrantfile中的最后一个end前面加入：\n1 2 3 config.vm.provider \u0026#34;virtualbox\u0026#34; do |vb| vb.gui = true end 然后删掉目录下的.vagrant文件，命令行窗口重新运行 vagrant up 命令，这时就可以看到启动过程中到底哪里出了问题了。 我的启动卡在 default: SSH auth method: private key 的原因是 “VT-x/AMD-V 硬件加速在您的系统中不可用”，到BIOS中找到对应选项修改成enabled 就可以了。\n参考： https://zhuanlan.zhihu.com/p/49538228\nhttps://blog.csdn.net/m0_50546016/article/details/119176009\nhttps://jimmysong.io/blog/vagrant-intro/\n","date":"2023-08-27T00:00:00Z","permalink":"https://msdemt.github.io/p/ubuntu-install-vagrant/","title":"ubuntu18.04安装vagrant记录"},{"content":"介绍 minikube 是适合开发人员的迷你版 k8s，本文在 ubuntu 18.04 上安装 minikube。\n安装minikube To install the latest minikube stable release on x86-64 Linux using binary download:\n1 2 curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 sudo install minikube-linux-amd64 /usr/local/bin/minikube 启动minikube\nFrom a terminal with administrator access (but not logged in as root), run:\n1 minikube start If minikube fails to start, see the drivers page for help setting up a compatible container or virtual-machine manager.\n安装kubectl 用以下命令下载最新 kubectl 发行版\n1 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; 安装 kubectl\n1 sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl 测试\n1 kubectl version --client 操作 使用 kubectl 查看所有命名空间的 pod\n1 kubectl get po -A minikube 集成了 kubernetes dashboard，使用如下命令开启访问 dashboard\n1 minikube dashboard 查看 minikube 版本\n1 minikube version 部署服务 k8s 有三种暴露服务的方式：NodePort, LoadBalancer, Ingress，分别介绍使用minikube 安装暴露服务\nService Create a sample deployment and expose it on port 8080:\n1 2 kubectl create deployment hello-minikube --image=kicbase/echo-server:1.0 kubectl expose deployment hello-minikube --type=NodePort --port=8080 It may take a moment, but your deployment will soon show up when you run:\n1 kubectl get services hello-minikube The easiest way to access this service is to let minikube launch a web browser for you:\n1 minikube service hello-minikube Alternatively, use kubectl to forward the port:\n1 kubectl port-forward service/hello-minikube 7080:8080 Tada! Your application is now available at http://localhost:7080/.\nYou should be able to see the request metadata in the application output. Try changing the path of the request and observe the changes. Similarly, you can do a POST request and observe the body show up in the output.\nLoadBalancer To access a LoadBalancer deployment, use the “minikube tunnel” command. Here is an example deployment:\n1 2 kubectl create deployment balanced --image=kicbase/echo-server:1.0 kubectl expose deployment balanced --type=LoadBalancer --port=8080 In another window, start the tunnel to create a routable IP for the ‘balanced’ deployment:\n1 minikube tunnel To find the routable IP, run this command and examine the EXTERNAL-IP column:\n1 kubectl get services balanced Your deployment is now available at \u0026lt;EXTERNAL-IP\u0026gt;:8080\nIngress Enable ingress addon:\n1 minikube addons enable ingress The following example creates simple echo-server services and an Ingress object to route to these services.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 kind: Pod apiVersion: v1 metadata: name: foo-app labels: app: foo spec: containers: - name: foo-app image: \u0026#39;kicbase/echo-server:1.0\u0026#39; --- kind: Service apiVersion: v1 metadata: name: foo-service spec: selector: app: foo ports: - port: 8080 --- kind: Pod apiVersion: v1 metadata: name: bar-app labels: app: bar spec: containers: - name: bar-app image: \u0026#39;kicbase/echo-server:1.0\u0026#39; --- kind: Service apiVersion: v1 metadata: name: bar-service spec: selector: app: bar ports: - port: 8080 --- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: example-ingress spec: rules: - http: paths: - pathType: Prefix path: /foo backend: service: name: foo-service port: number: 8080 - pathType: Prefix path: /bar backend: service: name: bar-service port: number: 8080 --- Apply the contents\n1 kubectl apply -f https://storage.googleapis.com/minikube-site-examples/ingress-example.yaml Wait for ingress address\n1 2 3 kubectl get ingress NAME CLASS HOSTS ADDRESS PORTS AGE example-ingress nginx * \u0026lt;your_ip_here\u0026gt; 80 5m45s Note for Docker Desktop Users:\nTo get ingress to work you’ll need to open a new terminal window and run minikube tunnel and in the following step use 127.0.0.1 in place of \u0026lt;ip_from_above\u0026gt;.\nNow verify that the ingress works\n1 2 3 4 5 6 7 $ curl \u0026lt;ip_from_above\u0026gt;/foo Request served by foo-app ... $ curl \u0026lt;ip_from_above\u0026gt;/bar Request served by bar-app ... 管理minikube Pause Kubernetes without impacting deployed applications:\n1 minikube pause Unpause a paused instance:\n1 minikube unpause Halt the cluster:\n1 minikube stop Change the default memory limit (requires a restart):\n1 minikube config set memory 9001 Browse the catalog of easily installed Kubernetes services:\n1 minikube addons list Create a second cluster running an older Kubernetes release:\n1 minikube start -p aged --kubernetes-version=v1.16.1 Delete all of the minikube clusters:\n1 minikube delete --all 参考：\nhttps://kubernetes.io/zh-cn/docs/tutorials/hello-minikube/\nhttps://minikube.sigs.k8s.io/docs/start/\nhttps://kubernetes.io/zh-cn/docs/tasks/tools/#kubectl\nhttps://kubernetes.io/zh-cn/docs/tasks/tools/install-kubectl-linux/#install-kubectl-binary-with-curl-on-linux\n","date":"2023-08-27T00:00:00Z","permalink":"https://msdemt.github.io/p/ubuntu-minikube/","title":"ubuntu安装minikube"},{"content":"介绍 因为云主机，不支持 cpu 虚拟化（如：vt-x），但是我希望在上面运行虚拟机，所以进行了此次探索。\n因为不支持 cpu 虚拟化，所以只能运行 32位 的系统\nvmware 在不支持 cpu 虚拟化的环境，vmware 最高可以使用vmware 10.0.7 版本安装centos 6.10 i386及以下的32位系统，也支持 ubuntu 13.10 i386 及以下的32位系统\n其中ubuntu系统安装后桌面上无法显示图标，网上资料说重新安装ubuntu-desktop，但是找不到相关包，并且无法使用apt-get install。\ncentos 6.10 特点如下：\n缺点：卡，无法流畅使用\n优点：cpu支持多核，4核可以运行；内存支持4GB；安装tools后可以支持全屏。\nvirtualbox 使用virtualbox 5.2.44 可以安装 centos 7.4 i386 及以下的32位系统\n缺点：卡，cpu只能1核，内存最大3500MB，安装tools后无法全屏，无法正常使用。\nvagrant + virtualbox 使用 vagrant 结合 virtualbox 可以在后台运行虚拟机实例，但是只能运行 32位 且 cpu核数为1核的虚拟机。\nVagrantFile 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # -*- mode: ruby -*- # vi: set ft=ruby : Vagrant.configure(\u0026#34;2\u0026#34;) do |config| config.vm.box = \u0026#34;jasonc/centos7-32bit\u0026#34; config.vm.provider \u0026#34;virtualbox\u0026#34; do |v| v.memory = 1024 v.cpus = 1 end end 执行 vagrant up ，启动虚拟机实例\n执行 vagrant ssh 进入虚拟机\n相关下载 vmware workstation 10.0.7 下载地址： https://download3.vmware.com/software/wkst/file/VMware-workstation-full-10.0.7-2844087.exe\nvmware workstation 10 激活序列号：\n1 JZ6WK-4529P-HZAA1-9RAG6-33JNR 1 5F4EV-4Z0DP-XZHN9-0L95H-02V17 virtualbox 5.2.44 下载地址： https://www.virtualbox.org/wiki/Download_Old_Builds_5_2\ncentos 6.10 i386 下载地址： http://mirrors.aliyun.com/centos-vault/6.10/isos/i386/\ncentos7.4 i386 下载地址： https://mirrors.tripadvisor.com/centos-vault/altarch/\nubuntu 13.10 i386 下载地址： https://old-releases.ubuntu.com/releases/\n参考：\nhttps://forums.linuxmint.com/viewtopic.php?t=337186\nhttps://forums.virtualbox.org/viewtopic.php?t=108215\nhttps://stackoverflow.com/questions/24620599/error-vt-x-not-available-for-vagrant-machine-inside-virtualbox\n","date":"2023-08-27T00:00:00Z","permalink":"https://msdemt.github.io/p/without-cpu-virtualization/","title":"不支持cpu虚拟化环境运行虚拟机的探索"},{"content":"介绍 中央仓库就是 Maven 的一个默认的远程仓库，Maven 的安装文件中自带了中央仓库的配置($M2_HOME/lib/maven-model-builder.jar)\n在很多情况下，默认的中央仓库无法满足项目的需求，这时就需要在pom.xml文件中配置仓库，在pom文件中的配置仅对当前项目有效\n避免代码重复性，减少冗余，可在 settings.xml 文件中配置 settings.xml文件中配置可参考：https://developer.aliyun.com/mvn/guide\n注意：Maven 自带的中央仓库使用的Id为central 如果其他的仓库声明也是用该Id就会覆盖中央仓库的配置\n在maven的settings.xml中配置 对使用该maven的所有项目有效\n打开 maven 的配置文件（ windows 机器一般在 maven 安装目录的 conf/settings.xml ），在\u0026lt;mirrors\u0026gt;\u0026lt;/mirrors\u0026gt;标签中添加 mirror 子节点:\n1 2 3 4 5 6 \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;aliyunmaven\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;*\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;阿里云公共仓库\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://maven.aliyun.com/repository/public\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; 如果想使用其它代理仓库，可在\u0026lt;repositories\u0026gt;\u0026lt;/repositories\u0026gt;节点中加入对应的仓库使用地址。以使用 central 代理仓为例：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;central\u0026lt;/id\u0026gt; \u0026lt;url\u0026gt;https://maven.aliyun.com/repository/central\u0026lt;/url\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/repository\u0026gt; 在项目根目录下的pom.xml中配置 只对本项目有效\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;public\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;aliyun nexus\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://maven.aliyun.com/nexus/content/groups/public/\u0026lt;/url\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; \u0026lt;pluginRepositories\u0026gt; \u0026lt;pluginRepository\u0026gt; \u0026lt;id\u0026gt;public\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;aliyun nexus\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://maven.aliyun.com/nexus/content/groups/public/\u0026lt;/url\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/pluginRepository\u0026gt; \u0026lt;/pluginRepositories\u0026gt; 问题：\n当url为http时出现如下错误：\n1 2 3 4 5 6 7 8 Blocked mirror for repositories: [public (http://maven.aliyun.com/nexus/content/groups/public/, default, releases+snapshots)] Since Maven 3.8.1 http repositories are blocked. Possible solutions: - Check that Maven pom files do not contain http repository http://maven.aliyun.com/nexus/content/groups/public/ - Add a mirror(s) for http://maven.aliyun.com/nexus/content/groups/public/ that allows http url in the Maven settings.xml - Downgrade Maven to version 3.8.1 or earlier in settings 将http改为https\n参考：\nhttps://developer.aliyun.com/mvn/guide\nhttps://www.cnblogs.com/h-c-g/p/9928658.html\n","date":"2023-08-24T00:00:00Z","permalink":"https://msdemt.github.io/p/maven-repo-aliyun/","title":"maven配置阿里云仓库"},{"content":"配置 nginx 支持 websockt，需要添加如下配置\n1 2 3 proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#39;upgrade\u0026#39;; nginx 配置文件修改之前（反向代理后端服务）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ sudo cat /etc/nginx/conf.d/manager.conf server { listen 16002; server_name _; charset utf-8; root /root/manager/dist; location /api { proxy_pass http://192.168.120.10:16002; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } nginx 支持后端 websocket （websocket地址： ws://192.168.120.10:16002/api/webssh），配置如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 $ sudo cat /etc/nginx/conf.d/manager.conf server { listen 16002; server_name _; charset utf-8; root /root/manager/dist; proxy_set_header X-Real_IP $remote_addr; proxy_set_header Host $host:$server_port; proxy_set_header X_Forward_For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#39;upgrade\u0026#39;; location /api { proxy_pass http://192.168.120.10:16002; } } proxt_http_version 1.1;: 表示反向代理发送的HTTP协议的版本是1.1,HTTP1.1支持长连接 proxy_set_header Upgrade $http_upgrade;和 proxy_set_header Connection \u0026quot;upgrade\u0026quot;;: 表示 websocket 连接进入的时候，将一个 http 连接升级为 websocket 连接 标准配置 根据 http://nginx.org/en/docs/http/websocket.html 编写一份标准配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 map $http_upgrade $connection_upgrade { default upgrade; \u0026#39;\u0026#39; close; } upstream wsbackend{ server ip1:port1; server ip2:port2; keepalive 1000; } server { listen 20038; location /{ proxy_http_version 1.1; proxy_pass http://wsbackend; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_read_timeout 3600s; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; } } 其中，\n1 2 3 4 map $http_upgrade $connection_upgrade { default upgrade; \u0026#39;\u0026#39; close; } 表示：\n如果 $http_upgrade 不为 \u0026rsquo;\u0026rsquo; (空),则 $connection_upgrade 为 upgrade 如果 $http_upgrade 为 \u0026rsquo;\u0026rsquo; (空),则 $connection_upgrade 为 close 1 2 3 4 5 upstream wsbackend{ server ip1:port1; server ip2:port2; keepalive 1000; } 表示 nginx 负载均衡\n负载两台服务器（ip1:port1）和（ip2:port2） keepalive 1000 表示的是每个nginx进程中上游服务器保持的空闲连接,当空闲连接过多时,会关闭最少使用的空闲连接.当然,这不是限制连接总数的,可以想象成空闲连接池的大小.设置的值应该是上游服务器能够承受的 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 server { listen 80; location /{ proxy_http_version 1.1; proxy_pass http://wsbackend; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_read_timeout 3600s; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; } } 表示的是监听的服务器的配置\nlisten 80 表示 nginx 监听的端口 locations / 表示监听的路径(/表示所有路径,通用匹配,相当于default) proxt_http_version 1.1 表示反向代理发送的HTTP协议的版本是1.1,HTTP1.1支持长连接 proxy_pass http://wsbackend; 表示反向代理的uri,这里可以使用负载均衡变量 proxy_redirect off; 表示不要替换路径,其实这里如果是/则有没有都没关系,因为default也是将路径替换到proxy_pass的后边 proxy_set_header Host $host; 表示传递时请求头不变, $host是nginx内置变量,表示的是当前的请求头,proxy_set_header表示设置请求头 proxy_set_header X-Real-IP $remote_addr; 表示传递时来源的ip还是现在的客户端的ip proxy_read_timeout 3600s; 表示两次请求之间的间隔超过 3600s 后才关闭这个连接,默认的60s.自动关闭的元凶 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 表示X-Forwarded-For头不发生改变 proxy_set_header Upgrade $http_upgrade; 表示设置Upgrade不变 proxy_set_header Connection $connection_upgrade; 表示如果 $http_upgrade为upgrade,则请求为upgrade(websocket),如果不是,就关闭连接 简化版本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 http { map $http_upgrade $connection_upgrade { default upgrade; \u0026#39;\u0026#39; close; } server { ... location /chat/ { proxy_pass http://backend; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; } } } 问题 Nginx代理webSocket经常出现中断的解决方案, 如何保持长连接 原因： nginx等待客户端第一次通讯和第二次通讯的时间差，超过了它设定的最大等待时间，简单来说就是，超时，所以就断了webSocket连接。\n解决方案一\n配置nginx.conf的对应localhost里面的这几个参数\n1 2 3 proxy_connect_timeout proxy_read_timeout proxy_send_timeout 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 http { server { location / { root html; index index.html index.htm; proxy_pass http://webscoket; proxy_http_version 1.1; proxy_connect_timeout 4s; #配置点1 proxy_read_timeout 60s; #配置点2，如果没效，可以考虑这个时间配置长一点 proxy_send_timeout 12s; #配置点3 proxy_set_header Upgrade $http_upgrade; #这是webSocket的配置，与此解决方案无关 proxy_set_header Connection \u0026#34;Upgrade\u0026#34;; #这是webSocket的配置，与此解决方案无关 } } } 配置点2: 这个是服务器对客户端等待最大的时间，也就是说，当webSocket使用nginx转发的时候，对于上面的配置点2来说，如果60秒内没有通讯，依然是会断开的，所以，你可以按照你的需求来设定。\n解决方案二\n发心跳包，原理就是在有效的再读时间内进行通讯，重新刷新再读时间\n参考：\nhttps://www.jianshu.com/p/6205c8769e3c\nhttp://nginx.org/en/docs/http/websocket.html\n","date":"2023-08-24T00:00:00Z","permalink":"https://msdemt.github.io/p/nginx-websocket/","title":"nginx配置websocket"},{"content":"介绍 Bash case 语句是具有许多 ELIF 元素的 IF-THEN-ELSE 的最简单形式。使用 case 语句使 bash 脚本更具可读性，并且更易于维护。它通常用于简化具有多种不同选择的复杂条件。 Bash case 语句遵循与 Javascript 或 C 语言中的switch 语句类似的逻辑。但是又略有不同，如下所示：\nBash case 语句只接受一次值，然后多次测试该值。一旦找到模式就执行与其链接的语句，它将停止搜索模式，这与 C switch 语句几乎相反。\n语法 bash case 语句的语法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 case expression in pattern_1) statements ;; pattern_2) statements ;; pattern_3|pattern_4|pattern_5) statements ;; pattern-n) statements ;; *) statements ;; esac bash case 语句的一些重要说明：\nbash 中的每个 case 语句均以 case 关键字开头，后接 case 表达式和 in 关键字。使用 esac 关键字关闭 case 语句。 可以使用以 | 分隔的多个模式运算符，运算符 ) 表示模式列表的终止。包含语句的模式称为子句，并且必须以双分号(;;)终止。星号(*)用作定义默认情况的最终模式。当用作最后一种情况时，它用作默认情况。 子句中如果使用冒号 : ，表示空命令，不执行任何操作 首先，case 语句扩展表达式并尝试与每个包含的模式匹配。找到匹配项后，将执行所有链接的语句，直到双分号(;;)为止。在第一个匹配项之后，case 以最后执行的语句的退出状态终止。如果没有匹配的模式，则 case 的退出状态为零。否则，返回状态是已执行语句的退出状态。如果使用默认的星号(*)模式，则在没有匹配模式的情况下将执行它。下面通过一些示例来了解这种机制：\n示例 使用 case 语句解决执行两次 source /etc/profile 后，$PATH 出现重复数据的问题\n1 2 3 4 case \u0026#34;:$PATH:\u0026#34; in *\u0026#34;:$new_entry:\u0026#34;*) :;; # already there *) PATH=\u0026#34;$new_entry:$PATH\u0026#34;;; # or PATH=\u0026#34;$PATH:$new_entry\u0026#34; esac 参考：\nhttps://www.yiibai.com/bash/bash-case-statement.html\nhttps://www.cnblogs.com/ChinaGo/p/9910747.html\nhttps://unix.stackexchange.com/questions/14895/duplicate-entries-in-path-a-problem\n","date":"2023-08-17T00:00:00Z","permalink":"https://msdemt.github.io/p/bash-case/","title":"Bash case 语句"},{"content":"介绍 在 linux(centos、ubuntu\u0026hellip;) 上tar包解压方式安装 jdk1.8.0_202\n安装 下载 jdk1.8.0_202\njdk-8u202下载\n解压 tar 到指定目录\n1 sudo tar -zxf jdk-8u202-linux-x64.tar.gz -C /usr/local 创建软链接，方便以后更换 jdk 版本\n1 sudo ln -s /usr/local/jdk1.8.0_202 /usr/local/jdk 添加环境变量配置 新建 jdk 环境变量文件 /etc/profile.d/jdk.sh\n1 sudo touch /etc/profile.d/jdk.sh 添加如下内容\n1 2 3 4 5 6 7 #!/bin/bash export JAVA_HOME=/usr/local/jdk export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar case \u0026#34;:$PATH:\u0026#34; in *\u0026#34;:$JAVA_HOME/bin:\u0026#34;*) :;; # already there *) PATH=\u0026#34;$JAVA_HOME/bin:$PATH\u0026#34;;; # or PATH=\u0026#34;$PATH:$new_entry\u0026#34; esac 注意：/etc/profile.d/jdk.sh 文件权限应该为 644\n更新当前 shell 环境变量\n1 source /etc/profile 参考：\nhttps://unix.stackexchange.com/questions/14895/duplicate-entries-in-path-a-problem\n","date":"2023-08-17T00:00:00Z","permalink":"https://msdemt.github.io/p/install-java/","title":"linux 安装 java"},{"content":"介绍 ubuntu 18.04 重装后，记录下必需软件的安装过程\n配置root用户密码 ubuntu 安装后，默认 root 用户没有密码，无法执行 su - root 切换到 root 用户，配置 root 用户密码\n1 sudo passwd root 密码配置成功后，就可以执行 su - root 切换到 root 用户了\n配置普通用户sudo免密 方法一： 在 /etc/sudoers.d/ 文件夹下新建文件，如 custom ，文件中添加如下内容\n1 username ALL=(ALL) NOPASSWD:ALL 方法二： sudo 相关的配置位于 /etc/sudoers 文件内，这个文件不建议直接编辑，而是使用以下命令\n1 sudo visudo 该命令会打开默认的编辑器编辑 /etc/sudoers 文件，并在保存时自动检查文件格式并设置到正确的文件权限。\n进入编辑状态后，在文件的最后面 添加以下内容\n1 username ALL=(ALL) NOPASSWD:ALL username 改成自己的用户名\n配置自动登录 打开 ubuntu desktop 后，自动登录到桌面，避免每次输入密码\nubuntu -\u0026gt; 设置 -\u0026gt; 详细信息 -\u0026gt; 用户 -\u0026gt; 开启 自动登录\n挂载磁盘 执行 fdisk -l 查看可用的磁盘\n/dev/vdb 是额外可用的磁盘，将该磁盘挂载到 /opt 目录下\n卸载 /dev/vdb 目前的挂载位置 1 sudo umount /dev/vdb 编辑 /etc/fstab，添加或修改 /dev/vdb的挂载，该文件也可以让磁盘开机自动挂载 1 2 3 sudo vi /etc/fstab # 新增或修改磁盘挂载 /dev/vdb /opt ext4 defaults,nofail 0 2 创建 /opt 目录 1 sudo touch /opt 将 /etc/fstab 中定义的所有磁盘系统挂上 1 sudo mount -a 修改家目录为英文 默认家目录下的文件夹名称为中文，现将中文名称改为英文名称\n方法一：\n终端执行\n1 2 export LANG=en_US xdg-user-dirs-gtk-update 执行后，会弹出更换文件夹名称提示，选择 Update Names，将文件夹名称改为英文\n再执行\n1 2 export LANG=zh_CN.UTF-8 xdg-user-dirs-gtk-update 再次弹出更换文件夹名称提示，选择保留旧的名称，并选上不要再次询问我（下次开机的时候，就不会再次询问了）\n重启。\n方法二：\n修改配置文件 ~/.config/user-dirs.dirs ，将对应的路径改为英文名\n1 2 3 4 5 6 7 8 XDG_DESKTOP_DIR=\u0026#34;$HOME/Desktop\u0026#34; XDG_DOWNLOAD_DIR=\u0026#34;$HOME/Download\u0026#34; XDG_TEMPLATES_DIR=\u0026#34;$HOME/Template\u0026#34; XDG_PUBLICSHARE_DIR=\u0026#34;$HOME/Public\u0026#34; XDG_DOCUMENTS_DIR=\u0026#34;$HOME/Document\u0026#34; XDG_MUSIC_DIR=\u0026#34;$HOME/Music\u0026#34; XDG_PICTURES_DIR=\u0026#34;$HOME/Picture\u0026#34; XDG_VIDEOS_DIR=\u0026#34;$HOME/Video\u0026#34; 重启。\n安装docker 参考：\nhttps://docs.docker.com/engine/install/ubuntu/\nhttps://docs.docker.com/compose/install/linux/#install-the-plugin-manually\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 sudo apt-get remove docker docker-engine docker.io containerd runc sudo apt-get update sudo apt-get install \\ ca-certificates \\ curl \\ gnupg sudo mkdir -m 0755 -p /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg echo \\ \u0026#34;deb [arch=\u0026#34;$(dpkg --print-architecture)\u0026#34; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ \u0026#34;$(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;)\u0026#34; stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 修改docker存储路径 参考：\nhttps://blog.csdn.net/m0_58684193/article/details/127554527\ndocker数据默认存放在 /var/lib/docker 下，修改docker数据存储路径，将其放到容量大的磁盘中\n新建docker数据存储目录\n1 2 sudo mkdir -p /opt/data/docker sudo vi /etc/docker/daemon.json 新建docker配置文件，添加存储路径配置\n1 sudo vi /etc/docker/daemon.json 内容如下\n1 2 3 { \u0026#34;data-root\u0026#34;: \u0026#34;/opt/data/docker\u0026#34; } 重启docker\n1 2 sudo systemctl stop docker sudo systemctl start docker 删除旧的docker数据目录\n1 sudo rm -rf /var/lib/docker 安装rar压缩工具 压缩功能\n安装\n1 sudo apt-get -y install rar 卸载\n1 sudo apt-get -y remove rar 解压功能\n安装\n1 sudo apt-get install unrar 卸载\n1 sudo apt-get remove unrar 压缩解压缩.rar\n解压：\n1 rar x FileName.rar 压缩：\n1 rar a FileName.rar DirName 安装java 下载 jdk1.8.0_202\njdk-8u202下载\n解压 tar 到指定目录\n1 sudo tar -zxf jdk-8u202-linux-x64.tar.gz -C /usr/local 创建软链接，方便以后更换 jdk 版本\n1 sudo ln -s /usr/local/jdk1.8.0_202 /usr/local/jdk 添加环境变量配置 新建 jdk 环境变量文件 /etc/profile.d/jdk.sh\n1 sudo touch /etc/profile.d/jdk.sh 添加如下内容\n1 2 3 4 5 6 7 #!/bin/bash export JAVA_HOME=/usr/local/jdk export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar case \u0026#34;:$PATH:\u0026#34; in *\u0026#34;:$JAVA_HOME/bin:\u0026#34;*) :;; # already there *) PATH=\u0026#34;$JAVA_HOME/bin:$PATH\u0026#34;;; # or PATH=\u0026#34;$PATH:$new_entry\u0026#34; esac 注意：/etc/profile.d/jdk.sh 文件权限应该为 644\n更新当前 shell 环境变量\n1 source /etc/profile 安装idea 下载idea\n下载链接：https://www.jetbrains.com/zh-cn/idea/download/\n解压\n1 2 3 sudo tar -xzf ideaIU-2023.1.tar.gz -C /opt/develop/ cd /opt/develop/ mv idea-IU-231.8109.175/ idea-IU 创建快捷方式\n方式一：idea首页，左下角齿轮 -\u0026gt; create desktop entry\n方式二：\n1 2 3 4 5 6 7 8 9 10 11 12 $ cat /usr/share/applications/jetbrains-idea.desktop [Desktop Entry] Version=1.0 Type=Application Name=IntelliJ IDEA Ultimate Edition Icon=/opt/develop/idea-IU/bin/idea.svg Exec=\u0026#34;/opt/develop/idea-IU/bin/idea.sh\u0026#34; %f Comment=Capable and Ergonomic IDE for JVM Categories=Development;IDE; Terminal=false StartupWMClass=jetbrains-idea StartupNotify=true 添加可执行权限\n1 sudo chmod +x /usr/share/applications/jetbrains-idea.desktop idea64.vmoptions idea64.vmoptions 内容\n1 2 3 4 5 6 cat /home/username/.config/JetBrains/IntelliJIdea2023.1/idea64.vmoptions # custom IntelliJ IDEA VM options (expand/override \u0026#39;bin/idea.vmoptions\u0026#39;) -javaagent:/opt/develop/jetbra/ja-netfilter.jar --add-opens=java.base/jdk.internal.org.objectweb.asm=ALL-UNNAMED --add-opens=java.base/jdk.internal.org.objectweb.asm.tree=ALL-UNNAMED -Xmx4096m idea 快捷键 ctrl + shift + f 无法使用问题\n原因： ubuntu 自带的输入法占用了 ctrl + shift + f 快捷键\n解决：修改 ubntu 输入法中切换繁体/简体中文模式快捷键\n安装clash for windows clash for windows 下载\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 mkdir /opt/app tar -zxf Clash.for.Windows-0.20.9-x64-linux.tar.gz -C /opt/app ln -s /opt/app/Clash\\ for\\ Windows-0.20.9-x64-linux /opt/app/clash cd /opt/app/clash wget http://cdn.jsdelivr.net/gh/Dreamacro/clash@master/docs/logo.png cd .. vi clash.desktop # 内容如下 [Desktop Entry] Name=clash Comment=Clash Exec=/home/hekai/.app/clash/cfw Icon=/home/hekai/.app/clash/logo.png Type=Application Categories=Development; StartupNotify=true NoDisplay=false sudo cp clash.desktop /usr/share/applications/ 注意：.desktop 文件内容权限为 644 ，属主为 root\n安装 fcitx 见 ubuntu安装fcitx输入法框架\n使用Ubuntu软件安装时认证失败 使用 ubuntu 软件中心 安装 deb 包时，遇到了认证失败的问题。\n比如弹出安装不可信任的软件，需要输入用户密码，但是密码输入后，提示抱歉，认证失败。请重试。\n查看 /var/log/auth.log 日志\n1 2 Aug 18 23:39:02 00bafcjc-dUrwEMo9N5 polkitd(authority=local): Operator of unix-session:1 FAILED to authenticate to gain authorization for action org.freedesktop.packagekit.package-install-untrusted for system-bus-name::1.84 [gnome-software --local-filename=/home/hekai/Downloads/microsoft-edge-stable_115.0.1901.203-1_amd64.deb] (owned by unix-user:hekai) Aug 18 23:39:02 00bafcjc-dUrwEMo9N5 PackageKit: uid 1000 failed to obtain auth 解决：修改 /usr/share/polkit-1/actions/org.freedesktop.packagekit.policy 中 action 为 org.freedesktop.packagekit.package-install-untrusted ，将其中 auth_admin 的改为 yes ，如下\n1 2 3 4 5 \u0026lt;defaults\u0026gt; \u0026lt;allow_any\u0026gt;yes\u0026lt;/allow_any\u0026gt; \u0026lt;allow_inactive\u0026gt;yes\u0026lt;/allow_inactive\u0026gt; \u0026lt;allow_active\u0026gt;yes\u0026lt;/allow_active\u0026gt; \u0026lt;/defaults\u0026gt; 参考：\nhttps://zhuanlan.zhihu.com/p/250658106\nhttps://blog.csdn.net/Andy86666/article/details/106328819 https://blog.csdn.net/qq_25518029/article/details/119906550\nhttps://blog.csdn.net/zhaominyong/article/details/118361940\nhttps://askubuntu.com/questions/18222/how-to-prevent-system-applications-like-the-software-center-from-asking-for-pa\n","date":"2023-08-17T00:00:00Z","permalink":"https://msdemt.github.io/p/ubuntu-install-software/","title":"ubuntu安装idea等软件"},{"content":"介绍 在 Linux 系统中，冒号(:)常用来做路径的分隔符（如在PATH），数据字段的分隔符（如在 /etc/passwd）等。其实，冒号(:)在 Bash 中也是一个内建命令，它啥也不做，是个空命令、只起到占一个位置的作用，但有时候确实需要它。当然，它也有它的用途的，否则没必要存在。在 Linux 的帮助页中说它除了参数扩展和重定向之外不产生任何作用。\ngnu 帮助：http://www.gnu.org/software/bash/manual/bash.html#Bourne-Shell-Builtins\n作用 冒号（:）的作用\n空命令 参数扩展 重定向 当注释使用 空命令 空命令就是什么也不做，所以返回码永远都是 0 。虽说是空命令，但仍是命令，就具备一般命令应有的特征，可以象一般命令一样使用。如\n1 2 3 4 [root@localhost test]# : [root@localhost test]# echo $? 0 [root@localhost test]# 可以直接在console中执行。返回码为0。\n利用这一特性，:可以当 true 使用。如用在 while 等循环体中的条件判断。\n参数扩展 冒号引起的参数扩展，意思是将参数的值替换为新的值。一般有以下几种参数扩展用法：\n1 2 3 4 5 6 7 ${parameter:-word} #如果parameter没有设置或者为空，替换为word；否则替换为parameter的值 ${parameter:+word} #如果parameter没有设置或者为空，不进行任何替换；否则替换为word。 ${parameter:=word} #如果parameter没有设置或者为空，把word赋值给parameter。实际parameterd的值真的被替换了，这就是=号的意思。不能用这种方式指派位置参数或特殊参数的值。 ${parameter:?word} #如果parameter没有设置或者为空，把word输出到stderr，否则替换为parameter的值。 # -、+、? 实际parameter的值并不被修改，扩展只是临时显示成word的值。准确的讲，扩展实际替换的是参数的显示，而不是参数的定义。只有=，才是替换参数的定义。 ${parameter:offset} #扩展为parameter中从offset开始的子字符串。 ${parameter:offset:length} #扩展为parameter中从offset开始的长度不超过length的字符。 三元运算符\n1 2 var=100 (($var\u0026gt;100?var++:var--)) 重定向 1 2 3 : \u0026gt; test.file cat test.file cat 文件内容，什么都没有。\n注释 使用冒号还可以用作注释行的开始，但是如果有语法错误，仍将报错，这一点与使用 # 号不同。如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [root@localhost test]# cat test.sh fun() { echo 1222 : cccccc # llllll echo 222221 } fun [root@localhost test]# sh test.sh 1222 222221 参考：\nhttps://www.cnblogs.com/ChinaGo/p/9910747.html\n","date":"2023-08-17T00:00:00Z","permalink":"https://msdemt.github.io/p/bash-colon/","title":"冒号在shell中的作用"},{"content":"介绍 curl 是一个非常实用的、用来与服务器之间传输数据的工具；支持的协议包括 (DICT, FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMTP, SMTPS, TELNET and TFTP)，curl 设计为无用户交互下完成工作；curl 提供了一大堆非常有用的功能，包括代理访问、用户认证、ftp上传下载、HTTP POST、SSL连接、cookie支持、断点续传等。\n常用的 curl 命令 发送 GET 请求 -X: 指定执行请求类型（POST/GET/HEAD/DELETE/PUT/PATCH），不加 -X 默认为 GET 请求 -H: 指定 header 头 -d: 指定传输的数据 -b: 指定 cookie，cookie 语法: key=value\n表示请求的地址\n1 curl \u0026lt;URL\u0026gt; 1 curl \u0026lt;URL\u0026gt;?a=1\u0026amp;b=hello 1 curl -X GET \u0026lt;URL\u0026gt;?a=1\u0026amp;b=hello 发送 POST 请求 1 curl -X POST -d \u0026#39;a=1\u0026amp;b=hello\u0026#39; \u0026lt;URL\u0026gt; POST 发送 json 格式的数据\n1 curl -H \u0026#34;Content-Type: application/json\u0026#34; -X POST -d \u0026#39;{\u0026#34;a\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;b\u0026#34;:\u0026#34;hello\u0026#34;}\u0026#39; \u0026lt;URL\u0026gt; POST 发送 test.json 文件中的 json 数据\n1 curl -H \u0026#34;Content-Type: application/json\u0026#34; -X POST -d @test.json \u0026lt;URL\u0026gt; POST 请求携带 cookie\n1 curl -H \u0026#34;Content-Type: application/json\u0026#34; -b \u0026#34;Token=eyJ0eXAi\u0026#34; -X POST -d @test.json \u0026lt;URL\u0026gt; 下载文件 -O 参数后面的 url 要具体到待下载的文件\n1 curl -O http://www.linux.com/test.jpg 下载并重命名文件\n1 curl -o test.jpg http://www.linux.com/test.jpg curl 命令语法 curl 命令语法 1 curl [options...] \u0026lt;URL\u0026gt; curl 参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 $ curl -h all Usage: curl [options...] \u0026lt;url\u0026gt; --abstract-unix-socket \u0026lt;path\u0026gt; Connect via abstract Unix domain socket --alt-svc \u0026lt;file name\u0026gt; Enable alt-svc with this cache file --anyauth Pick any authentication method -a, --append Append to target file when uploading --aws-sigv4 \u0026lt;provider1[:provider2[:region[:service]]]\u0026gt; Use AWS V4 signature authentication --basic Use HTTP Basic Authentication --cacert \u0026lt;file\u0026gt; CA certificate to verify peer against --capath \u0026lt;dir\u0026gt; CA directory to verify peer against -E, --cert \u0026lt;certificate[:password]\u0026gt; Client certificate file and password --cert-status Verify the status of the server cert via OCSP-staple --cert-type \u0026lt;type\u0026gt; Certificate type (DER/PEM/ENG) --ciphers \u0026lt;list of ciphers\u0026gt; SSL ciphers to use --compressed Request compressed response --compressed-ssh Enable SSH compression -K, --config \u0026lt;file\u0026gt; Read config from a file --connect-timeout \u0026lt;fractional seconds\u0026gt; Maximum time allowed for connection --connect-to \u0026lt;HOST1:PORT1:HOST2:PORT2\u0026gt; Connect to host -C, --continue-at \u0026lt;offset\u0026gt; Resumed transfer offset -b, --cookie \u0026lt;data|filename\u0026gt; Send cookies from string/file -c, --cookie-jar \u0026lt;filename\u0026gt; Write cookies to \u0026lt;filename\u0026gt; after operation --create-dirs Create necessary local directory hierarchy --create-file-mode \u0026lt;mode\u0026gt; File mode for created files --crlf Convert LF to CRLF in upload --crlfile \u0026lt;file\u0026gt; Use this CRL list --curves \u0026lt;algorithm list\u0026gt; (EC) TLS key exchange algorithm(s) to request -d, --data \u0026lt;data\u0026gt; HTTP POST data --data-ascii \u0026lt;data\u0026gt; HTTP POST ASCII data --data-binary \u0026lt;data\u0026gt; HTTP POST binary data --data-raw \u0026lt;data\u0026gt; HTTP POST data, \u0026#39;@\u0026#39; allowed --data-urlencode \u0026lt;data\u0026gt; HTTP POST data url encoded --delegation \u0026lt;LEVEL\u0026gt; GSS-API delegation permission --digest Use HTTP Digest Authentication -q, --disable Disable .curlrc --disable-eprt Inhibit using EPRT or LPRT --disable-epsv Inhibit using EPSV --disallow-username-in-url Disallow username in url --dns-interface \u0026lt;interface\u0026gt; Interface to use for DNS requests --dns-ipv4-addr \u0026lt;address\u0026gt; IPv4 address to use for DNS requests --dns-ipv6-addr \u0026lt;address\u0026gt; IPv6 address to use for DNS requests --dns-servers \u0026lt;addresses\u0026gt; DNS server addrs to use --doh-cert-status Verify the status of the DoH server cert via OCSP-staple --doh-insecure Allow insecure DoH server connections --doh-url \u0026lt;URL\u0026gt; Resolve host names over DoH -D, --dump-header \u0026lt;filename\u0026gt; Write the received headers to \u0026lt;filename\u0026gt; --egd-file \u0026lt;file\u0026gt; EGD socket path for random data --engine \u0026lt;name\u0026gt; Crypto engine to use --etag-compare \u0026lt;file\u0026gt; Pass an ETag from a file as a custom header --etag-save \u0026lt;file\u0026gt; Parse ETag from a request and save it to a file --expect100-timeout \u0026lt;seconds\u0026gt; How long to wait for 100-continue -f, --fail Fail silently (no output at all) on HTTP errors --fail-early Fail on first transfer error, do not continue --fail-with-body Fail on HTTP errors but save the body --false-start Enable TLS False Start -F, --form \u0026lt;name=content\u0026gt; Specify multipart MIME data --form-escape Escape multipart form field/file names using backslash --form-string \u0026lt;name=string\u0026gt; Specify multipart MIME data --ftp-account \u0026lt;data\u0026gt; Account data string --ftp-alternative-to-user \u0026lt;command\u0026gt; String to replace USER [name] --ftp-create-dirs Create the remote dirs if not present --ftp-method \u0026lt;method\u0026gt; Control CWD usage --ftp-pasv Use PASV/EPSV instead of PORT -P, --ftp-port \u0026lt;address\u0026gt; Use PORT instead of PASV --ftp-pret Send PRET before PASV --ftp-skip-pasv-ip Skip the IP address for PASV --ftp-ssl-ccc Send CCC after authenticating --ftp-ssl-ccc-mode \u0026lt;active/passive\u0026gt; Set CCC mode --ftp-ssl-control Require SSL/TLS for FTP login, clear for transfer -G, --get Put the post data in the URL and use GET -g, --globoff Disable URL sequences and ranges using {} and [] --happy-eyeballs-timeout-ms \u0026lt;milliseconds\u0026gt; Time for IPv6 before trying IPv4 --haproxy-protocol Send HAProxy PROXY protocol v1 header -I, --head Show document info only -H, --header \u0026lt;header/@file\u0026gt; Pass custom header(s) to server -h, --help \u0026lt;category\u0026gt; Get help for commands --hostpubmd5 \u0026lt;md5\u0026gt; Acceptable MD5 hash of the host public key --hostpubsha256 \u0026lt;sha256\u0026gt; Acceptable SHA256 hash of the host public key --hsts \u0026lt;file name\u0026gt; Enable HSTS with this cache file --http0.9 Allow HTTP 0.9 responses -0, --http1.0 Use HTTP 1.0 --http1.1 Use HTTP 1.1 --http2 Use HTTP 2 --http2-prior-knowledge Use HTTP 2 without HTTP/1.1 Upgrade --http3 Use HTTP v3 --ignore-content-length Ignore the size of the remote resource -i, --include Include protocol response headers in the output -k, --insecure Allow insecure server connections --interface \u0026lt;name\u0026gt; Use network INTERFACE (or address) -4, --ipv4 Resolve names to IPv4 addresses -6, --ipv6 Resolve names to IPv6 addresses -j, --junk-session-cookies Ignore session cookies read from file --keepalive-time \u0026lt;seconds\u0026gt; Interval time for keepalive probes --key \u0026lt;key\u0026gt; Private key file name --key-type \u0026lt;type\u0026gt; Private key file type (DER/PEM/ENG) --krb \u0026lt;level\u0026gt; Enable Kerberos with security \u0026lt;level\u0026gt; --libcurl \u0026lt;file\u0026gt; Dump libcurl equivalent code of this command line --limit-rate \u0026lt;speed\u0026gt; Limit transfer speed to RATE -l, --list-only List only mode --local-port \u0026lt;num/range\u0026gt; Force use of RANGE for local port numbers -L, --location Follow redirects --location-trusted Like --location, and send auth to other hosts --login-options \u0026lt;options\u0026gt; Server login options --mail-auth \u0026lt;address\u0026gt; Originator address of the original email --mail-from \u0026lt;address\u0026gt; Mail from this address --mail-rcpt \u0026lt;address\u0026gt; Mail to this address --mail-rcpt-allowfails Allow RCPT TO command to fail for some recipients -M, --manual Display the full manual --max-filesize \u0026lt;bytes\u0026gt; Maximum file size to download --max-redirs \u0026lt;num\u0026gt; Maximum number of redirects allowed -m, --max-time \u0026lt;fractional seconds\u0026gt; Maximum time allowed for transfer --metalink Process given URLs as metalink XML file --negotiate Use HTTP Negotiate (SPNEGO) authentication -n, --netrc Must read .netrc for user name and password --netrc-file \u0026lt;filename\u0026gt; Specify FILE for netrc --netrc-optional Use either .netrc or URL -:, --next Make next URL use its separate set of options --no-alpn Disable the ALPN TLS extension -N, --no-buffer Disable buffering of the output stream --no-keepalive Disable TCP keepalive on the connection --no-npn Disable the NPN TLS extension --no-progress-meter Do not show the progress meter --no-sessionid Disable SSL session-ID reusing --noproxy \u0026lt;no-proxy-list\u0026gt; List of hosts which do not use proxy --ntlm Use HTTP NTLM authentication --ntlm-wb Use HTTP NTLM authentication with winbind --oauth2-bearer \u0026lt;token\u0026gt; OAuth 2 Bearer Token -o, --output \u0026lt;file\u0026gt; Write to file instead of stdout --output-dir \u0026lt;dir\u0026gt; Directory to save files in -Z, --parallel Perform transfers in parallel --parallel-immediate Do not wait for multiplexing (with --parallel) --parallel-max \u0026lt;num\u0026gt; Maximum concurrency for parallel transfers --pass \u0026lt;phrase\u0026gt; Pass phrase for the private key --path-as-is Do not squash .. sequences in URL path --pinnedpubkey \u0026lt;hashes\u0026gt; FILE/HASHES Public key to verify peer against --post301 Do not switch to GET after following a 301 --post302 Do not switch to GET after following a 302 --post303 Do not switch to GET after following a 303 --preproxy [protocol://]host[:port] Use this proxy first -#, --progress-bar Display transfer progress as a bar --proto \u0026lt;protocols\u0026gt; Enable/disable PROTOCOLS --proto-default \u0026lt;protocol\u0026gt; Use PROTOCOL for any URL missing a scheme --proto-redir \u0026lt;protocols\u0026gt; Enable/disable PROTOCOLS on redirect -x, --proxy [protocol://]host[:port] Use this proxy --proxy-anyauth Pick any proxy authentication method --proxy-basic Use Basic authentication on the proxy --proxy-cacert \u0026lt;file\u0026gt; CA certificate to verify peer against for proxy --proxy-capath \u0026lt;dir\u0026gt; CA directory to verify peer against for proxy --proxy-cert \u0026lt;cert[:passwd]\u0026gt; Set client certificate for proxy --proxy-cert-type \u0026lt;type\u0026gt; Client certificate type for HTTPS proxy --proxy-ciphers \u0026lt;list\u0026gt; SSL ciphers to use for proxy --proxy-crlfile \u0026lt;file\u0026gt; Set a CRL list for proxy --proxy-digest Use Digest authentication on the proxy --proxy-header \u0026lt;header/@file\u0026gt; Pass custom header(s) to proxy --proxy-insecure Do HTTPS proxy connections without verifying the proxy --proxy-key \u0026lt;key\u0026gt; Private key for HTTPS proxy --proxy-key-type \u0026lt;type\u0026gt; Private key file type for proxy --proxy-negotiate Use HTTP Negotiate (SPNEGO) authentication on the proxy --proxy-ntlm Use NTLM authentication on the proxy --proxy-pass \u0026lt;phrase\u0026gt; Pass phrase for the private key for HTTPS proxy --proxy-pinnedpubkey \u0026lt;hashes\u0026gt; FILE/HASHES public key to verify proxy with --proxy-service-name \u0026lt;name\u0026gt; SPNEGO proxy service name --proxy-ssl-allow-beast Allow security flaw for interop for HTTPS proxy --proxy-ssl-auto-client-cert Use auto client certificate for proxy (Schannel) --proxy-tls13-ciphers \u0026lt;ciphersuite list\u0026gt; TLS 1.3 proxy cipher suites --proxy-tlsauthtype \u0026lt;type\u0026gt; TLS authentication type for HTTPS proxy --proxy-tlspassword \u0026lt;string\u0026gt; TLS password for HTTPS proxy --proxy-tlsuser \u0026lt;name\u0026gt; TLS username for HTTPS proxy --proxy-tlsv1 Use TLSv1 for HTTPS proxy -U, --proxy-user \u0026lt;user:password\u0026gt; Proxy user and password --proxy1.0 \u0026lt;host[:port]\u0026gt; Use HTTP/1.0 proxy on given port -p, --proxytunnel Operate through an HTTP proxy tunnel (using CONNECT) --pubkey \u0026lt;key\u0026gt; SSH Public key file name -Q, --quote \u0026lt;command\u0026gt; Send command(s) to server before transfer --random-file \u0026lt;file\u0026gt; File for reading random data from -r, --range \u0026lt;range\u0026gt; Retrieve only the bytes within RANGE --raw Do HTTP \u0026#34;raw\u0026#34;; no transfer decoding -e, --referer \u0026lt;URL\u0026gt; Referrer URL -J, --remote-header-name Use the header-provided filename -O, --remote-name Write output to a file named as the remote file --remote-name-all Use the remote file name for all URLs -R, --remote-time Set the remote file\u0026#39;s time on the local output -X, --request \u0026lt;method\u0026gt; Specify request method to use --request-target \u0026lt;path\u0026gt; Specify the target for this request --resolve \u0026lt;[+]host:port:addr[,addr]...\u0026gt; Resolve the host+port to this address --retry \u0026lt;num\u0026gt; Retry request if transient problems occur --retry-all-errors Retry all errors (use with --retry) --retry-connrefused Retry on connection refused (use with --retry) --retry-delay \u0026lt;seconds\u0026gt; Wait time between retries --retry-max-time \u0026lt;seconds\u0026gt; Retry only within this period --sasl-authzid \u0026lt;identity\u0026gt; Identity for SASL PLAIN authentication --sasl-ir Enable initial response in SASL authentication --service-name \u0026lt;name\u0026gt; SPNEGO service name -S, --show-error Show error even when -s is used -s, --silent Silent mode --socks4 \u0026lt;host[:port]\u0026gt; SOCKS4 proxy on given host + port --socks4a \u0026lt;host[:port]\u0026gt; SOCKS4a proxy on given host + port --socks5 \u0026lt;host[:port]\u0026gt; SOCKS5 proxy on given host + port --socks5-basic Enable username/password auth for SOCKS5 proxies --socks5-gssapi Enable GSS-API auth for SOCKS5 proxies --socks5-gssapi-nec Compatibility with NEC SOCKS5 server --socks5-gssapi-service \u0026lt;name\u0026gt; SOCKS5 proxy service name for GSS-API --socks5-hostname \u0026lt;host[:port]\u0026gt; SOCKS5 proxy, pass host name to proxy -Y, --speed-limit \u0026lt;speed\u0026gt; Stop transfers slower than this -y, --speed-time \u0026lt;seconds\u0026gt; Trigger \u0026#39;speed-limit\u0026#39; abort after this time --ssl Try SSL/TLS --ssl-allow-beast Allow security flaw to improve interop --ssl-auto-client-cert Use auto client certificate (Schannel) --ssl-no-revoke Disable cert revocation checks (Schannel) --ssl-reqd Require SSL/TLS --ssl-revoke-best-effort Ignore missing/offline cert CRL dist points -2, --sslv2 Use SSLv2 -3, --sslv3 Use SSLv3 --stderr \u0026lt;file\u0026gt; Where to redirect stderr --styled-output Enable styled output for HTTP headers --suppress-connect-headers Suppress proxy CONNECT response headers --tcp-fastopen Use TCP Fast Open --tcp-nodelay Use the TCP_NODELAY option -t, --telnet-option \u0026lt;opt=val\u0026gt; Set telnet option --tftp-blksize \u0026lt;value\u0026gt; Set TFTP BLKSIZE option --tftp-no-options Do not send any TFTP options -z, --time-cond \u0026lt;time\u0026gt; Transfer based on a time condition --tls-max \u0026lt;VERSION\u0026gt; Set maximum allowed TLS version --tls13-ciphers \u0026lt;ciphersuite list\u0026gt; TLS 1.3 cipher suites to use --tlsauthtype \u0026lt;type\u0026gt; TLS authentication type --tlspassword \u0026lt;string\u0026gt; TLS password --tlsuser \u0026lt;name\u0026gt; TLS user name -1, --tlsv1 Use TLSv1.0 or greater --tlsv1.0 Use TLSv1.0 or greater --tlsv1.1 Use TLSv1.1 or greater --tlsv1.2 Use TLSv1.2 or greater --tlsv1.3 Use TLSv1.3 or greater --tr-encoding Request compressed transfer encoding --trace \u0026lt;file\u0026gt; Write a debug trace to FILE --trace-ascii \u0026lt;file\u0026gt; Like --trace, but without hex output --trace-time Add time stamps to trace/verbose output --unix-socket \u0026lt;path\u0026gt; Connect through this Unix domain socket -T, --upload-file \u0026lt;file\u0026gt; Transfer local FILE to destination --url \u0026lt;url\u0026gt; URL to work with -B, --use-ascii Use ASCII/text transfer -u, --user \u0026lt;user:password\u0026gt; Server user and password -A, --user-agent \u0026lt;name\u0026gt; Send User-Agent \u0026lt;name\u0026gt; to server -v, --verbose Make the operation more talkative -V, --version Show version number and quit -w, --write-out \u0026lt;format\u0026gt; Use output FORMAT after completion --xattr Store metadata in extended file attributes 参数详解 参考：\nhttps://blog.csdn.net/angle_chen123/article/details/120675472\n","date":"2023-08-16T00:00:00Z","permalink":"https://msdemt.github.io/p/curl-introduction/","title":"curl 命令介绍"},{"content":"介绍 希望修改 ubuntu 18.04 上的用户名，比如现在的用户名是 abc，家目录是 /home/abc，想将该用户名修改为 def，家目录修改为 /home/def 。\n最简单的方式当然是新建一个名为 def 的用户，将 abc 用户删掉，但是因为在 abc 目录下配置了很多东西，所以希望能修改用户名。\n修改密码 注意：修改用户名前，必须先修改下密码\n在终端中，执行 sudo su 切换为 root 用户（注意，必须转为 root 用户）。 执行 sudo passwd abc （abc 是当前的用户名） 输入新密码，确认密码 修改密码成功，重启，输入新密码进入系统 修改用户名 打开终端，输入 sudo su 转为 root 用户 （注意，必须转为 root 用户）。 vi /etc/passwd ，修改用户名 abc 为新的用户名 def （注意：只修改用户名！后面的全名、目录等不要动！）。 vi /etc/shadow , 修改用户名 abc 为新的用户名 def 。 vi /etc/group , 用户名 abc 可能在很多的组中，将所有包含 abc 的组中的 abc 修改为 def 。 修改完成，保存，重启。 重启后，会发现 Ubuntu 登陆界面的用户名还是原来的用户名，但是终端里的用户名已经修改。此时，再选择 Ubuntu 屏幕右上角的电源图标下的账号设置，在弹出的对话框中再次修改用户名，然后就完全成功了。\n修改家目录名 上述修改完成后，家目录还是旧的名称 /home/abc\nvi /etc/passwd , 找到新用户名，修改该用户的家目录为新的家目录，比如 /home/def 将旧家目录名修改为新家目录名 sudo mv /home/abc home/def 重启 参考：\nhttps://www.cnblogs.com/yxqxx/p/12319130.html\n","date":"2023-08-15T00:00:00Z","permalink":"https://msdemt.github.io/p/ubuntu-change-username/","title":"ubuntu18.04修改用户名"},{"content":"介绍 项目中，需要将数据库由 H2 迁移到 mariadb-5.5.60，迁移过程中遇到的问题汇总如下\n表名大小写敏感问题 在 linux 系统中，mysql/mariadb 对表名的大小写是敏感的，因为在 SQL 语句中，使用大写的表名，在 H2 中正常，但是迁移到 mariadb 后，提示找不到表。\n解决：将 SQL 语句中的表名改为小写\nDATE_FORMAT() 函数问题 在 H2 的 SQL 语句中，使用了 FORMATDATETIME(create_time, 'yyyy-MM-dd HH:') 对日期进行格式化处理，转为 mariadb 后，mariadb 不支持 FORMATDATETIME() 函数，所以使用了 DATE_FORMAT() 函数代替，但是，执行 sql 后发现查不到期望的数据。\n测试： 在 H2 控制台执行\n1 select FORMATDATETIME(\u0026#39;2023-08-09 11:06:57\u0026#39;, \u0026#39;yyyy-MM-dd HH:\u0026#39;) 可以得到 2023-08-09 11:\n在 mariadb 控制台执行\n1 select DATE_FORMAT(\u0026#39;2023-08-09 11:06:57\u0026#39;, \u0026#39;yyyy-MM-dd HH:\u0026#39;); 得到 yyyy-MM-dd HH:\n参考：\nhttps://www.w3school.com.cn/sql/func_date_format.asp\nDATE_FORMAT() 函数的格式化参数和 FORMATDATETIME() 函数不同，将 SQL 修改为 DATE_FORMAT(create_time, '%Y-%m-%d %H:') 后，可以查到正确的数据。\n在 mariadb 控制台执行\n1 select DATE_FORMAT(\u0026#39;2023-08-09 11:06:57\u0026#39;, \u0026#39;%Y-%m-%d %H:\u0026#39;); 得到正确的结果：2023-08-09 11:\n","date":"2023-08-11T00:00:00Z","permalink":"https://msdemt.github.io/p/h2-to-mysql/","title":"H2 迁移到 MySQL 问题"},{"content":"介绍 在 MySQL 中，数据库对应数据目录中的目录，数据库中的每个表至少对应数据库目录中的一个文件（也可能是多个，取决于存储引擎）。因此，所使用操作系统的大小写敏感性决定了数据库名和表名的大小写敏感性。\n在大多数 Unix 中数据库名和表名对大小写敏感，而在 Windows 中对大小写不敏感。一个显著的例外情况是 Mac OS X ，它基于 Unix 但使用默认文件系统类型（HFS+），对大小写不敏感。然而，Mac OS X 也支持 UFS 卷，该卷对大小写敏感，就像 Unix 一样。\nlower_case_file_system 参数（只读） 表示当前系统文件是否大小写敏感，只读参数，无法修改。\nON: 大小写不敏感 OFF: 大小写敏感 lower_case_table_names 参数 Unix 下 lower_case_table_names 默认值为 0 ；Windows 下默认值是 1 ；Mac OS X 下默认值是 2 。\n0: 使用 CREATE TABLE 或 CREATE DATABASE 语句指定的大小写字母在硬盘上保存表名和数据库名。名称比较对大小写敏感。在大小写不敏感的操作系统如 Windows 或 Mac OS x 上我们不能将该参数设为 0 ，如果在大小写不敏感的文件系统上将 --lowercase-table-names 强制设为 0 ，并且使用不同的大小写访问 MyISAM 表名，可能会导致索引破坏。 1: 表名在硬盘上以小写保存，名称比较对大小写不敏感。 MySQL 将所有表名转换为小写在存储和查找表上。该行为也适合数据库名和表的别名。该值为 Windows 的默认值。 2: 表名和数据库名在硬盘上使用 CREATE TABLE 或 CREATE DATABASE 语句指定的大小写字母进行保存，但 MySQL 将它们转换为小写在查找表上。名称比较对大小写不敏感，即按照大小写来保存，按照小写来比较。注释：只在对大小写不敏感的文件系统上适用! innodb 表名用小写保存。 由大小写敏感转换为不敏感方法 如果原来所建立库及表都是对大小写敏感的，想要转换为对大小写不敏感，主要需要进行如下3步：\n将数据库数据通过 mysqldump 导出。 在 my.cnf （ CentOS 下配置文件是 /etc/my.cnf ）中更改最后添加 lower_case_tables_name = 1，然后重启 mysql 数据库 将导出的数据导入 mysql 数据库。 注：MySQL 8.0 开始，禁止在重新启动 MySQL 服务时将 lower_case_table_names 设置 成不同于初始化 MySQL 服务时设置的 lower_case_table_names 值。该值只能在初始化 MySQL 之前设置。\n命名规则 为了避免大小写引发的问题，一种推荐的命名规则是：在定义数据库、表、列的时候全部采用小写字母加下划线的方式，不使用任何大写字母。\n在任何系统中可以使用 lower_case_table_names=1 。使用该选项的不利之处是当使用 SHOW TABLES 或 SHOW DATABASES 时，看不出名字原来是用大写还是小写。\n请注意在 Unix 中如果以前 lower_case_table_names = 0，在将 lower_case_table_names 设置为 1 时，重启 mysqld 之前，必须先将旧的数据库名和表名转换为小写。\n字段名大小写不敏感 数据库字段名，大小写不敏感\n字段值大小写敏感设置，字符集和排序规则 字段值的大小写由 mysql 的校对规则来控制。提到校对规则，就不得不说字符集。字符集是一套符号和编码，校对规则是在字符集内用于比较字符的一套规则。\n一般而言，校对规则以其相关的字符集名开始，通常包括一个语言名，并且以 _ci（大小写不敏感）、_cs（大小写敏感）或 _bin（二元）结束 。比如 utf8 字符集，utf8_general_ci 表示不区分大小写，这个是 utf8 字符集默认的校对规则； utf8_general_cs 表示区分大小写，utf8_bin 表示二进制比较，同样也区分大小写 。\n参考：\nhttps://blog.csdn.net/lishuoboy/article/details/84562007\nhttps://zhuanlan.zhihu.com/p/147720463\n","date":"2023-08-11T00:00:00Z","permalink":"https://msdemt.github.io/p/mysql-case-sensitive/","title":"MySQL 大小写敏感配置"},{"content":"工作中使用到了 mariadb 5.5.60 版本，使用 docker 部署下。\n参考：\nhttps://hub.docker.com/_/mariadb\ndocker-compose 如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 hekai@thinkpad-l14:~/doc/docker-mariadb$ cat docker-compose.yml # Use root/example as user/password credentials version: \u0026#39;3.1\u0026#39; services: db: image: mariadb:5.5.60 restart: always environment: MYSQL_ROOT_PASSWORD: root MYSQL_ROOT_HOST: \u0026#34;%\u0026#34; TZ: Asia/Shanghai ports: - 3306:3306 volumes: - ./data:/var/lib/mysql - ./conf:/etc/mysql/conf.d adminer: image: adminer restart: always environment: TZ: Asia/Shanghai ports: - 18080:8080 docker-compose 参数\nrestart: always : 重启 docker 后，配置该参数的docker容器在docker重启时自动启动 TZ: Asia/Shanghai: environment 参数，指定中国时区，默认是格林尼治时间（GMT） mariadb 环境变量\nMYSQL_ROOT_PASSWORD: 指定 mariadb root 用户密码 MYSQL_ROOT_HOST: 指定 root 用户可访问的来源， % 表示所有来源的 root 用户都可以访问 docker-compose 中使用到了 adminer 开源数据库管理工具，访问方式为：http://127.0.0.1:18080\n","date":"2023-08-10T00:00:00Z","permalink":"https://msdemt.github.io/p/docker-mariadb-5.5.60/","title":"docker 部署 mariadb-5.5.60"},{"content":"介绍 在 ubuntu 上使用 git clone 下载时，每次都需要输入密码，而且，现在 github 要求使用 personal access token，无法直接输入密码了。\n解决办法\n1 git config --global credential.helper store 使用 store 模式存储凭证，凭证用明文的形式存放在磁盘中，并且永不过期，存储位置： ~/.git-credentials 中。\n参考：\nhttps://git-scm.com/book/zh/v2/Git-%E5%B7%A5%E5%85%B7-%E5%87%AD%E8%AF%81%E5%AD%98%E5%82%A8\n凭证存储 如果你使用的是 SSH 方式连接远端，并且设置了一个没有口令的密钥，这样就可以在不输入用户名和密码的情况下安全地传输数据。 然而，这对 HTTP 协议来说是不可能的 \u0026mdash; 每一个连接都是需要用户名和密码的。 这在使用双重认证的情况下会更麻烦，因为你需要输入一个随机生成并且毫无规律的 token 作为密码。\n幸运的是，Git 拥有一个凭证系统来处理这个事情。 下面有一些 Git 的选项：\n默认所有都不缓存。 每一次连接都会询问你的用户名和密码。\n“cache” 模式会将凭证存放在内存中一段时间。 密码永远不会被存储在磁盘中，并且在15分钟后从内存中清除。\n“store” 模式会将凭证用明文的形式存放在磁盘中，并且永不过期。 这意味着除非你修改了你在 Git 服务器上的密码，否则你永远不需要再次输入你的凭证信息。 这种方式的缺点是你的密码是用明文的方式存放在你的 home 目录下。\n如果你使用的是 Mac，Git 还有一种 “osxkeychain” 模式，它会将凭证缓存到你系统用户的钥匙串中。 这种方式将凭证存放在磁盘中，并且永不过期，但是是被加密的，这种加密方式与存放 HTTPS 凭证以及 Safari 的自动填写是相同的。\n如果你使用的是 Windows，你可以安装一个叫做 “Git Credential Manager for Windows” 的辅助工具。 这和上面说的 “osxkeychain” 十分类似，但是是使用 Windows Credential Store 来控制敏感信息。 可以在 https://github.com/Microsoft/Git-Credential-Manager-for-Windows 下载。\n你可以设置 Git 的配置来选择上述的一种方式\n1 $ git config --global credential.helper cache 部分辅助工具有一些选项。 “store” 模式可以接受一个 --file \u0026lt;path\u0026gt; 参数，可以自定义存放密码的文件路径（默认是 ~/.git-credentials ）。 “cache” 模式有 --timeout \u0026lt;seconds\u0026gt; 参数，可以设置后台进程的存活时间（默认是 “900”，也就是 15 分钟）。 下面是一个配置 “store” 模式自定义路径的例子：\n1 $ git config --global credential.helper \u0026#39;store --file ~/.my-credentials\u0026#39; Git 甚至允许你配置多个辅助工具。 当查找特定服务器的凭证时，Git 会按顺序查询，并且在找到第一个回答时停止查询。 当保存凭证时，Git 会将用户名和密码发送给 所有 配置列表中的辅助工具，它们会按自己的方式处理用户名和密码。 如果你在闪存上有一个凭证文件，但又希望在该闪存被拔出的情况下使用内存缓存来保存用户名密码，.gitconfig 配置文件如下：\n1 2 3 [credential] helper = store --file /mnt/thumbdrive/.git-credentials helper = cache --timeout 30000 ","date":"2023-08-10T00:00:00Z","permalink":"https://msdemt.github.io/p/git-credential/","title":"git凭证存储"},{"content":"在 wsl 上 git clone 失败，错误如下\n1 2 3 hekai@thinkpad-l14:~$ git clone https://github.com/msdemt/docker-centos7-slurm-cluster.git Cloning into \u0026#39;docker-centos7-slurm-cluster\u0026#39;... fatal: unable to access \u0026#39;https://github.com/msdemt/docker-centos7-slurm-cluster.git/\u0026#39;: GnuTLS recv error (-110): The TLS connection was non-properly terminated. 参考：\nhttps://zhuanlan.zhihu.com/p/624555732\n重新安装下 git\n1 2 3 sudo add-apt-repository ppa:git-core/ppa sudo apt update sudo apt install git 之后可以 git clone 成功了，但是过一段时间，又 git clone 出现了相同的问题\n最终解决：配置 git 代理\n1 git config --global http.proxy socks5://127.0.0.1:7890 git clone 失败，原因 linux 子系统无法使用 127.0.0.1 访问 windows 系统上的服务\n参考：\nhttps://learn.microsoft.com/zh-cn/windows/wsl/networking\n在 linux 子系统 ubuntu 中执行\n1 cat /etc/resolv.conf 1 2 3 4 5 hekai@thinkpad-l14:~$ cat /etc/resolv.conf # This file was automatically generated by WSL. To stop automatic generation of this file, add the following entry to /etc/wsl.conf: # [network] # generateResolvConf = false nameserver 172.22.192.1 复制 nameserver 后面的地址\n在 linux 子系统中使用该地址访问 windows 上的服务，所以 git 代理改为如下内容\n1 git config --global http.proxy socks5://172.22.192.1:7890 git clone 成功。\n","date":"2023-08-10T00:00:00Z","permalink":"https://msdemt.github.io/p/wsl-ubuntu-git-fail/","title":"wsl ubuntu git clone 失败"},{"content":"Set up the repository Update the apt package index and install packages to allow apt to use a repository over HTTPS:\n1 2 sudo apt-get update sudo apt-get install ca-certificates curl gnupg Add Docker’s official GPG key:\n1 2 3 sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg Use the following command to set up the repository:\n1 2 3 4 echo \\ \u0026#34;deb [arch=\u0026#34;$(dpkg --print-architecture)\u0026#34; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ \u0026#34;$(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;)\u0026#34; stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null Update the apt package index:\n1 sudo apt-get update Install Docker Engine Install Docker Engine, containerd, and Docker Compose.\nTo install the latest version, run:\n1 sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin Verify that the Docker Engine installation is successful by running the hello-world image.\n1 sudo docker run hello-world 安装 docker compose To download and install the Compose CLI plugin, run:\n1 2 3 DOCKER_CONFIG=${DOCKER_CONFIG:-$HOME/.docker} mkdir -p $DOCKER_CONFIG/cli-plugins curl -SL https://github.com/docker/compose/releases/download/v2.20.2/docker-compose-linux-x86_64 -o $DOCKER_CONFIG/cli-plugins/docker-compose Apply executable permissions to the binary:\n1 chmod +x $DOCKER_CONFIG/cli-plugins/docker-compose Test the installation.\n1 docker compose version 以非 Root 用户身份执行 Docker 默认情况下，只有 root 或者 有 sudo 权限的用户可以执行 Docker 命令。\n想要以非 root 用户执行 Docker 命令，你需要将你的用户添加到 Docker 用户组，该用户组在 Docker CE 软件包安装过程中被创建。想要这么做，输入：\n1 sudo usermod -aG docker $USER $USER是一个环境变量，代表当前用户名。\n登出，并且重新登录，以便用户组信息刷新。\ndocker 开机启动 目前，在 wsl ubuntu 上安装docker后，已经支持 docker 开机启动了。\nwsl ubuntu 也支持使用 systemctl 命令了。\n开机启动\n1 systemctl enable docker 禁止开机启动\n1 systemctl disable docker 卸载 docker 在卸载 Docker 之前，移除所有的容器，镜像，卷和网络。\n运行下面的命令停止所有正在运行的容器，并且移除所有的 docker 对象：\n1 2 docker container stop $(docker container ls -aq) docker system prune -a --volumes 现在可以使用apt像卸载其他软件包一样来卸载 Docker：\n1 2 sudo apt purge docker-ce sudo apt autoremove 修改docker数据存储路径 wsl ubuntu 默认安装在 c 盘，希望将 docker 的数据存储路径（默认为 /var/lib/docker ）修改到 d 盘。\n添加 /etc/docker/daemon.json 文件，内容如下\n1 2 3 4 5 6 { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://registry.docker-cn.com\u0026#34;], \u0026#34;data-root\u0026#34;: \u0026#34;/mnt/d/data/docker\u0026#34;, \u0026#34;log-driver\u0026#34;:\u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: {\u0026#34;max-size\u0026#34;:\u0026#34;100m\u0026#34;} } docker 启动失败。wls ubuntu docker可能不支持将文件存储到 windows 磁盘。\n将 /var/lib/docker 拷贝到 d 盘，报错，应该是 windows 磁盘不支持这些特殊文件。\n1 2 3 4 5 hekai@thinkpad-l14:~$ sudo mv /var/lib/docker /mnt/d/data/docker mv: cannot create special file \u0026#39;/mnt/d/data/docker/volumes/backingFsBlockDev\u0026#39;: Operation not supported mv: cannot create special file \u0026#39;/mnt/d/data/docker/volumes/docker-centos7-slurm-cluster_mysql/_data/mysql.sock\u0026#39;: Operation not supported mv: cannot create special file \u0026#39;/mnt/d/data/docker/overlay2/3a272b47e6ae28aa475f3eea705bdb2bdeb83dc97c6feb91cc20e6c49bbc004b-init/work/work/#23d\u0026#39;: Operation not supported mv: cannot create special file \u0026#39;/mnt/d/data/docker/overlay2/2a012b89cc6a205c6c8a148abae32a5e735695b52a54e2e3e792c2a5e88a00af-init/work/work/#23f\u0026#39;: Operation not supported wsl ubuntu docker 暂不更改存储位置了。\n参考：\nhttps://docs.docker.com/engine/install/ubuntu/\nhttps://docs.docker.com/compose/install/linux/#install-the-plugin-manually\nhttps://zhuanlan.zhihu.com/p/143156163\nhttps://blog.csdn.net/m0_58684193/article/details/127554527\n","date":"2023-08-10T00:00:00Z","permalink":"https://msdemt.github.io/p/wsl-ubuntu-docker/","title":"wsl ubuntu 安装 docker"},{"content":"介绍 wsl 全称 The Windows Subsystem for Linux ，即适用于 Linux 的 Windows 子系统，可以让开发者在 windows 系统上按原样运行 GNU/Linux 环境 - 包括大多数命令行工具、实用工具和应用程序 - 且不会产生传统虚拟机或双启动设置开销。\nWSL 2 是适用于 Linux 的 Windows 子系统体系结构的一个新版本，它支持适用于 Linux 的 Windows 子系统在 Windows 上运行 ELF64 Linux 二进制文件。 它的主要目标是提高文件系统性能，以及添加完全的系统调用兼容性。\n安装 系统： windows 11\n在管理员模式下打开 PowerShell 或 Windows 命令提示符，方法是右键单击并选择“以管理员身份运行”，输入 wsl --install 命令，然后重启计算机。\n1 wsl --install 此命令将启用运行 WSL 并安装 Linux 的 Ubuntu 发行版所需的功能。\n更改默认安装的 Linux 发行版 默认情况下，安装的 Linux 分发版为 Ubuntu。 可以使用 -d 标志进行更改。\n若要更改安装的发行版，请输入：wsl --install -d \u0026lt;Distribution Name\u0026gt;。 将 \u0026lt;Distribution Name\u0026gt; 替换为要安装的发行版的名称。\n若要查看可通过在线商店下载的可用 Linux 发行版列表，请输入：wsl --list --online 或 wsl -l -o。\n若要在初始安装后安装其他 Linux 发行版，还可使用命令：wsl --install -d \u0026lt;Distribution Name\u0026gt;。\n检查正在运行的 WSL 版本 可列出已安装的 Linux 发行版，并通过在 PowerShell 或 Windows 命令提示符中输入以下命令来检查每个发行版的 WSL 版本：wsl -l -v。\n要在安装新的 Linux 发行版时将默认版本设置为 WSL 1 或 WSL 2，请使用命令 wsl --set-default-version \u0026lt;Version#\u0026gt;，将 \u0026lt;Version#\u0026gt; 替换为 1 或 2。\n要设置与 wsl 命令一起使用的默认 Linux 发行版，请输入 wsl -s \u0026lt;DistributionName\u0026gt; 或 wsl --setdefault \u0026lt;DistributionName\u0026gt;，将 \u0026lt;DistributionName\u0026gt; 替换为要使用的 Linux 发行版的名称。 例如，从 PowerShell/CMD 输入 wsl -s Debian，将默认发行版设置为 Debian。 现在从 Powershell 运行 wsl npm init 将在 Debian 中运行 npm init 命令。\n要在 PowerShell 或 Windows 命令提示符下运行特定的 WSL 发行版而不更改默认发行版，请使用命令 wsl -d \u0026lt;DistributionName\u0026gt;，将 \u0026lt;DistributionName\u0026gt; 替换为要使用的发行版的名称。\n参考：\nhttps://learn.microsoft.com/zh-cn/windows/wsl\n","date":"2023-08-10T00:00:00Z","permalink":"https://msdemt.github.io/p/wsl-install/","title":"wsl 安装"},{"content":"介绍 在使用云主机时，某个用户登录后，可以执行如下命令直接切换到 root 用户\n1 $ sudo su - root sudo 命令需要输入当前用户的密码，su 命令需要输入 root 用户的密码。另外一个区别是其默认行为，sudo 命令只允许使用提升的权限运行单个命令，而 su 命令会启动一个新的 shell，同时允许使用 root 权限运行尽可能多的命令，直到明确退出登录。\nsudo 命令 sudo 命令，全称为 super user do，允许非root用户执行root用户才可以执行的命令。\n要想使一个用户具有使用sudo的能力，需要让root用户将其名字、可以执行的特定命令、按照哪种用户或用户组的身份执行等信息注册到/etc/sudoers文件中，即完成对该用户的授权（此时该用户称为“sudoer”）才可以。\n当一般用户执行特殊权限时，在命令前加上 sudo，此时系统会让你输入密码以确认终端机前操作的是你本人，确认后系统会将该命令的进程以超级用户的权限运行。\n在一定的时间段内，再次执行sudo的命令时不再询问密码，超出此时间段（一般为5分钟）后需要再次输入密码。\n可以配置用户执行sudo时不需输入密码\nsudo配置无密码后，用户就可以使用 sudo su - root 直接免密切换到root 用户了\n无密码 sudo 配置 centos7 配置用户无密码 sudo 修改/etc/sudoers文件，从而让普通用户username支持无密码sudo\n方式一：\nsudo 相关的配置位于 /etc/sudoers 文件内，这个文件不建议直接编辑，而是使用以下命令\n1 sudo visudo 该命令会打开默认的编辑器编辑 /etc/sudoers 文件，并在保存时自动检查文件格式并设置到正确的文件权限。\n进入编辑状态后，在文件的最后面 添加以下内容\n1 username ALL=(ALL) NOPASSWD:ALL username 改成自己的用户名\nNOPASSWD 表示不需要输入密码\nALL 表示所有命令\n也就是，用户在执行所有的 sudo 命令时军不需要输入密码，如果要设置指定命令无需输入密码，只需要把后面的 ALL 替换为具体命令\n方式二：\n手动修改 /etc/sudoers 方式如下\n1 2 3 4 5 6 7 8 $ chmod u+w /etc/sudoers $ vim /etc/sudoers $ diff /etc/sudoers /etc/sudoers.bak 108c108 \u0026lt; username ALL=(ALL) NOPASSWD:ALL --- \u0026gt; $ chmod u-w /etc/sudoers 注意：username ALL=(ALL) NOPASSWD:ALL 需要添加到 # %wheel ALL=(ALL) NOPASSWD: ALL 下面（即文件最后面），否则sudo还是会需要密码的。\n然后，username用户就可以无需密码执行sudo命令了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 [root@centos7-desktop ~]# ll /etc/sudoers -r--r-----. 1 root root 4328 9月 30 2020 /etc/sudoers [root@centos7-desktop ~]# chmod u+w /etc/sudoers [root@centos7-desktop ~]# ll /etc/sudoers -rw-r-----. 1 root root 4328 9月 30 2020 /etc/sudoers [root@centos7-desktop ~]# vim /etc/sudoers [root@centos7-desktop ~]# diff /etc/sudoers /etc/sudoers.bak 108c108 \u0026lt; username ALL=(ALL) NOPASSWD:ALL --- \u0026gt; [root@centos7-desktop ~]# chmod u-w /etc/sudoers [root@centos7-desktop ~]# ll /etc/sudoers -r--r-----. 1 root root 4364 12月 20 15:17 /etc/sudoers [root@centos7-desktop ~]# cat /etc/sudoers ## Next comes the main part: which users can run what software on ## which machines (the sudoers file can be shared between multiple ## systems). ## Syntax: ## ## user MACHINE=COMMANDS ## ## The COMMANDS section may have other options added to it. ## ## Allow root to run any commands anywhere root ALL=(ALL) ALL ## Allows members of the \u0026#39;sys\u0026#39; group to run networking, software, ## service management apps and more. # %sys ALL = NETWORKING, SOFTWARE, SERVICES, STORAGE, DELEGATING, PROCESSES, LOCATE, DRIVERS ## Allows people in group wheel to run all commands %wheel ALL=(ALL) ALL ## Same thing without a password # %wheel ALL=(ALL) NOPASSWD: ALL username ALL=(ALL) NOPASSWD:ALL 配置用户有密码 sudo 若允许用户执行sudo命令（默认sudo命令需要输入用户密码），需将用户添加到 wheel 组，使用如下命令\n1 $ usermod -a -G username wheel 也可以使用\n1 $ gpasswd -a username wheel 此时，username用户执行 sudo ，还需要输入密码。加入wheel用户组，只是允许普通用户能够 sudo -s 切换到 root\n使用如下命令，将用户 username 从 wheel 组删除\n1 $ gpasswd -d username wheel 执行 usermod 或 gpasswd 命令，不会改变 /etc/sudoers 文件内容\n操作记录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 将username添加到wheel组 [root@centos7-desktop etc]# usermod -a -G username wheel # 也可以使用 gpasswd -a username wheel # 使用username用户执行sudo，还是需要输入密码 [username@centos7-desktop ~]$ sudo vi /etc/hosts [sudo] username 的密码： [username@centos7-desktop ~]$ [root@centos7-desktop etc]# diff /etc/sudoers /etc/sudoers.bak [root@centos7-desktop etc]# id username uid=1000(username) gid=1000(username) 组=1000(username),10(wheel) 将username从wheel用户组删除 [root@centos7-desktop etc]# gpasswd -d username wheel 正在将用户“username”从“wheel”组中删除 [root@centos7-desktop etc]# id username uid=1000(username) gid=1000(username) 组=1000(username) [root@centos7-desktop etc]# su 命令 su 是切换用户的命令，后面不加用户，默认切换到root，切换后不改变当前环境变量 su - 是切换用户的同时将环境变量修改为目标用户的环境变量\n使用su切换用户时，需要输入目标用户的密码\n参考：\nhttps://blog.csdn.net/chl183/article/details/108305842\nhttps://zhuanlan.zhihu.com/p/137332644\nhttps://zhuanlan.zhihu.com/p/252345791\n","date":"2023-08-09T00:00:00Z","permalink":"https://msdemt.github.io/p/sudo-su-root/","title":"sudo su - root 介绍"},{"content":"介绍 我们在 linux 上安装软件时,经常会使用如下命令\n1 2 3 ./configure make make install 这些命令是怎么工作的呢？\n这些命令有什么作用？ linux 上使用源码编译安装软件通常有如下三步\n配置软件（Configure the software） configure 脚本负责完成在指定系统上构建软件的准备工作，它确保后续的构建和安装过程中所有需要的依赖可以使用，并且找出使用这些依赖所需的任何信息。\nUnix/Linux 程序经常使用 C 语言编写，所以我们经常需要 C 编译器来构建这些程序。在这个场景下, configure 脚本会确保你的系统中确实存在一个 C 编译器，并且找到这个 C 编译器的名字和位置。\n构建软件（Build the software） 一旦 configure 命令执行完成，我们可以调用 make 命令来构建软件。这个步骤会执行定义在 Makefile 文件中的一系列任务来将软件从源码构建为最终可执行程序。\n你下载的软件源码 tar 包通常不包含最终的 Makefile 文件，而是包含名为 Makefile.in 的模板文件。然后利用 configure 脚本针对当前的系统利用 Makefile.in 文件生成的定制化的 Makefile 文件。\n安装软件（Install the software） 现在软件已经构建完成，可以运行了，相关文件可以被拷贝到它们的最终目录。 make install 命令会将构建出的可执行文件和它的依赖库、文档拷贝到正确的位置。\n这通常意味着软件的二进制文件会被拷贝到你的 PATH 路径下，软件的操作手册会被拷贝到你的 MANPATH 路径下，同时软件依赖的其他文件也会被安全地保存到相应的位置。\n因为安装步骤也是定义在 Makefile 文件中，所以软件的安装位置可以通过某个参数传递给 configure 脚本，或者由 configure 脚本利用某个系统变量来实现指定安装位置。\n根据软件的安装位置，您可能需要升级此步骤的权限，以便可以将文件复制到系统目录。 使用 sudo 通常可以达到目的。\n这些脚本是怎么产生的？ 上述步骤之所以能成功工作，是因为 configure 脚本会检查你的系统，并使用它找到的信息将 Makefile.in 模板转换为 Makefile 文件，但是 configure 脚本和 Makefile.in 模板是怎么产生的呢？\n如果你曾经打开过 configure 脚本，或者相关的 Makefile.in 文件，你会发现这些文件里包含几千行的脚本语句。有时候这些支持配置的脚本语句比要安装的程序的源代码还要长。\n即使利用已有的 configure 脚本文件开始编写，手动编写完成一个 configure 脚本也是非常艰巨的。不过不用担心：这些脚本不是手工构建的。\n以这种方式构建的软件通常使用一个叫做 autotools 的工具集进行打包。这个工具集包含 autoconf、automake 等工具，所有的这些工具使得维护软件生命周期变得很容易。最终用户不需要了解这些工具，同时让软件在不同的 Unix/Linux 系统的安装步骤变得简单。\nHello World 案例 我们以一个简单的 Hello World C 语言程序为例，来看看如何使用 autotools 工具集打包。\n下面是程序源代码，在一个名为 main.c 的文件中\n1 2 3 4 5 6 7 #include \u0026lt;stdio.h\u0026gt; int main(int argc, char* argv[]) { printf(\u0026#34;Hello World\\n\u0026#34;); return 0; } 创建 configure 脚本 不需要手动编写 configure 脚本，我们需要创建一个使用 m4sh 语言（m4 宏命令和 POSIX shell 脚本的组合）编写的 configure.ac 文件来描述 configure 脚本需要做的事情。\n我们需要第一个调用的 m4 宏为 AC_INIT，它会初始化 autoconf 并且设置一些关于打包软件的基本信息。我们的软件名为 helloworld，版本为 0.1，维护者为 george@thoughtbot.com：\n1 AC_INIT([helloworld], [0.1], [george@thoughtbot.com]) 这个项目中我们会使用 automake，所以我们需要使用 AM_INIT_AUTOMAKE 宏命令来初始化 automake\n1 AM_INIT_AUTOMAKE 下面，我们需要告诉 autoconf 让 configure 脚本需要寻找的相关依赖，在本例中， configure 脚本仅需要使用 C 编译器，我们可以使用 AC_PROG_CC 宏命令设置。\n1 AC_PROG_CC 如果有其他的依赖项，那我们可以使用其他的 m4 宏命令来设置，如使用 AC_PATH_PROG 宏表示在用户的 PATH 路径中搜索一个特定的程序。\n此时我们已经列出了使用的依赖，前面有提到，configure 脚本会根据用户系统的系统信息和 Makefile.in 模板文件生成 Makefile 文件。\n下面一行使用 AC_CONFIG_FILES 宏命令告诉 autoconf 工具 configure 脚本文件需要做这些工作：configure 脚本文件需要找到一个名为 Makefile.in 的文件，将文件内的站位符使用对应的值替换，例如将 @PACKAGE_VERSION@ 替换为 0.1，然后将结果写入到 Makefile 文件。\n1 AC_CONFIG_FILES([Makefile]) 最后，当我们告诉 autoconf 工具所有 configure 脚本需要做的工作后，可以调用 AC_OUTPUT 宏命令输出脚本内容\n1 AC_OUTPUT 下面是 configure.ac 中的所有代码，相比 4737 行的 configure 脚本文件，这些代码好多了。\n1 2 3 4 5 AC_INIT([helloworld], [0.1], [george@thoughtbot.com]) AM_INIT_AUTOMAKE AC_PROG_CC AC_CONFIG_FILES([Makefile]) AC_OUTPUT 还差一点我们就可以发布软件了，configure 脚本需要一个 Makefile.in 文件，将系统相关信息填充进去后，生成最终的 Makefile 文件。\n创建 Makefile 文件 与 configure 脚本文件相比，Makefile.in 模板文件非常长且复杂。因此，我们不是手工编写，而是编写一个较短的 Makefile.am 文件，然后利用automake 使用该文件为我们生成 Makefile.in 文件。\n首先，我们需要设置一些参数来告诉 automake 工具本项目的结构，因为这里的例子不是标准的 GNU 项目的结构，所以结构声明为 foreign 。\n1 AUTOMAKE_OPTIONS = foreign 接下来告诉 automake 我们希望 Makefile 编译的软件名为 helloworld:\n1 bin_PROGRAMS = helloworld 这行包含了很多打包信息，感谢 automake 的统一命名规则\nPROGRAMS 后缀成为 primary 主要信息，它告诉 automake 工具 helloworld 文件具有哪些属性。例如 PROGRAMS 需要被编译，相比 SCRIPTS 和 DATA 文件不需要被编译。\nbin 前缀告诉 automake 工具，这里列出的文件应该被安装到 bindir 变量指定的路径下。 autotools 工具还为我们定义了其他目录，包括 bindir , libdir , pkglibdir ，我们也可以自定义自己需要的目录。\n如果我们的程序有一部分是 Ruby 脚本，我们可以定义 rubydir 变量并且告诉 automake 安装我们的 ruby 文件到该路径。\n1 2 rubydir = $(datadir)/ruby ruby_DATA = my_script.rb my_other_script.rb 可以在安装目录之前添加其他前缀，以进一步区分 automake 的行为。\n因为我们已经定义了 RPOGRAM ，我们需要告诉 automake 在哪里可以找到它的源文件。 在这种情况下，前缀是这些源文件构建的程序的名称，而不是它们将安装的位置：\n1 helloworld_SOURCES = main.c 这是我们的 helloworld 程序的整个 Makefile.am 文件。 与 configure.ac 和 configure 脚本一样，它比它生成的 Makefile.in 要短得多：\n1 2 3 AUTOMAKE_OPTIONS = foreign bin_PROGRAMS = helloworld helloworld_SOURCES = main.c 把它们放在一起 现在我们已经编写了配置文件，我们可以运行 autotools 并生成完成的 configure 脚本和 Makefile.in 模板。\n首先，我们需要生成一个 m4 环境供 autotools 使用：\n1 aclocal 现在我们可以运行 autoconf 将 configure.ac转换为configure脚本，并运行automake将Makefile.am转换为Makefile.in`：\n1 2 autoconf automake --add-missing 分发程序 最终用户不需要查看我们的 autotools 工具的设置，因此我们可以分发 configure 脚本和 Makefile.in，而无需分发用于生成它们的所有文件。\n幸运的是，autotools 工具也将帮助我们进行分发。 Makefile 包含各种有趣的目标，包括构建项目 tarball 的目标，其中包含我们需要分发的所有文件：\n1 2 ./configure make dist 您甚至可以测试分发 tarball 是否可以在各种条件下安装：\n1 make distcheck 总览 现在我们知道编译安装命令从何而来以及它是如何运作的！\n在维护者的系统上：\n1 2 3 4 5 aclocal # Set up an m4 environment autoconf # Generate configure from configure.ac automake --add-missing # Generate Makefile.in from Makefile.am ./configure # Generate Makefile from Makefile.in make distcheck # Use Makefile to build and test a tarball to distribute 在最终用户的系统上：\n1 2 3 ./configure # Generate Makefile from Makefile.in make # Use Makefile to build the program make install # Use Makefile to install the program 参考：\nhttps://zhuanlan.zhihu.com/p/77813702\nhttps://thoughtbot.com/blog/the-magic-behind-configure-make-make-install\n","date":"2023-08-03T00:00:00Z","permalink":"https://msdemt.github.io/p/configure-make-makeinstall/","title":"configure、make、make install 如何工作?"},{"content":"介绍 本文在 centos7 系统上安装 nginx，nginx 有两种安装方式，yum 安装和源码编译安装。\nyum安装 yum 安装后会将 nginx 的文件放在系统的不同位置,可以使用 rpm -ql nginx 或 whereis nginx 查看安装路径\n卸载的话,使用yum remove nginx 命令来卸载\n安装 nginx\n1 $ sudo yum -y install nginx 卸载 nginx\n1 $ sudo yum remove nginx 使用 yum 安装 nginx 时, nginx 配置文件在 /etc/nginx 目录\n配置 nginx 服务\n1 2 3 4 5 6 7 8 9 10 # 设置开机启动 $ sudo systemctl enable nginx # 启动 nginx 服务 $ sudo service nginx start # 停止 nginx 服务 $ sudo service nginx stop # 重启 nginx 服务 $ sudo service nginx restart # 重新加载配置，一般是在修改过 nginx 配置文件时使用 $ sudo service nginx reload 此外,还有\n1 2 3 4 # 检查 nginx 配置是否正确 $ nginx -t # 重新加载配置 $ ngxin -s reload 源码编译安装 使用 rpm -qa | grep nginx 查询 nginx 安装包,然后使用 rpm -e nginx 卸载, 如果提示存在依赖无法卸载,可以使用 rpm -e --nodeps nginx 强制卸载\n安装依赖库 安装 gcc 环境\n1 2 # nginx编译时依赖 gcc 环境 $ sudo yum -y install gcc gcc-c++ 安装 pcre\n1 2 # 让 nginx 支持重写功能 $ sudo yum -y install pcre pcre-devel 安装 zlib\n1 2 # zlib 库提供了很多压缩和解压缩的方式，nginx 使用 zlib 对 http 包内容进行 gzip 压缩 $ sudo yum -y install zlib zlib-devel 安装 openssl\n1 2 # 安全套接字层密码库，用于通信加密 $ sudo yum -y install openssl openssl-devel 编译安装 下载 nginx 源码包\n1 $ sudo curl -O https://nginx.org/download/nginx-1.24.0.tar.gz 解压\n1 $ sudo tar -zxf nginx-1.24.0.tar.gz 进入解压后的目录,配置环境\n1 2 $ cd nginx-1.24.0 $ ./configure --prefix=/usr/local/nginx --prefix=/usr/local/nginx 指定 nginx 编译安装的目录,安装后会在此目录下生成 nginx 相关文件\n编译安装\n1 2 3 4 # 编译 $ make # 安装 $ make install 编译安装后的操作命令和 yum 安装的不同\n启动服务\n1 $ /usr/local/nginx/sbin/nginx 检查 nginx 配置\n1 $ /usr/local/nginx/sbin/nginx -t 重新加载服务\n1 $ /usr/local/nginx/sbin/nginx -s reload 停止服务\n1 $ /usr/local/nginx/sbin/nginx -s stop 查看 nginx 服务进程\n1 $ ps -ef|grep nginx 参考:\nhttps://juejin.cn/post/6844904134345228301\nhttps://blog.csdn.net/weixin_53187893/article/details/115090825\nhttps://segmentfault.com/a/1190000007116797\n","date":"2023-08-02T00:00:00Z","image":"https://msdemt.github.io/p/nginx-install/nginx-ar21.svg","permalink":"https://msdemt.github.io/p/nginx-install/","title":"centos7系统安装nginx"},{"content":"介绍 ssh 有三种方式可以跳转登录，分别是：ProxyJump、ProxyCommand、SSH Tunnel。\n在某些场景下，SSH无法直接访问服务器，需要通过其他服务器进行代理访问，比如外网服务器访问仅允许使用VPN或4A访问的内网服务器。在这种场景下，常用的方式是端口转发，使用端口转发建立连接，然后再做访问。如果面临更多服务器，就需要建立多个端口转发连接，比较麻烦。\nProxyJump 可以使用SSH提供的ProxyJump参数，进行代理服务跳转，简化登录流程，ProxyJump简写参数是 -J 。\n在 openssh7.3 以上的版本，开始支持 ProxyJump 。\nProxyJump可以在命令行执行，也可以写在配置文件（~/.ssh/config）中。\n命令行执行语法\n1 $ ssh -J user@proxyserver1,user@proxyserver2 user@targetserver 使用命令行时需要逐个输入代理服务器的密码。\n可以使用config配置文件和ssh密钥文件，简化登录流程，\n配置文件（~/.ssh/config）语法\n1 2 3 4 5 6 7 8 9 10 11 12 Host ProxyServer Hostname \u0026lt;jump_server ip\u0026gt; Port \u0026lt;jump_server port\u0026gt; User \u0026lt;jump_server user\u0026gt; IdentityFile \u0026lt;jump_server id_rsa\u0026gt; Host target HostName \u0026lt;target_server ip\u0026gt; Port \u0026lt;target_server port\u0026gt; User \u0026lt;target_server user\u0026gt; IdentityFile \u0026lt;target_server id_rsa\u0026gt; ProxyJump ProxyServer 配置之后，在终端执行 ssh target 即可ssh到目标服务器\nProxyCommand 若不支持ProxyJump，可以使用ProxyCommand\n-W host:port #将client过来的标准输入和输出forward到host和port指定的地方. 可以看到,这个选项直接就可以搭配上ProxyCommand的需求\nProxyCommand 命令行语法\n1 ssh username@target_server_ip -p 22 -o ProxyCommand=\u0026#39;ssh -p 22 username@jump_server_ip -W %h:%p\u0026#39; 同样可以在~/.ssh/config增加配置\n1 2 3 4 5 6 7 8 9 10 11 Host ProxyServer Hostname \u0026lt;jump_server ip\u0026gt; Port \u0026lt;jump_server port\u0026gt; User \u0026lt;jump_server user\u0026gt; IdentityFile \u0026lt;jump_server id_rsa\u0026gt; Host target HostName \u0026lt;target_server ip\u0026gt; Port \u0026lt;target_server port\u0026gt; User \u0026lt;target_server user\u0026gt; ProxyCommand ssh -p 22 -W %h:%p ProxyServer 参考：\nhttps://qusec.cn/posts/sssh/\nhttps://peirs.net/sshs-proxyjump-parameter/\nhttps://murphypei.github.io/blog/2021/12/ssh-proxyjump\nhttps://www.jianshu.com/p/199013854070\nhttps://zhuanlan.zhihu.com/p/74193910\nhttps://blog.csdn.net/wxqee/article/details/49234595\nhttps://www.jianshu.com/p/ad5aa9663d37\nhttps://juejin.cn/s/ssh%20config%20proxyjump%20windows\n","date":"2023-07-28T00:00:00Z","image":"https://msdemt.github.io/p/ssh-proxy/Linux-Symbole-2048x1158_hu6f8b26c03cc6e65572403f8d94a50599_544049_120x120_fill_box_smart1_3.png","permalink":"https://msdemt.github.io/p/ssh-proxy/","title":"SSH-ProxyJump跳转登录"},{"content":"介绍 在Linux系统上，常见的输入法有 IBus(Intelligent Input Bus)、XIM(X Input Method)、Fcitx(FlexibleInput Method Framework)。\nFcitx: 支持谷歌拼音、搜狗拼音、五笔 IBus: 支持只能拼音，五笔 XIM: 略（用的比较少） 安装 ubuntu18.04系统中，已自带IBus和XIM输入法框架\n本文在ubuntu18.04上安装fcitx输入法框架\n安装方法\n检查fcitx是否已安装 1 fcitx --version 安装fcitx框架 1 sudo apt install -y fcitx-bin 安装fcitx默认输入法，fcitx-table中包含了拼音输入法（fcitx-pinyin），可以安装fcitx-table-all，包含了五笔输入法。 1 sudo apt install -y fcitx-table 安装谷歌拼音输入法 1 sudo apt install -y fcitx-googlepinyin 配置fcitx ubuntu设置\u0026mdash;区域和语言\u0026mdash;管理已安装语言\u0026mdash;键盘输入法系统中选择fcitx 重启ubuntu系统\n安装记录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 test@00bafcjc-durwemo9n5:~$ fcitx --version Command \u0026#39;fcitx\u0026#39; not found, but can be installed with: sudo apt install fcitx-bin test@00bafcjc-durwemo9n5:~$ sudo apt install fcitx-bin ... ... test@00bafcjc-durwemo9n5:~$ sudo apt install -y fcitx-table 正在读取软件包列表... 完成 正在分析软件包的依赖关系树 正在读取状态信息... 完成 将会同时安装下列软件： fcitx-pinyin 建议安装： fcitx-table-all 下列【新】软件包将被安装： fcitx-pinyin fcitx-table 升级了 0 个软件包，新安装了 2 个软件包，要卸载 0 个软件包，有 0 个软件包未被升级。 test@00bafcjc-durwemo9n5:~$ sudo apt install -y fcitx-googlepinyin ... ... test@00bafcjc-durwemo9n5:~$ fcitx --version fcitx version: 4.2.9.6 问题 输入法图标问题\n重启后，可以在ubuntu界面右上角看到fcitx的小键盘图标，如果之前配置使用过IBus输入法，此时右上角会有两个输入法图标。\n解决：ubuntu设置\u0026mdash;区域和语言\u0026mdash;输入源 中删除汉语，只保留英语(美国)，这样默认的输入法图标就消失了。\n参考：\nhttps://leimao.github.io/blog/Ubuntu-Gaming-Chinese-Input/\n中英文切换问题\nfcitx使用中，无法shift切换中英文\n原因：点击右上角fcitx小键盘图标\u0026mdash;配置\u0026mdash;输入法 中只配置了 Google拼音 输入法。\nUbuntu下所谓的中英文切换就是一个输入法系统的中文输入法切换到其中的英文输入法，所以一定要保证输入法系统中既有中文输入法也要有英文输入法。 所以，添加 键盘-英语(美国) 输入法。 此外，在 全局配置\u0026mdash;快捷键 中，切换激活/非激活输入法 使用 Lshift ，额外的激活输入法快捷键 选择 左Shift\n参考：\nhttps://blog.csdn.net/yucicheung/article/details/79331529\nidea快捷键冲突问题\n使用idea时，无法使用快捷键 Ctrl+Shift+F，原因该键被fcitx的简繁转换功能占用\n解决： 点击右上角fcitx小键盘图标\u0026mdash;配置\u0026mdash;附加组件，取消简繁转换\n谷歌拼音输入法无法输出中文中括号（【】）\n使用谷歌拼音输入法输出中文中括号时，输出的是·「·」\n解决办法：\n查看 fcitx 的版本: fcitx --version fctix 使用的是 4 版本 编辑 /usr/share/fcitx/data/punc.mb.zh_CN，将第18行修改为 [ 【，将第19行修改为 ] 】 fcitx 使用的是 5 版本 编辑 /usr/share/fcitx5/punctuation/punc.mb.zh_CN 重启 fcitx 误点击 ctrl+. 导致切换到全角输入法\n使用谷歌拼音时，不小心点击了 ctrl+.，切换到了全角字母，导致输出的空格、中划线等不符合预期。\n解决：\n在谷歌拼音-全局配置-显示高级选项-Hotkey-Switch Full Width Punc Mode-将快捷键置为空 附加组件-高级-取消选中全角字符 重启 fcitx 参考：\nhttps://zhuanlan.zhihu.com/p/508797663\nhttps://zhuanlan.zhihu.com/p/529892064\nhttps://leimao.github.io/blog/Ubuntu-Gaming-Chinese-Input/\nhttps://blog.csdn.net/chen462488588/article/details/109290855\nhttps://blog.csdn.net/u010168781/article/details/80033701\nhttps://zhuanlan.zhihu.com/p/163805070\n","date":"2023-07-27T00:00:00Z","image":"https://msdemt.github.io/p/ubuntu-fcitx/ubuntu_logo_hu373a6c33440a9fb65cfc39e6a6372242_135517_120x120_fill_box_smart1_3.png","permalink":"https://msdemt.github.io/p/ubuntu-fcitx/","title":"ubuntu18.04安装fcitx输入法框架"},{"content":"介绍 工作中，生产环境的服务器是无法直接访问的，通常需要4A，访问比较麻烦，可以使用 ssh隧道 简化登录流程。\n如下图\nssh登录4A后，无法直接访问 server-2，可以通过 server-1 服务器代理访问。\n具体流程\nssh登录4A，新建隧道 使用4A的隧道作为代理，ssh访问server-1服务器,在server-1上新建隧道 使用server-1隧道代理访问server-2服务器 使用bitvise配置 安装bitvise ssh client，下载地址：https://www.bitvise.com/download-area\n新开一个bitvise页面，假设4A系统内网IP为192.168.15.45:10011，添加用户名、密码等登录信息，点击Save profile，将该配置保存。\n新开一个bitvise页面，填入server-1的IP、端口和登录信息，在 Proxy settings 中，选择第二步保存的4A配置文件，这样就可以使用4A作为代理访问server-1了。（第二步不需要登录了） 因为的目标服务器server-2还需要使用server-1代理才可以访问，所以还需要打开Services选项卡，勾选SOCKS/HTTP Proxy Forwarding，将本地空闲的端口如1079填入Listen Port；\n点击Login，登录到server-1服务器\n打开一个新的bitvise页面，填入目标服务器 server-2 的IP、端口和登录信息，Proxy Setting配置使用server-1服务器开放的1079代理端口。 为了能够访问 server-2 服务器上的网页服务，比如jenkins，还需要在Services标签页中开放代理，比如使用本地未使用的端口1080作为代理端口\n本地浏览器可以使用SwitchyOmega插件，将目标服务器上的jenkins等地址配置使用127.0.0.1:1080代理访问。 使用finalshell配置 bitvise仅支持windows系统，如果在linux（如：ubuntu）上访问目标服务器，可以使用finalshell\n建立4A SSH连接，配置隧道，类型：本地，监听端口：本地未占用的某个端口，如1078；绑定IP: 127.0.0.1，绑定本地IP；目标地址：使用该隧道访问的地址，此处为server-1服务器地址 10.246.100.5；目标端口：目标地址对应的端口，此处为 10000 建立server-1的SSH连接，主机和端口使用4A连接隧道中的绑定ip和监听端口，同时还需建立隧道，供访问server-2服务器代理。 建立目标服务器server-2的SSH连接，同理，主机和端口填入server-1隧道的绑定ip和监听端口，这样就能访问到目标服务器了（需要同时开启4A和server-1的ssh连接），为了访问目标服务器上的网页，还需要在该连接上新建socks5代理隧道 本地浏览器可以使用SwitchyOmega插件，将目标服务器上的jenkins等地址配置使用127.0.0.1:1080代理访问。 使用ProxyJump配置 在linux系统上，也可以使用ProxyJump实现访问server-2服务器，缺点：无法配置socks5代理实现访问目标服务器的网页服务。\n如果想在 Windows 上使用 ssh 的 proxyjump 功能，需要使用一个支持该功能的 ssh 客户端。推荐使用 OpenSSH 。\nWindows 安装 OpenSSH 参考：\nhttps://learn.microsoft.com/zh-cn/windows-server/administration/openssh/openssh_install_firstuse\n在 $HOME/.ssh/config 文件新增如下内容 1 2 3 4 5 6 7 8 9 10 11 12 13 Host 55.250.10.20 HostName 55.250.10.20 User test Port 10000 IdentityFile /opt/develop/ssh/id_rsa ProxyJump test@10.246.110.5:10000 Host 10.246.110.5 HostName 10.246.110.5 User test Port 10000 IdentityFile /opt/develop/ssh/id_rsa ProxyJump abc@192.168.15.45:10011 在终端输入 ssh 55.250.10.20，然后输入abc用户的密码，即可ssh连接到 server-2 服务器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 user@00bafcjc-durwemo9n5:~/.ssh$ ssh 55.250.10.20 abc@192.168.15.45\u0026#39;s password: The authenticity of host \u0026#39;[55.250.10.20]:10000 (\u0026lt;no hostip for proxy command\u0026gt;)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is SHA256:TJctlnqugvdS+y7uP9M6DPjoiFHjBBYS9FtwBKBmHFk. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;[55.250.10.20]:10000\u0026#39; (ECDSA) to the list of known hosts. Linux host-55 5.10.0-18-amd64 #1 SMP Debian 5.10.140-1 (2022-09-02) x86_64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Tue Jul 25 14:12:14 2023 from 10.63.143.23 secure@host-55:~$ ","date":"2023-07-19T00:00:00Z","image":"https://msdemt.github.io/p/ssh-tunnel/Linux-Symbole-2048x1158_hu6f8b26c03cc6e65572403f8d94a50599_544049_120x120_fill_box_smart1_3.png","permalink":"https://msdemt.github.io/p/ssh-tunnel/","title":"多级ssh访问内网服务器"},{"content":"问题 使用hugo-theme-stack主题时，将项目部署到github pages上后，发现categories图片无法显示\n解决 在静态网页项目根目录下新建名为 .nojekyll 的文件。\n或者在hugo项目中static目录下新建名为 .nojekyll 的文件。\n原因 Github Pages 默认是基于 Jekyll 构建，Jekyll 是一个将纯文本转换为静态网站的工具，它构建的网站下各种目录都是特定的以下划线开头命名的文件夹，例如 _layouts、_posts ，它会忽略掉其它的以下划线开头的文件夹和文件。\n.nojekyll 就是告诉 Github Pages 当前网站不是基于 Jekyll 构建的，不要忽略掉下划线开头的文件和文件夹。\n可见 .nojekyll 主要就是用于 Github Pages 这种有默认规则的网站部署平台，如果是部署在自己的服务器上，可以把它删掉。\n反之，如果你的网站不是 Jekyll 构建的，要部署到 Github Pages ，并且包含下划线开头的文件或文件夹，那么你就需要在根目录添加一个 .nojekyll 空文件。\n参考：\nhttps://github.com/CaiJimmy/hugo-theme-stack/issues/726\nhttps://www.cnblogs.com/babywhale/p/13560573.html\n","date":"2023-07-07T00:00:00Z","permalink":"https://msdemt.github.io/p/github-pages-image/","title":"github pages无法显示图片"},{"content":"git的4个区 工作区（Working Area） 相当于工作空间的目录，即代码的存放位置\n暂存区（Stage） 也称为 index ，用来跟踪已暂存文件，一般存在 .git 下的 index 文件，所以有时也称暂存区为索引。\n本地仓库（Local Repository）\n远程仓库（Remote Repository）\ngit文件的5种状态 未修改（Origin） 已修改（Modified） 已暂存（Staged） 已提交（Committed） 已推送（Pushed） 工作区中文件的初始状态是 未修改，当我们修改文件后，其状态变为 已修改，git diff 命令可以查看已修改但未暂存的文件。（git diff后输入 q 可以退出） 通过 git add 命令可以把已修改的文件添加到暂存区，git diff --cached 可以查看已暂存但未提交的文件。 通过 git commit 将代码提交到本地仓库，git diff [本地分支] [远程分支] 可以查看已提交本地，但未推送到远程分支的文件。 通过 git push 命令将本地分支推送到远程分支。 回退相关命令 git reset 命令 git reset 是进行回退的具体命令，参数介绍如下\n--soft: 仅仅将头指针恢复，已经 add 的暂存区及工作空间的文件修改不变。 --mixed: 将头指针恢复，已经 add 的暂存区也会恢复 ，工作空间的代码修改不变。 --hard: 头指针、暂存区和工作空间的修改都会恢复。 git log 命令 git log 命令查看git的提交记录，但无法查看已经删除的记录。\ngit reflog 命令 git reflog 命令可以查看所有分支的所有操作记录（包括commit和已被删除的commit记录）\n回退操作 回退操作命令\n将已修改或暂存但未提交的文件回退: git reset --hard 将已提交未推送的版本回退: git reset --hard origin/master 将已提交且推送的版本回退： 回退到某个版本：git reset --hard \u0026lt;版本号\u0026gt; 将回退的版本强制推送到远程仓库：git push -f --hard 可以替换为其他恢复等级，一般使用 --soft，这样修改的内容不会丢失\n版本号可以使用 git log 或 git reflog 查看，如 git reset --hard 811aesfi8\ngit reset --hard \u0026lt;版本号\u0026gt; 也可以替换为 git reset --hard HEAD\n回退到当前版本：git reset --hard HEAD 回退到上一个版本：git reset --hard HEAD^ 回退到上两个版本：git reset --hard HEAD^^ 回退到上三个版本：git reset --hard HEAD^^^ 回退到上十个版本：git reset --hard HEAD~10 git 远程覆盖本地 可以执行如下命令将远程仓库的代码直接覆盖本地仓库\ngit fetch \u0026ndash;all git reset \u0026ndash;hard origin/main git pull git fetch 是下载远程仓库的内容，不做任务的合并\ngit reset 把 HEAD 指向刚刚下载的最新版本\n参考：\nhttps://blog.csdn.net/qing040513/article/details/109150075 https://blog.csdn.net/gercke/article/details/119085963\n","date":"2023-07-07T00:00:00Z","image":"https://msdemt.github.io/p/git-rollback/1_Wjxx83j-qyiNvFBy1yOA1w_hufb4407888dbfcda01762496277a1213f_11862_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://msdemt.github.io/p/git-rollback/","title":"git回退版本"},{"content":"添加代理 1 2 3 4 5 6 7 //http || https git config --global http.proxy http://127.0.0.1:7890 git config --global https.proxy https://127.0.0.1:7890 //sock5代理 git config --global http.proxy socks5://127.0.0.1:7891 git config --global http.proxy socks5://127.0.0.1:7891 只针对github配置代理\n1 2 3 4 5 6 7 8 #使用socks5代理（推荐） git config --global http.https://github.com.proxy socks5://127.0.0.1:7890 #使用http代理（不推荐） git config --global http.https://github.com.proxy http://127.0.0.1:7890 #取消socks5代理 git config --global --unset http.https://github.com.proxy #取消http代理 git config --global --unset http.https://github.com.proxy 查看代理 1 2 git config --global --get http.proxy git config --global --get https.proxy 取消代理 1 2 git config --global --unset http.proxy git config --global --unset https.proxy clash for windows 代理 clash for windows 的 http 和 socks5 代理使用的是同一个端口。\n参考：\nhttps://blog.csdn.net/weimeibuqieryu/article/details/106793645 https://github.com/Fndroid/clash_for_windows_pkg/issues/1244\n","date":"2023-07-07T00:00:00Z","image":"https://msdemt.github.io/p/git-proxy/1_Wjxx83j-qyiNvFBy1yOA1w_hufb4407888dbfcda01762496277a1213f_11862_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://msdemt.github.io/p/git-proxy/","title":"git设置代理"},{"content":"添加子模块 1 git submodule add \u0026lt;url\u0026gt; \u0026lt;path\u0026gt; url为子模块git路径 path为子模块存储的目录路径\n如，将 hugo-theme-stack 项目作为子模块添加到本地项目的 themes 目录\n1 git submodule add https://github.com/CaiJimmy/hugo-theme-stack.git themes 子模块添加成功后，执行 git status 命令可以看到 .gitmodules 文件已被修改，并新增了一个子模块\n执行 git diff --cached 命令可以查看修改内容\n执行 git commit 命令可以将子模块添加到本地仓库\n添加子模块时使用 -b 参数指定分支\n1 git submodule add -b main [URL to Git repo]; 若子模块已添加，可以在 .gitmodules 中设置分支，其中 public 是主模块中安装子模块的名称， stable 是对应要设置的分支名称。\n1 git config -f .gitmodules submodule.public.branch stable 执行后，会在 .gitmodules 中的子模块添加分支（branch = main），如下\n1 2 3 4 [submodule \u0026#34;public\u0026#34;] path = public url = https://github.com/msdemt/msdemt.github.io.git branch = main 使用子模块 直接克隆包含子模块的项目时，子模块目录下没有任何文件，需要在项目的根目录下执行如下命令，完成子模块的下载\n1 2 git submodule init git submodule update 或者\n1 git submodule update --init 克隆项目的同时下载子模块\n1 git clone \u0026lt;url\u0026gt; --recursive 更新子模块 子模块的维护者更新子模块后，使用子模块的项目必须手动更新子模块才可以使用最新的子模块。\n在项目中，进入子模块目录下，执行 git pull 更新，执行 git log 可以查看子模块的更新内容。\n之后进入项目根目录，使用 git add 和 git commit 命令将子模块更新到项目中，然后使用 git push 命令将更新子模块的项目推送到远程仓库。\n如果自己要修改子模块内容，需要先在子模块根路径下执行 git checkout \u0026lt;分支名\u0026gt; ，然后才可以对该子模块进行修改和提交，否则git push提交时出现Everything up-to-date。\n将子模块修改提交后，如果希望将项目依赖的子模块更新到最新版本，需要在项目根路径下执行 git submodule update --remote，然后将项目提交到远程仓库。\n删除子模块 使用 git submodule deinit \u0026lt;子模块名称\u0026gt; 和 git rm \u0026lt;子模块名称\u0026gt; 命令卸载一个子模块。\n如果添加 \u0026ndash;force 参数，则子模块工作区内即使有本地的修改，也会被移除。\n例如，删除名为 test-submodule 子模块\n1 2 git submodule deinit test-submodule git rm test-submodule 如果完全删除子模块，还需要删除项目根路径下的 .gitmodules 文件和 .git/modules 目录下的子模块文件\n问题 子模块更新分支 添加子模块\n1 git submodule add https://github.com/msdemt/msdemt.github.io.git public 子模块更新后，在父模块中更新子模块到最新版本\n1 git submodule update --remote 更新失败，错误如下\n1 2 fatal: Needed a single revision 无法在子模组路径 \u0026#39;public\u0026#39; 中找到当前版本 origin/maste 发现父模块依赖的子模块分支为master，正确应该是main分支（子模块项目初始分支是master，后来我新增了main作为默认分支，删掉了master分支）\n参考：https://blog.csdn.net/weboof/article/details/108517187\n更新子模块的分支\n1 git config -f .gitmodules submodule.public.branch main 再执行更新子模块\n1 git submodule update --remote 参考：\nhttps://blog.csdn.net/guotianqing/article/details/82391665 https://blog.csdn.net/Lee_queenie/article/details/127386151\n","date":"2023-07-07T00:00:00Z","image":"https://msdemt.github.io/p/git-submodule/1_Wjxx83j-qyiNvFBy1yOA1w_hufb4407888dbfcda01762496277a1213f_11862_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://msdemt.github.io/p/git-submodule/","title":"git子模块操作"},{"content":"介绍 在 ubuntu 上使用 vscode 时，默认的字体（ Droid Sans Mono）很不好看。 Windows 上的 vscode 默认字体是微软的 Consolas ，比 Droid Sans Mono 好看很多，而且 JetBrains 出了免费字体 JetBrains Mono，也十分好看。\n本文将 JetBrains Mono 安装到 u`buntu 中，并且配置 vscode 使用该字体。\n安装字体 JetBrains Mono 字体下载地址： https://www.jetbrains.com/lp/mono/\n下载后，解压\n1 sudo unzip JetBrainsMono-2.242.zip -d /usr/share/fonts/JetBrains-Mono 字体目录的权限需要为 755\n1 sudo chmod -R 755 /usr/share/fonts/JetBrains-Mono 字体文件权限需要为644\n1 sudo chmod -R 644 /usr/share/fonts/JetBrains-Mono/* 更新系统字体缓存\n1 sudo fc-cache -fv 检查\n1 fc-list | grep JetBrains vscode添加字体 设置 - 文本编辑器 - 字体 - Font Family\n将Jetbrains Mono字体添加到行首，如下\n1 \u0026#39;Jetbrains Mono\u0026#39;, \u0026#39;Droid Sans Mono\u0026#39;, \u0026#39;monospace\u0026#39;, monospace 或直接在 settings.json 中添加\n1 \u0026#34;editor.fontFamily\u0026#34;: \u0026#34;\u0026#39;Jetbrains Mono\u0026#39;, \u0026#39;Droid Sans Mono\u0026#39;, \u0026#39;monospace\u0026#39;, monospace\u0026#34;, 重启 vscode ，就可以使用 Jetbrains Mono 字体了。\n对应 settings.json 中会设置如下\n1 2 3 \u0026#34;editor.fontLigatures\u0026#34;: true, // 是否启用字体连字 \u0026#34;editor.fontSize\u0026#34;: 18, // 设置字体大小 \u0026#34;editor.fontFamily\u0026#34;: \u0026#34;\u0026#39;Jetbrains Mono\u0026#39;,\u0026#39;Droid Sans Mono\u0026#39;, \u0026#39;monospace\u0026#39;, monospace\u0026#34;, vscode调整桌面字体大小\n1 \u0026#34;window.zoomLevel\u0026#34;: 1, 字体位置 ubuntu 字体位置\n用户字体文件：~/.local/share/fonts 系统字体文件：/usr/share/fonts 字体配置文件：/etc/fonts ","date":"2023-07-07T00:00:00Z","image":"https://msdemt.github.io/p/ubuntu-vscode-font/ubuntu_logo_hu373a6c33440a9fb65cfc39e6a6372242_135517_120x120_fill_box_smart1_3.png","permalink":"https://msdemt.github.io/p/ubuntu-vscode-font/","title":"ubuntu 配置 vscode 字体"},{"content":"题 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。\n你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。\n你可以按任意顺序返回答案。\n示例 1：\n输入：nums = [2,7,11,15], target = 9 输出：[0,1] 解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。\n解 暴力枚举法 1 2 3 4 5 6 7 8 9 10 11 public static int[] twoSum(int[] nums, int target) { int n = nums.length; for(int i=0; i\u0026lt;n; ++i){ for(int j=i+1; j\u0026lt;n; ++j){ if(nums[i] + nums[j] == target){ return new int[]{i, j}; } } } return new int[0]; } 复杂度分析\n时间复杂度：O(N^2)，其中 N 是数组中的元素数量。最坏情况下数组中任意两个数都要被匹配一次。 空间复杂度：O(1) 哈希表 1 2 3 4 5 6 7 8 9 10 public static int[] twoSum1(int[] nums, int target) { Map\u0026lt;Integer, Integer\u0026gt; hashtable = new HashMap\u0026lt;Integer, Integer\u0026gt;(); for(int i=0; i\u0026lt;nums.length; ++i){ if(hashtable.containsKey(target - nums[i])){ return new int[]{hashtable.get(target - nums[i]), i}; } hashtable.put(nums[i], i); } return new int[0]; } 复杂度分析：\n时间复杂度：O(N), 其中 N 是数组中的元素数量。对于每一个元素 x，我们可以 O(1) 地寻找 target - x。 空间复杂度：O(N)，其中 N 是数组中的元素数量。主要为哈希表的开销。 作者：LeetCode-Solution 链接：https://leetcode.cn/problems/two-sum/solution/liang-shu-zhi-he-by-leetcode-solution/ 来源：力扣（LeetCode） 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n","date":"2023-07-07T00:00:00Z","image":"https://msdemt.github.io/p/two_sum/1603980178-c305fb1df5f5fb7_hu61eb5bf94bba91376f0df83c72584e6c_90324_120x120_fill_box_smart1_3.png","permalink":"https://msdemt.github.io/p/two_sum/","title":"两数之和"},{"content":"ubuntu 安装后，默认没有root用户密码，所以，无法使用su命令切换到root用户\n配置ubuntu root用户密码\n1 sudo passwd 配置后，就可以使用su命令切换到root用户了\n","date":"2022-11-23T00:00:00Z","image":"https://msdemt.github.io/p/ubuntu-root-pwd/ubuntu_logo_hu373a6c33440a9fb65cfc39e6a6372242_135517_120x120_fill_box_smart1_3.png","permalink":"https://msdemt.github.io/p/ubuntu-root-pwd/","title":"ubuntu配置root密码"}]