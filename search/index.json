[{"content":"介绍 在ubuntu 18.04 上，上传大于100mb文件到github\n安装 git lfs 添加软件仓库\n1 curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash 安装 lfs\n1 sudo apt-get install git-lfs 上传 进入代码仓库，执行\n1 git lfs track \u0026lt;file\u0026gt; file 是需要上传的大文件\n执行完后会发现目录下生成了 .gitattributes 文件， 文件内记录了我们要上传文件的信息。只有先把 .gitattributes 传上去，才可以上传大文件。\n1 2 3 git add .gitattributes git commit -m \u0026#34;add large file .gitattributes\u0026#34; git push origin main 开始上传大文件\n1 2 3 git add \u0026lt;file\u0026gt; git commit -m \u0026#34;add large file\u0026#34; git push origin main 需要注意的是，通过git-lfs上传文件是有空间限制的，单个文件最大100mb，最大支持1GB，免费用户如果上传的文件超过了1G，账号就会被冻结，所以在上传前一定要检查一下自己还剩多少空间，可以在 Settings - Billing and plans - Plans and usage 查看。\n问题 上传大文件时失败 1 batch response: Git LFS is disabled for this repository. 就说明你的账号被冻结了，需要在GitHub后台提交解封申请。\nhttps://support.github.com/contact\n工作日一般几个小时就会帮你把账号解封，解封后才可以继续上传大文件\n参考：\nhttps://docs.github.com/zh/repositories/working-with-files/managing-large-files/about-large-files-on-github\nhttps://github.com/git-lfs/git-lfs/blob/main/INSTALLING.md\nhttps://cloud.tencent.com/developer/article/1677003\n","date":"2023-09-03T00:00:00Z","permalink":"https://msdemt.github.io/p/github-large-files/","title":"使用git-lfs上传大文件到github"},{"content":"介绍 在不支持 cpu 虚拟化的 ubuntu 18.04 云主机上安装 vagrant + virtualbox，实现创建虚拟机实例。\n安装 virtualbox 参考： https://forums.virtualbox.org/viewtopic.php?t=108215\nvirtualbox 6 及以上版本开始依赖cpu虚拟化，如 vt-x，所以需要安装 virtualbox 5 版本\nvirtualbox 5 下载地址：https://www.virtualbox.org/wiki/Download_Old_Builds_5_2\n下载安装 virtualbox 5.2.44 deb 包后，右键使用ubuntu软件中心安装。\n卸载 virtualbox (ubuntu 软件中心中找不到已安装的virturalbox)\n1 sudo apt remove virtualbox virtualbox-* 安装 vagrant 参考：\nhttps://developer.hashicorp.com/vagrant/downloads\nhttps://stackoverflow.com/questions/24620599/error-vt-x-not-available-for-vagrant-machine-inside-virtualbox\n下载安装 vagrant\n1 2 3 wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg echo \u0026#34;deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\u0026#34; | sudo tee /etc/apt/sources.list.d/hashicorp.list sudo apt update \u0026amp;\u0026amp; sudo apt install vagrant 新建工作目录\n1 mkdir ~/vagrant-test 执行 vagrant init 命令初始化 VagrantFile，因为需要使用32位系统镜像，所以指定了 jasonc/centos7-32bit\n1 vagrant init jasonc/centos7-32bit jasonc/centos7-32bit 镜像地址 https://app.vagrantup.com/jasonc/boxes/centos7-32bit\n执行后，会生成 VagrantFile 文件\n修改 VagrantFile，配置 cpu 和 内存\n1 2 3 4 5 6 7 8 9 10 11 12 13 # -*- mode: ruby -*- # vi: set ft=ruby : Vagrant.configure(\u0026#34;2\u0026#34;) do |config| config.vm.box = \u0026#34;jasonc/centos7-32bit\u0026#34; config.vm.provider \u0026#34;virtualbox\u0026#34; do |v| v.memory = 1024 v.cpus = 1 end end 执行 vagrant up 命令，启动虚拟机实例\n1 vagrant up 进入虚拟机实例\n1 vagrant ssh 关闭虚拟机实例\n1 vagrant halt 销毁虚拟机实例\n1 vagrant destroy 查看已下载的镜像（box）\n1 vagrant box list vagrant 镜像查询：https://app.vagrantup.com\n错误汇总 无法启动 centos7 1 2 vagrant init centos/7 vagrant up 出现错误\n1 2 3 4 5 6 7 There was an error while executing `VBoxManage`, a CLI used by Vagrant for controlling VirtualBox. The command and stderr is shown below. Command: [\u0026#34;startvm\u0026#34;, \u0026#34;328357ce-9204-4c53-bbd1-279427c5350b\u0026#34;, \u0026#34;--type\u0026#34;, \u0026#34;headless\u0026#34;] Stderr: VBoxManage: error: VT-x is not available (VERR_VMX_NO_VMX) VBoxManage: error: Details: code NS_ERROR_FAILURE (0x80004005), component ConsoleWrap, interface IConsole virtual + vagrant 在没有vt-x的环境只能运行1核32位的系统。 https://app.vagrantup.com/jasonc/boxes/centos7-32bit\nvagrant 配置cpu和内存 https://talk.ninghao.net/t/vagrant-ru-he-pei-zhi-shi-yong-cpu-he-xin-yu-nei-cun/597/3\n启动vagrant实例时出现错误，找不到具体原因 启动虚拟机实例时超时，实例启动失败\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 default: SSH auth method: private key Timed out while waiting for the machine to boot. This means that Vagrant was unable to communicate with the guest machine within the configured (\u0026#34;config.vm.boot_timeout\u0026#34; value) time period. If you look above, you should be able to see the error(s) that Vagrant had when attempting to connect to the machine. These errors are usually good hints as to what may be wrong. If you\u0026#39;re using a custom box, make sure that networking is properly working and you\u0026#39;re able to connect to the machine. It is a common problem that networking isn\u0026#39;t setup properly in these boxes. Verify that authentication configurations are also setup properly, as well. If the box appears to be booting properly, you may want to increase the timeout (\u0026#34;config.vm.boot_timeout\u0026#34;) value. 找不到原因，是因为看不到虚拟机的启动过程。在Vagrantfile中的最后一个end前面加入：\n1 2 3 config.vm.provider \u0026#34;virtualbox\u0026#34; do |vb| vb.gui = true end 然后删掉目录下的.vagrant文件，命令行窗口重新运行 vagrant up 命令，这时就可以看到启动过程中到底哪里出了问题了。 我的启动卡在 default: SSH auth method: private key 的原因是 “VT-x/AMD-V 硬件加速在您的系统中不可用”，到BIOS中找到对应选项修改成enabled 就可以了。\n参考： https://zhuanlan.zhihu.com/p/49538228\nhttps://blog.csdn.net/m0_50546016/article/details/119176009\nhttps://jimmysong.io/blog/vagrant-intro/\n","date":"2023-08-27T00:00:00Z","permalink":"https://msdemt.github.io/p/ubuntu-install-vagrant/","title":"ubuntu18.04安装vagrant记录"},{"content":"介绍 minikube 是适合开发人员的迷你版 k8s，本文在 ubuntu 18.04 上安装 minikube。\n安装minikube To install the latest minikube stable release on x86-64 Linux using binary download:\n1 2 curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 sudo install minikube-linux-amd64 /usr/local/bin/minikube 启动minikube\nFrom a terminal with administrator access (but not logged in as root), run:\n1 minikube start If minikube fails to start, see the drivers page for help setting up a compatible container or virtual-machine manager.\n安装kubectl 用以下命令下载最新 kubectl 发行版\n1 curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; 安装 kubectl\n1 sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl 测试\n1 kubectl version --client 操作 使用 kubectl 查看所有命名空间的 pod\n1 kubectl get po -A minikube 集成了 kubernetes dashboard，使用如下命令开启访问 dashboard\n1 minikube dashboard 查看 minikube 版本\n1 minikube version 部署服务 k8s 有三种暴露服务的方式：NodePort, LoadBalancer, Ingress，分别介绍使用minikube 安装暴露服务\nService Create a sample deployment and expose it on port 8080:\n1 2 kubectl create deployment hello-minikube --image=kicbase/echo-server:1.0 kubectl expose deployment hello-minikube --type=NodePort --port=8080 It may take a moment, but your deployment will soon show up when you run:\n1 kubectl get services hello-minikube The easiest way to access this service is to let minikube launch a web browser for you:\n1 minikube service hello-minikube Alternatively, use kubectl to forward the port:\n1 kubectl port-forward service/hello-minikube 7080:8080 Tada! Your application is now available at http://localhost:7080/.\nYou should be able to see the request metadata in the application output. Try changing the path of the request and observe the changes. Similarly, you can do a POST request and observe the body show up in the output.\nLoadBalancer To access a LoadBalancer deployment, use the “minikube tunnel” command. Here is an example deployment:\n1 2 kubectl create deployment balanced --image=kicbase/echo-server:1.0 kubectl expose deployment balanced --type=LoadBalancer --port=8080 In another window, start the tunnel to create a routable IP for the ‘balanced’ deployment:\n1 minikube tunnel To find the routable IP, run this command and examine the EXTERNAL-IP column:\n1 kubectl get services balanced Your deployment is now available at \u0026lt;EXTERNAL-IP\u0026gt;:8080\nIngress Enable ingress addon:\n1 minikube addons enable ingress The following example creates simple echo-server services and an Ingress object to route to these services.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 kind: Pod apiVersion: v1 metadata: name: foo-app labels: app: foo spec: containers: - name: foo-app image: \u0026#39;kicbase/echo-server:1.0\u0026#39; --- kind: Service apiVersion: v1 metadata: name: foo-service spec: selector: app: foo ports: - port: 8080 --- kind: Pod apiVersion: v1 metadata: name: bar-app labels: app: bar spec: containers: - name: bar-app image: \u0026#39;kicbase/echo-server:1.0\u0026#39; --- kind: Service apiVersion: v1 metadata: name: bar-service spec: selector: app: bar ports: - port: 8080 --- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: example-ingress spec: rules: - http: paths: - pathType: Prefix path: /foo backend: service: name: foo-service port: number: 8080 - pathType: Prefix path: /bar backend: service: name: bar-service port: number: 8080 --- Apply the contents\n1 kubectl apply -f https://storage.googleapis.com/minikube-site-examples/ingress-example.yaml Wait for ingress address\n1 2 3 kubectl get ingress NAME CLASS HOSTS ADDRESS PORTS AGE example-ingress nginx * \u0026lt;your_ip_here\u0026gt; 80 5m45s Note for Docker Desktop Users:\nTo get ingress to work you’ll need to open a new terminal window and run minikube tunnel and in the following step use 127.0.0.1 in place of \u0026lt;ip_from_above\u0026gt;.\nNow verify that the ingress works\n1 2 3 4 5 6 7 $ curl \u0026lt;ip_from_above\u0026gt;/foo Request served by foo-app ... $ curl \u0026lt;ip_from_above\u0026gt;/bar Request served by bar-app ... 管理minikube Pause Kubernetes without impacting deployed applications:\n1 minikube pause Unpause a paused instance:\n1 minikube unpause Halt the cluster:\n1 minikube stop Change the default memory limit (requires a restart):\n1 minikube config set memory 9001 Browse the catalog of easily installed Kubernetes services:\n1 minikube addons list Create a second cluster running an older Kubernetes release:\n1 minikube start -p aged --kubernetes-version=v1.16.1 Delete all of the minikube clusters:\n1 minikube delete --all 参考：\nhttps://kubernetes.io/zh-cn/docs/tutorials/hello-minikube/\nhttps://minikube.sigs.k8s.io/docs/start/\nhttps://kubernetes.io/zh-cn/docs/tasks/tools/#kubectl\nhttps://kubernetes.io/zh-cn/docs/tasks/tools/install-kubectl-linux/#install-kubectl-binary-with-curl-on-linux\n","date":"2023-08-27T00:00:00Z","permalink":"https://msdemt.github.io/p/ubuntu-minikube/","title":"ubuntu安装minikube"},{"content":"介绍 因为云主机，不支持 cpu 虚拟化（如：vt-x），但是我希望在上面运行虚拟机，所以进行了此次探索。\n因为不支持 cpu 虚拟化，所以只能运行 32位 的系统\nvmware 在不支持 cpu 虚拟化的环境，vmware 最高可以使用vmware 10.0.7 版本安装centos 6.10 i386及以下的32位系统，也支持 ubuntu 13.10 i386 及以下的32位系统\n其中ubuntu系统安装后桌面上无法显示图标，网上资料说重新安装ubuntu-desktop，但是找不到相关包，并且无法使用apt-get install。\ncentos 6.10 特点如下：\n缺点：卡，无法流畅使用\n优点：cpu支持多核，4核可以运行；内存支持4GB；安装tools后可以支持全屏。\nvirtualbox 使用virtualbox 5.2.44 可以安装 centos 7.4 i386 及以下的32位系统\n缺点：卡，cpu只能1核，内存最大3500MB，安装tools后无法全屏，无法正常使用。\nvagrant + virtualbox 使用 vagrant 结合 virtualbox 可以在后台运行虚拟机实例，但是只能运行 32位 且 cpu核数为1核的虚拟机。\nVagrantFile 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # -*- mode: ruby -*- # vi: set ft=ruby : Vagrant.configure(\u0026#34;2\u0026#34;) do |config| config.vm.box = \u0026#34;jasonc/centos7-32bit\u0026#34; config.vm.provider \u0026#34;virtualbox\u0026#34; do |v| v.memory = 1024 v.cpus = 1 end end 执行 vagrant up ，启动虚拟机实例\n执行 vagrant ssh 进入虚拟机\n相关下载 vmware workstation 10.0.7 下载地址： https://download3.vmware.com/software/wkst/file/VMware-workstation-full-10.0.7-2844087.exe\nvmware workstation 10 激活序列号：\n1 JZ6WK-4529P-HZAA1-9RAG6-33JNR 1 5F4EV-4Z0DP-XZHN9-0L95H-02V17 virtualbox 5.2.44 下载地址： https://www.virtualbox.org/wiki/Download_Old_Builds_5_2\ncentos 6.10 i386 下载地址： http://mirrors.aliyun.com/centos-vault/6.10/isos/i386/\ncentos7.4 i386 下载地址： https://mirrors.tripadvisor.com/centos-vault/altarch/\nubuntu 13.10 i386 下载地址： https://old-releases.ubuntu.com/releases/\n参考：\nhttps://forums.linuxmint.com/viewtopic.php?t=337186\nhttps://forums.virtualbox.org/viewtopic.php?t=108215\nhttps://stackoverflow.com/questions/24620599/error-vt-x-not-available-for-vagrant-machine-inside-virtualbox\n","date":"2023-08-27T00:00:00Z","permalink":"https://msdemt.github.io/p/without-cpu-virtualization/","title":"不支持cpu虚拟化环境运行虚拟机的探索"},{"content":"介绍 中央仓库就是 Maven 的一个默认的远程仓库，Maven 的安装文件中自带了中央仓库的配置($M2_HOME/lib/maven-model-builder.jar)\n在很多情况下，默认的中央仓库无法满足项目的需求，这时就需要在pom.xml文件中配置仓库，在pom文件中的配置仅对当前项目有效\n避免代码重复性，减少冗余，可在 settings.xml 文件中配置 settings.xml文件中配置可参考：https://developer.aliyun.com/mvn/guide\n注意：Maven 自带的中央仓库使用的Id为central 如果其他的仓库声明也是用该Id就会覆盖中央仓库的配置\n在maven的settings.xml中配置 对使用该maven的所有项目有效\n打开 maven 的配置文件（ windows 机器一般在 maven 安装目录的 conf/settings.xml ），在\u0026lt;mirrors\u0026gt;\u0026lt;/mirrors\u0026gt;标签中添加 mirror 子节点:\n1 2 3 4 5 6 \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;aliyunmaven\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;*\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;阿里云公共仓库\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://maven.aliyun.com/repository/public\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; 如果想使用其它代理仓库，可在\u0026lt;repositories\u0026gt;\u0026lt;/repositories\u0026gt;节点中加入对应的仓库使用地址。以使用 central 代理仓为例：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;central\u0026lt;/id\u0026gt; \u0026lt;url\u0026gt;https://maven.aliyun.com/repository/central\u0026lt;/url\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/repository\u0026gt; 在项目根目录下的pom.xml中配置 只对本项目有效\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;public\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;aliyun nexus\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://maven.aliyun.com/nexus/content/groups/public/\u0026lt;/url\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; \u0026lt;pluginRepositories\u0026gt; \u0026lt;pluginRepository\u0026gt; \u0026lt;id\u0026gt;public\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;aliyun nexus\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://maven.aliyun.com/nexus/content/groups/public/\u0026lt;/url\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/pluginRepository\u0026gt; \u0026lt;/pluginRepositories\u0026gt; 问题：\n当url为http时出现如下错误：\n1 2 3 4 5 6 7 8 Blocked mirror for repositories: [public (http://maven.aliyun.com/nexus/content/groups/public/, default, releases+snapshots)] Since Maven 3.8.1 http repositories are blocked. Possible solutions: - Check that Maven pom files do not contain http repository http://maven.aliyun.com/nexus/content/groups/public/ - Add a mirror(s) for http://maven.aliyun.com/nexus/content/groups/public/ that allows http url in the Maven settings.xml - Downgrade Maven to version 3.8.1 or earlier in settings 将http改为https\n参考：\nhttps://developer.aliyun.com/mvn/guide\nhttps://www.cnblogs.com/h-c-g/p/9928658.html\n","date":"2023-08-24T00:00:00Z","permalink":"https://msdemt.github.io/p/maven-repo-aliyun/","title":"maven配置阿里云仓库"},{"content":"配置 nginx 支持 websockt，需要添加如下配置\n1 2 3 proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#39;upgrade\u0026#39;; nginx 配置文件修改之前（反向代理后端服务）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ sudo cat /etc/nginx/conf.d/manager.conf server { listen 16002; server_name _; charset utf-8; root /root/manager/dist; location /api { proxy_pass http://192.168.120.10:16002; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } nginx 支持后端 websocket （websocket地址： ws://192.168.120.10:16002/api/webssh），配置如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 $ sudo cat /etc/nginx/conf.d/manager.conf server { listen 16002; server_name _; charset utf-8; root /root/manager/dist; proxy_set_header X-Real_IP $remote_addr; proxy_set_header Host $host:$server_port; proxy_set_header X_Forward_For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#39;upgrade\u0026#39;; location /api { proxy_pass http://192.168.120.10:16002; } } proxt_http_version 1.1;: 表示反向代理发送的HTTP协议的版本是1.1,HTTP1.1支持长连接 proxy_set_header Upgrade $http_upgrade;和 proxy_set_header Connection \u0026quot;upgrade\u0026quot;;: 表示 websocket 连接进入的时候，将一个 http 连接升级为 websocket 连接 标准配置 根据 http://nginx.org/en/docs/http/websocket.html 编写一份标准配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 map $http_upgrade $connection_upgrade { default upgrade; \u0026#39;\u0026#39; close; } upstream wsbackend{ server ip1:port1; server ip2:port2; keepalive 1000; } server { listen 20038; location /{ proxy_http_version 1.1; proxy_pass http://wsbackend; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_read_timeout 3600s; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; } } 其中，\n1 2 3 4 map $http_upgrade $connection_upgrade { default upgrade; \u0026#39;\u0026#39; close; } 表示：\n如果 $http_upgrade 不为 \u0026rsquo;\u0026rsquo; (空),则 $connection_upgrade 为 upgrade 如果 $http_upgrade 为 \u0026rsquo;\u0026rsquo; (空),则 $connection_upgrade 为 close 1 2 3 4 5 upstream wsbackend{ server ip1:port1; server ip2:port2; keepalive 1000; } 表示 nginx 负载均衡\n负载两台服务器（ip1:port1）和（ip2:port2） keepalive 1000 表示的是每个nginx进程中上游服务器保持的空闲连接,当空闲连接过多时,会关闭最少使用的空闲连接.当然,这不是限制连接总数的,可以想象成空闲连接池的大小.设置的值应该是上游服务器能够承受的 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 server { listen 80; location /{ proxy_http_version 1.1; proxy_pass http://wsbackend; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_read_timeout 3600s; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; } } 表示的是监听的服务器的配置\nlisten 80 表示 nginx 监听的端口 locations / 表示监听的路径(/表示所有路径,通用匹配,相当于default) proxt_http_version 1.1 表示反向代理发送的HTTP协议的版本是1.1,HTTP1.1支持长连接 proxy_pass http://wsbackend; 表示反向代理的uri,这里可以使用负载均衡变量 proxy_redirect off; 表示不要替换路径,其实这里如果是/则有没有都没关系,因为default也是将路径替换到proxy_pass的后边 proxy_set_header Host $host; 表示传递时请求头不变, $host是nginx内置变量,表示的是当前的请求头,proxy_set_header表示设置请求头 proxy_set_header X-Real-IP $remote_addr; 表示传递时来源的ip还是现在的客户端的ip proxy_read_timeout 3600s; 表示两次请求之间的间隔超过 3600s 后才关闭这个连接,默认的60s.自动关闭的元凶 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 表示X-Forwarded-For头不发生改变 proxy_set_header Upgrade $http_upgrade; 表示设置Upgrade不变 proxy_set_header Connection $connection_upgrade; 表示如果 $http_upgrade为upgrade,则请求为upgrade(websocket),如果不是,就关闭连接 简化版本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 http { map $http_upgrade $connection_upgrade { default upgrade; \u0026#39;\u0026#39; close; } server { ... location /chat/ { proxy_pass http://backend; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; } } } 问题 Nginx代理webSocket经常出现中断的解决方案, 如何保持长连接 原因： nginx等待客户端第一次通讯和第二次通讯的时间差，超过了它设定的最大等待时间，简单来说就是，超时，所以就断了webSocket连接。\n解决方案一\n配置nginx.conf的对应localhost里面的这几个参数\n1 2 3 proxy_connect_timeout proxy_read_timeout proxy_send_timeout 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 http { server { location / { root html; index index.html index.htm; proxy_pass http://webscoket; proxy_http_version 1.1; proxy_connect_timeout 4s; #配置点1 proxy_read_timeout 60s; #配置点2，如果没效，可以考虑这个时间配置长一点 proxy_send_timeout 12s; #配置点3 proxy_set_header Upgrade $http_upgrade; #这是webSocket的配置，与此解决方案无关 proxy_set_header Connection \u0026#34;Upgrade\u0026#34;; #这是webSocket的配置，与此解决方案无关 } } } 配置点2: 这个是服务器对客户端等待最大的时间，也就是说，当webSocket使用nginx转发的时候，对于上面的配置点2来说，如果60秒内没有通讯，依然是会断开的，所以，你可以按照你的需求来设定。\n解决方案二\n发心跳包，原理就是在有效的再读时间内进行通讯，重新刷新再读时间\n参考：\nhttps://www.jianshu.com/p/6205c8769e3c\nhttp://nginx.org/en/docs/http/websocket.html\n","date":"2023-08-24T00:00:00Z","permalink":"https://msdemt.github.io/p/nginx-websocket/","title":"nginx配置websocket"},{"content":"介绍 Bash case 语句是具有许多 ELIF 元素的 IF-THEN-ELSE 的最简单形式。使用 case 语句使 bash 脚本更具可读性，并且更易于维护。它通常用于简化具有多种不同选择的复杂条件。 Bash case 语句遵循与 Javascript 或 C 语言中的switch 语句类似的逻辑。但是又略有不同，如下所示：\nBash case 语句只接受一次值，然后多次测试该值。一旦找到模式就执行与其链接的语句，它将停止搜索模式，这与 C switch 语句几乎相反。\n语法 bash case 语句的语法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 case expression in pattern_1) statements ;; pattern_2) statements ;; pattern_3|pattern_4|pattern_5) statements ;; pattern-n) statements ;; *) statements ;; esac bash case 语句的一些重要说明：\nbash 中的每个 case 语句均以 case 关键字开头，后接 case 表达式和 in 关键字。使用 esac 关键字关闭 case 语句。 可以使用以 | 分隔的多个模式运算符，运算符 ) 表示模式列表的终止。包含语句的模式称为子句，并且必须以双分号(;;)终止。星号(*)用作定义默认情况的最终模式。当用作最后一种情况时，它用作默认情况。 子句中如果使用冒号 : ，表示空命令，不执行任何操作 首先，case 语句扩展表达式并尝试与每个包含的模式匹配。找到匹配项后，将执行所有链接的语句，直到双分号(;;)为止。在第一个匹配项之后，case 以最后执行的语句的退出状态终止。如果没有匹配的模式，则 case 的退出状态为零。否则，返回状态是已执行语句的退出状态。如果使用默认的星号(*)模式，则在没有匹配模式的情况下将执行它。下面通过一些示例来了解这种机制：\n示例 使用 case 语句解决执行两次 source /etc/profile 后，$PATH 出现重复数据的问题\n1 2 3 4 case \u0026#34;:$PATH:\u0026#34; in *\u0026#34;:$new_entry:\u0026#34;*) :;; # already there *) PATH=\u0026#34;$new_entry:$PATH\u0026#34;;; # or PATH=\u0026#34;$PATH:$new_entry\u0026#34; esac 参考：\nhttps://www.yiibai.com/bash/bash-case-statement.html\nhttps://www.cnblogs.com/ChinaGo/p/9910747.html\nhttps://unix.stackexchange.com/questions/14895/duplicate-entries-in-path-a-problem\n","date":"2023-08-17T00:00:00Z","permalink":"https://msdemt.github.io/p/bash-case/","title":"Bash case 语句"},{"content":"介绍 在 linux(centos、ubuntu\u0026hellip;) 上tar包解压方式安装 jdk1.8.0_202\n安装 下载 jdk1.8.0_202\njdk-8u202下载\n解压 tar 到指定目录\n1 sudo tar -zxf jdk-8u202-linux-x64.tar.gz -C /usr/local 创建软链接，方便以后更换 jdk 版本\n1 sudo ln -s /usr/local/jdk1.8.0_202 /usr/local/jdk 添加环境变量配置 新建 jdk 环境变量文件 /etc/profile.d/jdk.sh\n1 sudo touch /etc/profile.d/jdk.sh 添加如下内容\n1 2 3 4 5 6 7 #!/bin/bash export JAVA_HOME=/usr/local/jdk export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar case \u0026#34;:$PATH:\u0026#34; in *\u0026#34;:$JAVA_HOME/bin:\u0026#34;*) :;; # already there *) PATH=\u0026#34;$JAVA_HOME/bin:$PATH\u0026#34;;; # or PATH=\u0026#34;$PATH:$new_entry\u0026#34; esac 注意：/etc/profile.d/jdk.sh 文件权限应该为 644\n更新当前 shell 环境变量\n1 source /etc/profile 参考：\nhttps://unix.stackexchange.com/questions/14895/duplicate-entries-in-path-a-problem\n","date":"2023-08-17T00:00:00Z","permalink":"https://msdemt.github.io/p/install-java/","title":"linux 安装 java"},{"content":"介绍 ubuntu 18.04 重装后，记录下必需软件的安装过程\n配置root用户密码 ubuntu 安装后，默认 root 用户没有密码，无法执行 su - root 切换到 root 用户，配置 root 用户密码\n1 sudo passwd root 密码配置成功后，就可以执行 su - root 切换到 root 用户了\n配置普通用户sudo免密 方法一： 在 /etc/sudoers.d/ 文件夹下新建文件，如 custom ，文件中添加如下内容\n1 username ALL=(ALL) NOPASSWD:ALL 方法二： sudo 相关的配置位于 /etc/sudoers 文件内，这个文件不建议直接编辑，而是使用以下命令\n1 sudo visudo 该命令会打开默认的编辑器编辑 /etc/sudoers 文件，并在保存时自动检查文件格式并设置到正确的文件权限。\n进入编辑状态后，在文件的最后面 添加以下内容\n1 username ALL=(ALL) NOPASSWD:ALL username 改成自己的用户名\n配置自动登录 打开 ubuntu desktop 后，自动登录到桌面，避免每次输入密码\nubuntu -\u0026gt; 设置 -\u0026gt; 详细信息 -\u0026gt; 用户 -\u0026gt; 开启 自动登录\n挂载磁盘 执行 fdisk -l 查看可用的磁盘\n/dev/vdb 是额外可用的磁盘，将该磁盘挂载到 /opt 目录下\n卸载 /dev/vdb 目前的挂载位置 1 sudo umount /dev/vdb 编辑 /etc/fstab，添加或修改 /dev/vdb的挂载，该文件也可以让磁盘开机自动挂载 1 2 3 sudo vi /etc/fstab # 新增或修改磁盘挂载 /dev/vdb /opt ext4 defaults,nofail 0 2 创建 /opt 目录 1 sudo touch /opt 将 /etc/fstab 中定义的所有磁盘系统挂上 1 sudo mount -a 修改家目录为英文 默认家目录下的文件夹名称为中文，现将中文名称改为英文名称\n方法一：\n终端执行\n1 2 export LANG=en_US xdg-user-dirs-gtk-update 执行后，会弹出更换文件夹名称提示，选择 Update Names，将文件夹名称改为英文\n再执行\n1 2 export LANG=zh_CN.UTF-8 xdg-user-dirs-gtk-update 再次弹出更换文件夹名称提示，选择保留旧的名称，并选上不要再次询问我（下次开机的时候，就不会再次询问了）\n重启。\n方法二：\n修改配置文件 ~/.config/user-dirs.dirs ，将对应的路径改为英文名\n1 2 3 4 5 6 7 8 XDG_DESKTOP_DIR=\u0026#34;$HOME/Desktop\u0026#34; XDG_DOWNLOAD_DIR=\u0026#34;$HOME/Download\u0026#34; XDG_TEMPLATES_DIR=\u0026#34;$HOME/Template\u0026#34; XDG_PUBLICSHARE_DIR=\u0026#34;$HOME/Public\u0026#34; XDG_DOCUMENTS_DIR=\u0026#34;$HOME/Document\u0026#34; XDG_MUSIC_DIR=\u0026#34;$HOME/Music\u0026#34; XDG_PICTURES_DIR=\u0026#34;$HOME/Picture\u0026#34; XDG_VIDEOS_DIR=\u0026#34;$HOME/Video\u0026#34; 重启。\n安装docker 参考：\nhttps://docs.docker.com/engine/install/ubuntu/\nhttps://docs.docker.com/compose/install/linux/#install-the-plugin-manually\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 sudo apt-get remove docker docker-engine docker.io containerd runc sudo apt-get update sudo apt-get install \\ ca-certificates \\ curl \\ gnupg sudo mkdir -m 0755 -p /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg echo \\ \u0026#34;deb [arch=\u0026#34;$(dpkg --print-architecture)\u0026#34; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ \u0026#34;$(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;)\u0026#34; stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 修改docker存储路径 参考：\nhttps://blog.csdn.net/m0_58684193/article/details/127554527\ndocker数据默认存放在 /var/lib/docker 下，修改docker数据存储路径，将其放到容量大的磁盘中\n新建docker数据存储目录\n1 2 sudo mkdir -p /opt/data/docker sudo vi /etc/docker/daemon.json 新建docker配置文件，添加存储路径配置\n1 sudo vi /etc/docker/daemon.json 内容如下\n1 2 3 { \u0026#34;data-root\u0026#34;: \u0026#34;/opt/data/docker\u0026#34; } 重启docker\n1 2 sudo systemctl stop docker sudo systemctl start docker 删除旧的docker数据目录\n1 sudo rm -rf /var/lib/docker 安装rar压缩工具 压缩功能\n安装\n1 sudo apt-get -y install rar 卸载\n1 sudo apt-get -y remove rar 解压功能\n安装\n1 sudo apt-get install unrar 卸载\n1 sudo apt-get remove unrar 压缩解压缩.rar\n解压：\n1 rar x FileName.rar 压缩：\n1 rar a FileName.rar DirName 安装java 下载 jdk1.8.0_202\njdk-8u202下载\n解压 tar 到指定目录\n1 sudo tar -zxf jdk-8u202-linux-x64.tar.gz -C /usr/local 创建软链接，方便以后更换 jdk 版本\n1 sudo ln -s /usr/local/jdk1.8.0_202 /usr/local/jdk 添加环境变量配置 新建 jdk 环境变量文件 /etc/profile.d/jdk.sh\n1 sudo touch /etc/profile.d/jdk.sh 添加如下内容\n1 2 3 4 5 6 7 #!/bin/bash export JAVA_HOME=/usr/local/jdk export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar case \u0026#34;:$PATH:\u0026#34; in *\u0026#34;:$JAVA_HOME/bin:\u0026#34;*) :;; # already there *) PATH=\u0026#34;$JAVA_HOME/bin:$PATH\u0026#34;;; # or PATH=\u0026#34;$PATH:$new_entry\u0026#34; esac 注意：/etc/profile.d/jdk.sh 文件权限应该为 644\n更新当前 shell 环境变量\n1 source /etc/profile 安装idea 下载idea\n下载链接：https://www.jetbrains.com/zh-cn/idea/download/\n解压\n1 2 3 sudo tar -xzf ideaIU-2023.1.tar.gz -C /opt/develop/ cd /opt/develop/ mv idea-IU-231.8109.175/ idea-IU 创建快捷方式\n方式一：idea首页，左下角齿轮 -\u0026gt; create desktop entry\n方式二：\n1 2 3 4 5 6 7 8 9 10 11 12 $ cat /usr/share/applications/jetbrains-idea.desktop [Desktop Entry] Version=1.0 Type=Application Name=IntelliJ IDEA Ultimate Edition Icon=/opt/develop/idea-IU/bin/idea.svg Exec=\u0026#34;/opt/develop/idea-IU/bin/idea.sh\u0026#34; %f Comment=Capable and Ergonomic IDE for JVM Categories=Development;IDE; Terminal=false StartupWMClass=jetbrains-idea StartupNotify=true 添加可执行权限\n1 sudo chmod +x /usr/share/applications/jetbrains-idea.desktop idea64.vmoptions idea64.vmoptions 内容\n1 2 3 4 5 6 cat /home/username/.config/JetBrains/IntelliJIdea2023.1/idea64.vmoptions # custom IntelliJ IDEA VM options (expand/override \u0026#39;bin/idea.vmoptions\u0026#39;) -javaagent:/opt/develop/jetbra/ja-netfilter.jar --add-opens=java.base/jdk.internal.org.objectweb.asm=ALL-UNNAMED --add-opens=java.base/jdk.internal.org.objectweb.asm.tree=ALL-UNNAMED -Xmx4096m idea 快捷键 ctrl + shift + f 无法使用问题\n原因： ubuntu 自带的输入法占用了 ctrl + shift + f 快捷键\n解决：修改 ubntu 输入法中切换繁体/简体中文模式快捷键\n安装clash for windows clash for windows 下载\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 mkdir /opt/app tar -zxf Clash.for.Windows-0.20.9-x64-linux.tar.gz -C /opt/app ln -s /opt/app/Clash\\ for\\ Windows-0.20.9-x64-linux /opt/app/clash cd /opt/app/clash wget http://cdn.jsdelivr.net/gh/Dreamacro/clash@master/docs/logo.png cd .. vi clash.desktop # 内容如下 [Desktop Entry] Name=clash Comment=Clash Exec=/home/hekai/.app/clash/cfw Icon=/home/hekai/.app/clash/logo.png Type=Application Categories=Development; StartupNotify=true NoDisplay=false sudo cp clash.desktop /usr/share/applications/ 注意：.desktop 文件内容权限为 644 ，属主为 root\n安装 fcitx 见 ubuntu安装fcitx输入法框架\n使用Ubuntu软件安装时认证失败 使用 ubuntu 软件中心 安装 deb 包时，遇到了认证失败的问题。\n比如弹出安装不可信任的软件，需要输入用户密码，但是密码输入后，提示抱歉，认证失败。请重试。\n查看 /var/log/auth.log 日志\n1 2 Aug 18 23:39:02 00bafcjc-dUrwEMo9N5 polkitd(authority=local): Operator of unix-session:1 FAILED to authenticate to gain authorization for action org.freedesktop.packagekit.package-install-untrusted for system-bus-name::1.84 [gnome-software --local-filename=/home/hekai/Downloads/microsoft-edge-stable_115.0.1901.203-1_amd64.deb] (owned by unix-user:hekai) Aug 18 23:39:02 00bafcjc-dUrwEMo9N5 PackageKit: uid 1000 failed to obtain auth 解决：修改 /usr/share/polkit-1/actions/org.freedesktop.packagekit.policy 中 action 为 org.freedesktop.packagekit.package-install-untrusted ，将其中 auth_admin 的改为 yes ，如下\n1 2 3 4 5 \u0026lt;defaults\u0026gt; \u0026lt;allow_any\u0026gt;yes\u0026lt;/allow_any\u0026gt; \u0026lt;allow_inactive\u0026gt;yes\u0026lt;/allow_inactive\u0026gt; \u0026lt;allow_active\u0026gt;yes\u0026lt;/allow_active\u0026gt; \u0026lt;/defaults\u0026gt; 参考：\nhttps://zhuanlan.zhihu.com/p/250658106\nhttps://blog.csdn.net/Andy86666/article/details/106328819 https://blog.csdn.net/qq_25518029/article/details/119906550\nhttps://blog.csdn.net/zhaominyong/article/details/118361940\nhttps://askubuntu.com/questions/18222/how-to-prevent-system-applications-like-the-software-center-from-asking-for-pa\n","date":"2023-08-17T00:00:00Z","permalink":"https://msdemt.github.io/p/ubuntu-install-software/","title":"ubuntu安装idea等软件"},{"content":"介绍 在 Linux 系统中，冒号(:)常用来做路径的分隔符（如在PATH），数据字段的分隔符（如在 /etc/passwd）等。其实，冒号(:)在 Bash 中也是一个内建命令，它啥也不做，是个空命令、只起到占一个位置的作用，但有时候确实需要它。当然，它也有它的用途的，否则没必要存在。在 Linux 的帮助页中说它除了参数扩展和重定向之外不产生任何作用。\ngnu 帮助：http://www.gnu.org/software/bash/manual/bash.html#Bourne-Shell-Builtins\n作用 冒号（:）的作用\n空命令 参数扩展 重定向 当注释使用 空命令 空命令就是什么也不做，所以返回码永远都是 0 。虽说是空命令，但仍是命令，就具备一般命令应有的特征，可以象一般命令一样使用。如\n1 2 3 4 [root@localhost test]# : [root@localhost test]# echo $? 0 [root@localhost test]# 可以直接在console中执行。返回码为0。\n利用这一特性，:可以当 true 使用。如用在 while 等循环体中的条件判断。\n参数扩展 冒号引起的参数扩展，意思是将参数的值替换为新的值。一般有以下几种参数扩展用法：\n1 2 3 4 5 6 7 ${parameter:-word} #如果parameter没有设置或者为空，替换为word；否则替换为parameter的值 ${parameter:+word} #如果parameter没有设置或者为空，不进行任何替换；否则替换为word。 ${parameter:=word} #如果parameter没有设置或者为空，把word赋值给parameter。实际parameterd的值真的被替换了，这就是=号的意思。不能用这种方式指派位置参数或特殊参数的值。 ${parameter:?word} #如果parameter没有设置或者为空，把word输出到stderr，否则替换为parameter的值。 # -、+、? 实际parameter的值并不被修改，扩展只是临时显示成word的值。准确的讲，扩展实际替换的是参数的显示，而不是参数的定义。只有=，才是替换参数的定义。 ${parameter:offset} #扩展为parameter中从offset开始的子字符串。 ${parameter:offset:length} #扩展为parameter中从offset开始的长度不超过length的字符。 三元运算符\n1 2 var=100 (($var\u0026gt;100?var++:var--)) 重定向 1 2 3 : \u0026gt; test.file cat test.file cat 文件内容，什么都没有。\n注释 使用冒号还可以用作注释行的开始，但是如果有语法错误，仍将报错，这一点与使用 # 号不同。如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [root@localhost test]# cat test.sh fun() { echo 1222 : cccccc # llllll echo 222221 } fun [root@localhost test]# sh test.sh 1222 222221 参考：\nhttps://www.cnblogs.com/ChinaGo/p/9910747.html\n","date":"2023-08-17T00:00:00Z","permalink":"https://msdemt.github.io/p/bash-colon/","title":"冒号在shell中的作用"},{"content":"介绍 curl 是一个非常实用的、用来与服务器之间传输数据的工具；支持的协议包括 (DICT, FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMTP, SMTPS, TELNET and TFTP)，curl 设计为无用户交互下完成工作；curl 提供了一大堆非常有用的功能，包括代理访问、用户认证、ftp上传下载、HTTP POST、SSL连接、cookie支持、断点续传等。\n常用的 curl 命令 发送 GET 请求 -X: 指定执行请求类型（POST/GET/HEAD/DELETE/PUT/PATCH），不加 -X 默认为 GET 请求 -H: 指定 header 头 -d: 指定传输的数据 -b: 指定 cookie，cookie 语法: key=value\n表示请求的地址\n1 curl \u0026lt;URL\u0026gt; 1 curl \u0026lt;URL\u0026gt;?a=1\u0026amp;b=hello 1 curl -X GET \u0026lt;URL\u0026gt;?a=1\u0026amp;b=hello 发送 POST 请求 1 curl -X POST -d \u0026#39;a=1\u0026amp;b=hello\u0026#39; \u0026lt;URL\u0026gt; POST 发送 json 格式的数据\n1 curl -H \u0026#34;Content-Type: application/json\u0026#34; -X POST -d \u0026#39;{\u0026#34;a\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;b\u0026#34;:\u0026#34;hello\u0026#34;}\u0026#39; \u0026lt;URL\u0026gt; POST 发送 test.json 文件中的 json 数据\n1 curl -H \u0026#34;Content-Type: application/json\u0026#34; -X POST -d @test.json \u0026lt;URL\u0026gt; POST 请求携带 cookie\n1 curl -H \u0026#34;Content-Type: application/json\u0026#34; -b \u0026#34;Token=eyJ0eXAi\u0026#34; -X POST -d @test.json \u0026lt;URL\u0026gt; 下载文件 -O 参数后面的 url 要具体到待下载的文件\n1 curl -O http://www.linux.com/test.jpg 下载并重命名文件\n1 curl -o test.jpg http://www.linux.com/test.jpg curl 命令语法 curl 命令语法 1 curl [options...] \u0026lt;URL\u0026gt; curl 参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 $ curl -h all Usage: curl [options...] \u0026lt;url\u0026gt; --abstract-unix-socket \u0026lt;path\u0026gt; Connect via abstract Unix domain socket --alt-svc \u0026lt;file name\u0026gt; Enable alt-svc with this cache file --anyauth Pick any authentication method -a, --append Append to target file when uploading --aws-sigv4 \u0026lt;provider1[:provider2[:region[:service]]]\u0026gt; Use AWS V4 signature authentication --basic Use HTTP Basic Authentication --cacert \u0026lt;file\u0026gt; CA certificate to verify peer against --capath \u0026lt;dir\u0026gt; CA directory to verify peer against -E, --cert \u0026lt;certificate[:password]\u0026gt; Client certificate file and password --cert-status Verify the status of the server cert via OCSP-staple --cert-type \u0026lt;type\u0026gt; Certificate type (DER/PEM/ENG) --ciphers \u0026lt;list of ciphers\u0026gt; SSL ciphers to use --compressed Request compressed response --compressed-ssh Enable SSH compression -K, --config \u0026lt;file\u0026gt; Read config from a file --connect-timeout \u0026lt;fractional seconds\u0026gt; Maximum time allowed for connection --connect-to \u0026lt;HOST1:PORT1:HOST2:PORT2\u0026gt; Connect to host -C, --continue-at \u0026lt;offset\u0026gt; Resumed transfer offset -b, --cookie \u0026lt;data|filename\u0026gt; Send cookies from string/file -c, --cookie-jar \u0026lt;filename\u0026gt; Write cookies to \u0026lt;filename\u0026gt; after operation --create-dirs Create necessary local directory hierarchy --create-file-mode \u0026lt;mode\u0026gt; File mode for created files --crlf Convert LF to CRLF in upload --crlfile \u0026lt;file\u0026gt; Use this CRL list --curves \u0026lt;algorithm list\u0026gt; (EC) TLS key exchange algorithm(s) to request -d, --data \u0026lt;data\u0026gt; HTTP POST data --data-ascii \u0026lt;data\u0026gt; HTTP POST ASCII data --data-binary \u0026lt;data\u0026gt; HTTP POST binary data --data-raw \u0026lt;data\u0026gt; HTTP POST data, \u0026#39;@\u0026#39; allowed --data-urlencode \u0026lt;data\u0026gt; HTTP POST data url encoded --delegation \u0026lt;LEVEL\u0026gt; GSS-API delegation permission --digest Use HTTP Digest Authentication -q, --disable Disable .curlrc --disable-eprt Inhibit using EPRT or LPRT --disable-epsv Inhibit using EPSV --disallow-username-in-url Disallow username in url --dns-interface \u0026lt;interface\u0026gt; Interface to use for DNS requests --dns-ipv4-addr \u0026lt;address\u0026gt; IPv4 address to use for DNS requests --dns-ipv6-addr \u0026lt;address\u0026gt; IPv6 address to use for DNS requests --dns-servers \u0026lt;addresses\u0026gt; DNS server addrs to use --doh-cert-status Verify the status of the DoH server cert via OCSP-staple --doh-insecure Allow insecure DoH server connections --doh-url \u0026lt;URL\u0026gt; Resolve host names over DoH -D, --dump-header \u0026lt;filename\u0026gt; Write the received headers to \u0026lt;filename\u0026gt; --egd-file \u0026lt;file\u0026gt; EGD socket path for random data --engine \u0026lt;name\u0026gt; Crypto engine to use --etag-compare \u0026lt;file\u0026gt; Pass an ETag from a file as a custom header --etag-save \u0026lt;file\u0026gt; Parse ETag from a request and save it to a file --expect100-timeout \u0026lt;seconds\u0026gt; How long to wait for 100-continue -f, --fail Fail silently (no output at all) on HTTP errors --fail-early Fail on first transfer error, do not continue --fail-with-body Fail on HTTP errors but save the body --false-start Enable TLS False Start -F, --form \u0026lt;name=content\u0026gt; Specify multipart MIME data --form-escape Escape multipart form field/file names using backslash --form-string \u0026lt;name=string\u0026gt; Specify multipart MIME data --ftp-account \u0026lt;data\u0026gt; Account data string --ftp-alternative-to-user \u0026lt;command\u0026gt; String to replace USER [name] --ftp-create-dirs Create the remote dirs if not present --ftp-method \u0026lt;method\u0026gt; Control CWD usage --ftp-pasv Use PASV/EPSV instead of PORT -P, --ftp-port \u0026lt;address\u0026gt; Use PORT instead of PASV --ftp-pret Send PRET before PASV --ftp-skip-pasv-ip Skip the IP address for PASV --ftp-ssl-ccc Send CCC after authenticating --ftp-ssl-ccc-mode \u0026lt;active/passive\u0026gt; Set CCC mode --ftp-ssl-control Require SSL/TLS for FTP login, clear for transfer -G, --get Put the post data in the URL and use GET -g, --globoff Disable URL sequences and ranges using {} and [] --happy-eyeballs-timeout-ms \u0026lt;milliseconds\u0026gt; Time for IPv6 before trying IPv4 --haproxy-protocol Send HAProxy PROXY protocol v1 header -I, --head Show document info only -H, --header \u0026lt;header/@file\u0026gt; Pass custom header(s) to server -h, --help \u0026lt;category\u0026gt; Get help for commands --hostpubmd5 \u0026lt;md5\u0026gt; Acceptable MD5 hash of the host public key --hostpubsha256 \u0026lt;sha256\u0026gt; Acceptable SHA256 hash of the host public key --hsts \u0026lt;file name\u0026gt; Enable HSTS with this cache file --http0.9 Allow HTTP 0.9 responses -0, --http1.0 Use HTTP 1.0 --http1.1 Use HTTP 1.1 --http2 Use HTTP 2 --http2-prior-knowledge Use HTTP 2 without HTTP/1.1 Upgrade --http3 Use HTTP v3 --ignore-content-length Ignore the size of the remote resource -i, --include Include protocol response headers in the output -k, --insecure Allow insecure server connections --interface \u0026lt;name\u0026gt; Use network INTERFACE (or address) -4, --ipv4 Resolve names to IPv4 addresses -6, --ipv6 Resolve names to IPv6 addresses -j, --junk-session-cookies Ignore session cookies read from file --keepalive-time \u0026lt;seconds\u0026gt; Interval time for keepalive probes --key \u0026lt;key\u0026gt; Private key file name --key-type \u0026lt;type\u0026gt; Private key file type (DER/PEM/ENG) --krb \u0026lt;level\u0026gt; Enable Kerberos with security \u0026lt;level\u0026gt; --libcurl \u0026lt;file\u0026gt; Dump libcurl equivalent code of this command line --limit-rate \u0026lt;speed\u0026gt; Limit transfer speed to RATE -l, --list-only List only mode --local-port \u0026lt;num/range\u0026gt; Force use of RANGE for local port numbers -L, --location Follow redirects --location-trusted Like --location, and send auth to other hosts --login-options \u0026lt;options\u0026gt; Server login options --mail-auth \u0026lt;address\u0026gt; Originator address of the original email --mail-from \u0026lt;address\u0026gt; Mail from this address --mail-rcpt \u0026lt;address\u0026gt; Mail to this address --mail-rcpt-allowfails Allow RCPT TO command to fail for some recipients -M, --manual Display the full manual --max-filesize \u0026lt;bytes\u0026gt; Maximum file size to download --max-redirs \u0026lt;num\u0026gt; Maximum number of redirects allowed -m, --max-time \u0026lt;fractional seconds\u0026gt; Maximum time allowed for transfer --metalink Process given URLs as metalink XML file --negotiate Use HTTP Negotiate (SPNEGO) authentication -n, --netrc Must read .netrc for user name and password --netrc-file \u0026lt;filename\u0026gt; Specify FILE for netrc --netrc-optional Use either .netrc or URL -:, --next Make next URL use its separate set of options --no-alpn Disable the ALPN TLS extension -N, --no-buffer Disable buffering of the output stream --no-keepalive Disable TCP keepalive on the connection --no-npn Disable the NPN TLS extension --no-progress-meter Do not show the progress meter --no-sessionid Disable SSL session-ID reusing --noproxy \u0026lt;no-proxy-list\u0026gt; List of hosts which do not use proxy --ntlm Use HTTP NTLM authentication --ntlm-wb Use HTTP NTLM authentication with winbind --oauth2-bearer \u0026lt;token\u0026gt; OAuth 2 Bearer Token -o, --output \u0026lt;file\u0026gt; Write to file instead of stdout --output-dir \u0026lt;dir\u0026gt; Directory to save files in -Z, --parallel Perform transfers in parallel --parallel-immediate Do not wait for multiplexing (with --parallel) --parallel-max \u0026lt;num\u0026gt; Maximum concurrency for parallel transfers --pass \u0026lt;phrase\u0026gt; Pass phrase for the private key --path-as-is Do not squash .. sequences in URL path --pinnedpubkey \u0026lt;hashes\u0026gt; FILE/HASHES Public key to verify peer against --post301 Do not switch to GET after following a 301 --post302 Do not switch to GET after following a 302 --post303 Do not switch to GET after following a 303 --preproxy [protocol://]host[:port] Use this proxy first -#, --progress-bar Display transfer progress as a bar --proto \u0026lt;protocols\u0026gt; Enable/disable PROTOCOLS --proto-default \u0026lt;protocol\u0026gt; Use PROTOCOL for any URL missing a scheme --proto-redir \u0026lt;protocols\u0026gt; Enable/disable PROTOCOLS on redirect -x, --proxy [protocol://]host[:port] Use this proxy --proxy-anyauth Pick any proxy authentication method --proxy-basic Use Basic authentication on the proxy --proxy-cacert \u0026lt;file\u0026gt; CA certificate to verify peer against for proxy --proxy-capath \u0026lt;dir\u0026gt; CA directory to verify peer against for proxy --proxy-cert \u0026lt;cert[:passwd]\u0026gt; Set client certificate for proxy --proxy-cert-type \u0026lt;type\u0026gt; Client certificate type for HTTPS proxy --proxy-ciphers \u0026lt;list\u0026gt; SSL ciphers to use for proxy --proxy-crlfile \u0026lt;file\u0026gt; Set a CRL list for proxy --proxy-digest Use Digest authentication on the proxy --proxy-header \u0026lt;header/@file\u0026gt; Pass custom header(s) to proxy --proxy-insecure Do HTTPS proxy connections without verifying the proxy --proxy-key \u0026lt;key\u0026gt; Private key for HTTPS proxy --proxy-key-type \u0026lt;type\u0026gt; Private key file type for proxy --proxy-negotiate Use HTTP Negotiate (SPNEGO) authentication on the proxy --proxy-ntlm Use NTLM authentication on the proxy --proxy-pass \u0026lt;phrase\u0026gt; Pass phrase for the private key for HTTPS proxy --proxy-pinnedpubkey \u0026lt;hashes\u0026gt; FILE/HASHES public key to verify proxy with --proxy-service-name \u0026lt;name\u0026gt; SPNEGO proxy service name --proxy-ssl-allow-beast Allow security flaw for interop for HTTPS proxy --proxy-ssl-auto-client-cert Use auto client certificate for proxy (Schannel) --proxy-tls13-ciphers \u0026lt;ciphersuite list\u0026gt; TLS 1.3 proxy cipher suites --proxy-tlsauthtype \u0026lt;type\u0026gt; TLS authentication type for HTTPS proxy --proxy-tlspassword \u0026lt;string\u0026gt; TLS password for HTTPS proxy --proxy-tlsuser \u0026lt;name\u0026gt; TLS username for HTTPS proxy --proxy-tlsv1 Use TLSv1 for HTTPS proxy -U, --proxy-user \u0026lt;user:password\u0026gt; Proxy user and password --proxy1.0 \u0026lt;host[:port]\u0026gt; Use HTTP/1.0 proxy on given port -p, --proxytunnel Operate through an HTTP proxy tunnel (using CONNECT) --pubkey \u0026lt;key\u0026gt; SSH Public key file name -Q, --quote \u0026lt;command\u0026gt; Send command(s) to server before transfer --random-file \u0026lt;file\u0026gt; File for reading random data from -r, --range \u0026lt;range\u0026gt; Retrieve only the bytes within RANGE --raw Do HTTP \u0026#34;raw\u0026#34;; no transfer decoding -e, --referer \u0026lt;URL\u0026gt; Referrer URL -J, --remote-header-name Use the header-provided filename -O, --remote-name Write output to a file named as the remote file --remote-name-all Use the remote file name for all URLs -R, --remote-time Set the remote file\u0026#39;s time on the local output -X, --request \u0026lt;method\u0026gt; Specify request method to use --request-target \u0026lt;path\u0026gt; Specify the target for this request --resolve \u0026lt;[+]host:port:addr[,addr]...\u0026gt; Resolve the host+port to this address --retry \u0026lt;num\u0026gt; Retry request if transient problems occur --retry-all-errors Retry all errors (use with --retry) --retry-connrefused Retry on connection refused (use with --retry) --retry-delay \u0026lt;seconds\u0026gt; Wait time between retries --retry-max-time \u0026lt;seconds\u0026gt; Retry only within this period --sasl-authzid \u0026lt;identity\u0026gt; Identity for SASL PLAIN authentication --sasl-ir Enable initial response in SASL authentication --service-name \u0026lt;name\u0026gt; SPNEGO service name -S, --show-error Show error even when -s is used -s, --silent Silent mode --socks4 \u0026lt;host[:port]\u0026gt; SOCKS4 proxy on given host + port --socks4a \u0026lt;host[:port]\u0026gt; SOCKS4a proxy on given host + port --socks5 \u0026lt;host[:port]\u0026gt; SOCKS5 proxy on given host + port --socks5-basic Enable username/password auth for SOCKS5 proxies --socks5-gssapi Enable GSS-API auth for SOCKS5 proxies --socks5-gssapi-nec Compatibility with NEC SOCKS5 server --socks5-gssapi-service \u0026lt;name\u0026gt; SOCKS5 proxy service name for GSS-API --socks5-hostname \u0026lt;host[:port]\u0026gt; SOCKS5 proxy, pass host name to proxy -Y, --speed-limit \u0026lt;speed\u0026gt; Stop transfers slower than this -y, --speed-time \u0026lt;seconds\u0026gt; Trigger \u0026#39;speed-limit\u0026#39; abort after this time --ssl Try SSL/TLS --ssl-allow-beast Allow security flaw to improve interop --ssl-auto-client-cert Use auto client certificate (Schannel) --ssl-no-revoke Disable cert revocation checks (Schannel) --ssl-reqd Require SSL/TLS --ssl-revoke-best-effort Ignore missing/offline cert CRL dist points -2, --sslv2 Use SSLv2 -3, --sslv3 Use SSLv3 --stderr \u0026lt;file\u0026gt; Where to redirect stderr --styled-output Enable styled output for HTTP headers --suppress-connect-headers Suppress proxy CONNECT response headers --tcp-fastopen Use TCP Fast Open --tcp-nodelay Use the TCP_NODELAY option -t, --telnet-option \u0026lt;opt=val\u0026gt; Set telnet option --tftp-blksize \u0026lt;value\u0026gt; Set TFTP BLKSIZE option --tftp-no-options Do not send any TFTP options -z, --time-cond \u0026lt;time\u0026gt; Transfer based on a time condition --tls-max \u0026lt;VERSION\u0026gt; Set maximum allowed TLS version --tls13-ciphers \u0026lt;ciphersuite list\u0026gt; TLS 1.3 cipher suites to use --tlsauthtype \u0026lt;type\u0026gt; TLS authentication type --tlspassword \u0026lt;string\u0026gt; TLS password --tlsuser \u0026lt;name\u0026gt; TLS user name -1, --tlsv1 Use TLSv1.0 or greater --tlsv1.0 Use TLSv1.0 or greater --tlsv1.1 Use TLSv1.1 or greater --tlsv1.2 Use TLSv1.2 or greater --tlsv1.3 Use TLSv1.3 or greater --tr-encoding Request compressed transfer encoding --trace \u0026lt;file\u0026gt; Write a debug trace to FILE --trace-ascii \u0026lt;file\u0026gt; Like --trace, but without hex output --trace-time Add time stamps to trace/verbose output --unix-socket \u0026lt;path\u0026gt; Connect through this Unix domain socket -T, --upload-file \u0026lt;file\u0026gt; Transfer local FILE to destination --url \u0026lt;url\u0026gt; URL to work with -B, --use-ascii Use ASCII/text transfer -u, --user \u0026lt;user:password\u0026gt; Server user and password -A, --user-agent \u0026lt;name\u0026gt; Send User-Agent \u0026lt;name\u0026gt; to server -v, --verbose Make the operation more talkative -V, --version Show version number and quit -w, --write-out \u0026lt;format\u0026gt; Use output FORMAT after completion --xattr Store metadata in extended file attributes 参数详解 参考：\nhttps://blog.csdn.net/angle_chen123/article/details/120675472\n","date":"2023-08-16T00:00:00Z","permalink":"https://msdemt.github.io/p/curl-introduction/","title":"curl 命令介绍"},{"content":"介绍 希望修改 ubuntu 18.04 上的用户名，比如现在的用户名是 abc，家目录是 /home/abc，想将该用户名修改为 def，家目录修改为 /home/def 。\n最简单的方式当然是新建一个名为 def 的用户，将 abc 用户删掉，但是因为在 abc 目录下配置了很多东西，所以希望能修改用户名。\n修改密码 注意：修改用户名前，必须先修改下密码\n在终端中，执行 sudo su 切换为 root 用户（注意，必须转为 root 用户）。 执行 sudo passwd abc （abc 是当前的用户名） 输入新密码，确认密码 修改密码成功，重启，输入新密码进入系统 修改用户名 打开终端，输入 sudo su 转为 root 用户 （注意，必须转为 root 用户）。 vi /etc/passwd ，修改用户名 abc 为新的用户名 def （注意：只修改用户名！后面的全名、目录等不要动！）。 vi /etc/shadow , 修改用户名 abc 为新的用户名 def 。 vi /etc/group , 用户名 abc 可能在很多的组中，将所有包含 abc 的组中的 abc 修改为 def 。 修改完成，保存，重启。 重启后，会发现 Ubuntu 登陆界面的用户名还是原来的用户名，但是终端里的用户名已经修改。此时，再选择 Ubuntu 屏幕右上角的电源图标下的账号设置，在弹出的对话框中再次修改用户名，然后就完全成功了。\n修改家目录名 上述修改完成后，家目录还是旧的名称 /home/abc\nvi /etc/passwd , 找到新用户名，修改该用户的家目录为新的家目录，比如 /home/def 将旧家目录名修改为新家目录名 sudo mv /home/abc home/def 重启 参考：\nhttps://www.cnblogs.com/yxqxx/p/12319130.html\n","date":"2023-08-15T00:00:00Z","permalink":"https://msdemt.github.io/p/ubuntu-change-username/","title":"ubuntu18.04修改用户名"},{"content":"介绍 项目中，需要将数据库由 H2 迁移到 mariadb-5.5.60，迁移过程中遇到的问题汇总如下\n表名大小写敏感问题 在 linux 系统中，mysql/mariadb 对表名的大小写是敏感的，因为在 SQL 语句中，使用大写的表名，在 H2 中正常，但是迁移到 mariadb 后，提示找不到表。\n解决：将 SQL 语句中的表名改为小写\nDATE_FORMAT() 函数问题 在 H2 的 SQL 语句中，使用了 FORMATDATETIME(create_time, 'yyyy-MM-dd HH:') 对日期进行格式化处理，转为 mariadb 后，mariadb 不支持 FORMATDATETIME() 函数，所以使用了 DATE_FORMAT() 函数代替，但是，执行 sql 后发现查不到期望的数据。\n测试： 在 H2 控制台执行\n1 select FORMATDATETIME(\u0026#39;2023-08-09 11:06:57\u0026#39;, \u0026#39;yyyy-MM-dd HH:\u0026#39;) 可以得到 2023-08-09 11:\n在 mariadb 控制台执行\n1 select DATE_FORMAT(\u0026#39;2023-08-09 11:06:57\u0026#39;, \u0026#39;yyyy-MM-dd HH:\u0026#39;); 得到 yyyy-MM-dd HH:\n参考：\nhttps://www.w3school.com.cn/sql/func_date_format.asp\nDATE_FORMAT() 函数的格式化参数和 FORMATDATETIME() 函数不同，将 SQL 修改为 DATE_FORMAT(create_time, '%Y-%m-%d %H:') 后，可以查到正确的数据。\n在 mariadb 控制台执行\n1 select DATE_FORMAT(\u0026#39;2023-08-09 11:06:57\u0026#39;, \u0026#39;%Y-%m-%d %H:\u0026#39;); 得到正确的结果：2023-08-09 11:\n","date":"2023-08-11T00:00:00Z","permalink":"https://msdemt.github.io/p/h2-to-mysql/","title":"H2 迁移到 MySQL 问题"},{"content":"介绍 在 MySQL 中，数据库对应数据目录中的目录，数据库中的每个表至少对应数据库目录中的一个文件（也可能是多个，取决于存储引擎）。因此，所使用操作系统的大小写敏感性决定了数据库名和表名的大小写敏感性。\n在大多数 Unix 中数据库名和表名对大小写敏感，而在 Windows 中对大小写不敏感。一个显著的例外情况是 Mac OS X ，它基于 Unix 但使用默认文件系统类型（HFS+），对大小写不敏感。然而，Mac OS X 也支持 UFS 卷，该卷对大小写敏感，就像 Unix 一样。\nlower_case_file_system 参数（只读） 表示当前系统文件是否大小写敏感，只读参数，无法修改。\nON: 大小写不敏感 OFF: 大小写敏感 lower_case_table_names 参数 Unix 下 lower_case_table_names 默认值为 0 ；Windows 下默认值是 1 ；Mac OS X 下默认值是 2 。\n0: 使用 CREATE TABLE 或 CREATE DATABASE 语句指定的大小写字母在硬盘上保存表名和数据库名。名称比较对大小写敏感。在大小写不敏感的操作系统如 Windows 或 Mac OS x 上我们不能将该参数设为 0 ，如果在大小写不敏感的文件系统上将 --lowercase-table-names 强制设为 0 ，并且使用不同的大小写访问 MyISAM 表名，可能会导致索引破坏。 1: 表名在硬盘上以小写保存，名称比较对大小写不敏感。 MySQL 将所有表名转换为小写在存储和查找表上。该行为也适合数据库名和表的别名。该值为 Windows 的默认值。 2: 表名和数据库名在硬盘上使用 CREATE TABLE 或 CREATE DATABASE 语句指定的大小写字母进行保存，但 MySQL 将它们转换为小写在查找表上。名称比较对大小写不敏感，即按照大小写来保存，按照小写来比较。注释：只在对大小写不敏感的文件系统上适用! innodb 表名用小写保存。 由大小写敏感转换为不敏感方法 如果原来所建立库及表都是对大小写敏感的，想要转换为对大小写不敏感，主要需要进行如下3步：\n将数据库数据通过 mysqldump 导出。 在 my.cnf （ CentOS 下配置文件是 /etc/my.cnf ）中更改最后添加 lower_case_tables_name = 1，然后重启 mysql 数据库 将导出的数据导入 mysql 数据库。 注：MySQL 8.0 开始，禁止在重新启动 MySQL 服务时将 lower_case_table_names 设置 成不同于初始化 MySQL 服务时设置的 lower_case_table_names 值。该值只能在初始化 MySQL 之前设置。\n命名规则 为了避免大小写引发的问题，一种推荐的命名规则是：在定义数据库、表、列的时候全部采用小写字母加下划线的方式，不使用任何大写字母。\n在任何系统中可以使用 lower_case_table_names=1 。使用该选项的不利之处是当使用 SHOW TABLES 或 SHOW DATABASES 时，看不出名字原来是用大写还是小写。\n请注意在 Unix 中如果以前 lower_case_table_names = 0，在将 lower_case_table_names 设置为 1 时，重启 mysqld 之前，必须先将旧的数据库名和表名转换为小写。\n字段名大小写不敏感 数据库字段名，大小写不敏感\n字段值大小写敏感设置，字符集和排序规则 字段值的大小写由 mysql 的校对规则来控制。提到校对规则，就不得不说字符集。字符集是一套符号和编码，校对规则是在字符集内用于比较字符的一套规则。\n一般而言，校对规则以其相关的字符集名开始，通常包括一个语言名，并且以 _ci（大小写不敏感）、_cs（大小写敏感）或 _bin（二元）结束 。比如 utf8 字符集，utf8_general_ci 表示不区分大小写，这个是 utf8 字符集默认的校对规则； utf8_general_cs 表示区分大小写，utf8_bin 表示二进制比较，同样也区分大小写 。\n参考：\nhttps://blog.csdn.net/lishuoboy/article/details/84562007\nhttps://zhuanlan.zhihu.com/p/147720463\n","date":"2023-08-11T00:00:00Z","permalink":"https://msdemt.github.io/p/mysql-case-sensitive/","title":"MySQL 大小写敏感配置"},{"content":"工作中使用到了 mariadb 5.5.60 版本，使用 docker 部署下。\n参考：\nhttps://hub.docker.com/_/mariadb\ndocker-compose 如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 hekai@thinkpad-l14:~/doc/docker-mariadb$ cat docker-compose.yml # Use root/example as user/password credentials version: \u0026#39;3.1\u0026#39; services: db: image: mariadb:5.5.60 restart: always environment: MYSQL_ROOT_PASSWORD: root MYSQL_ROOT_HOST: \u0026#34;%\u0026#34; TZ: Asia/Shanghai ports: - 3306:3306 volumes: - ./data:/var/lib/mysql - ./conf:/etc/mysql/conf.d adminer: image: adminer restart: always environment: TZ: Asia/Shanghai ports: - 18080:8080 docker-compose 参数\nrestart: always : 重启 docker 后，配置该参数的docker容器在docker重启时自动启动 TZ: Asia/Shanghai: environment 参数，指定中国时区，默认是格林尼治时间（GMT） mariadb 环境变量\nMYSQL_ROOT_PASSWORD: 指定 mariadb root 用户密码 MYSQL_ROOT_HOST: 指定 root 用户可访问的来源， % 表示所有来源的 root 用户都可以访问 docker-compose 中使用到了 adminer 开源数据库管理工具，访问方式为：http://127.0.0.1:18080\n","date":"2023-08-10T00:00:00Z","permalink":"https://msdemt.github.io/p/docker-mariadb-5.5.60/","title":"docker 部署 mariadb-5.5.60"},{"content":"介绍 在 ubuntu 上使用 git clone 下载时，每次都需要输入密码，而且，现在 github 要求使用 personal access token，无法直接输入密码了。\n解决办法\n1 git config --global credential.helper store 使用 store 模式存储凭证，凭证用明文的形式存放在磁盘中，并且永不过期，存储位置： ~/.git-credentials 中。\n参考：\nhttps://git-scm.com/book/zh/v2/Git-%E5%B7%A5%E5%85%B7-%E5%87%AD%E8%AF%81%E5%AD%98%E5%82%A8\n凭证存储 如果你使用的是 SSH 方式连接远端，并且设置了一个没有口令的密钥，这样就可以在不输入用户名和密码的情况下安全地传输数据。 然而，这对 HTTP 协议来说是不可能的 \u0026mdash; 每一个连接都是需要用户名和密码的。 这在使用双重认证的情况下会更麻烦，因为你需要输入一个随机生成并且毫无规律的 token 作为密码。\n幸运的是，Git 拥有一个凭证系统来处理这个事情。 下面有一些 Git 的选项：\n默认所有都不缓存。 每一次连接都会询问你的用户名和密码。\n“cache” 模式会将凭证存放在内存中一段时间。 密码永远不会被存储在磁盘中，并且在15分钟后从内存中清除。\n“store” 模式会将凭证用明文的形式存放在磁盘中，并且永不过期。 这意味着除非你修改了你在 Git 服务器上的密码，否则你永远不需要再次输入你的凭证信息。 这种方式的缺点是你的密码是用明文的方式存放在你的 home 目录下。\n如果你使用的是 Mac，Git 还有一种 “osxkeychain” 模式，它会将凭证缓存到你系统用户的钥匙串中。 这种方式将凭证存放在磁盘中，并且永不过期，但是是被加密的，这种加密方式与存放 HTTPS 凭证以及 Safari 的自动填写是相同的。\n如果你使用的是 Windows，你可以安装一个叫做 “Git Credential Manager for Windows” 的辅助工具。 这和上面说的 “osxkeychain” 十分类似，但是是使用 Windows Credential Store 来控制敏感信息。 可以在 https://github.com/Microsoft/Git-Credential-Manager-for-Windows 下载。\n你可以设置 Git 的配置来选择上述的一种方式\n1 $ git config --global credential.helper cache 部分辅助工具有一些选项。 “store” 模式可以接受一个 --file \u0026lt;path\u0026gt; 参数，可以自定义存放密码的文件路径（默认是 ~/.git-credentials ）。 “cache” 模式有 --timeout \u0026lt;seconds\u0026gt; 参数，可以设置后台进程的存活时间（默认是 “900”，也就是 15 分钟）。 下面是一个配置 “store” 模式自定义路径的例子：\n1 $ git config --global credential.helper \u0026#39;store --file ~/.my-credentials\u0026#39; Git 甚至允许你配置多个辅助工具。 当查找特定服务器的凭证时，Git 会按顺序查询，并且在找到第一个回答时停止查询。 当保存凭证时，Git 会将用户名和密码发送给 所有 配置列表中的辅助工具，它们会按自己的方式处理用户名和密码。 如果你在闪存上有一个凭证文件，但又希望在该闪存被拔出的情况下使用内存缓存来保存用户名密码，.gitconfig 配置文件如下：\n1 2 3 [credential] helper = store --file /mnt/thumbdrive/.git-credentials helper = cache --timeout 30000 ","date":"2023-08-10T00:00:00Z","permalink":"https://msdemt.github.io/p/git-credential/","title":"git凭证存储"},{"content":"在 wsl 上 git clone 失败，错误如下\n1 2 3 hekai@thinkpad-l14:~$ git clone https://github.com/msdemt/docker-centos7-slurm-cluster.git Cloning into \u0026#39;docker-centos7-slurm-cluster\u0026#39;... fatal: unable to access \u0026#39;https://github.com/msdemt/docker-centos7-slurm-cluster.git/\u0026#39;: GnuTLS recv error (-110): The TLS connection was non-properly terminated. 参考：\nhttps://zhuanlan.zhihu.com/p/624555732\n重新安装下 git\n1 2 3 sudo add-apt-repository ppa:git-core/ppa sudo apt update sudo apt install git 之后可以 git clone 成功了，但是过一段时间，又 git clone 出现了相同的问题\n最终解决：配置 git 代理\n1 git config --global http.proxy socks5://127.0.0.1:7890 git clone 失败，原因 linux 子系统无法使用 127.0.0.1 访问 windows 系统上的服务\n参考：\nhttps://learn.microsoft.com/zh-cn/windows/wsl/networking\n在 linux 子系统 ubuntu 中执行\n1 cat /etc/resolv.conf 1 2 3 4 5 hekai@thinkpad-l14:~$ cat /etc/resolv.conf # This file was automatically generated by WSL. To stop automatic generation of this file, add the following entry to /etc/wsl.conf: # [network] # generateResolvConf = false nameserver 172.22.192.1 复制 nameserver 后面的地址\n在 linux 子系统中使用该地址访问 windows 上的服务，所以 git 代理改为如下内容\n1 git config --global http.proxy socks5://172.22.192.1:7890 git clone 成功。\n","date":"2023-08-10T00:00:00Z","permalink":"https://msdemt.github.io/p/wsl-ubuntu-git-fail/","title":"wsl ubuntu git clone 失败"},{"content":"Set up the repository Update the apt package index and install packages to allow apt to use a repository over HTTPS:\n1 2 sudo apt-get update sudo apt-get install ca-certificates curl gnupg Add Docker’s official GPG key:\n1 2 3 sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg Use the following command to set up the repository:\n1 2 3 4 echo \\ \u0026#34;deb [arch=\u0026#34;$(dpkg --print-architecture)\u0026#34; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ \u0026#34;$(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;)\u0026#34; stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null Update the apt package index:\n1 sudo apt-get update Install Docker Engine Install Docker Engine, containerd, and Docker Compose.\nTo install the latest version, run:\n1 sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin Verify that the Docker Engine installation is successful by running the hello-world image.\n1 sudo docker run hello-world 安装 docker compose To download and install the Compose CLI plugin, run:\n1 2 3 DOCKER_CONFIG=${DOCKER_CONFIG:-$HOME/.docker} mkdir -p $DOCKER_CONFIG/cli-plugins curl -SL https://github.com/docker/compose/releases/download/v2.20.2/docker-compose-linux-x86_64 -o $DOCKER_CONFIG/cli-plugins/docker-compose Apply executable permissions to the binary:\n1 chmod +x $DOCKER_CONFIG/cli-plugins/docker-compose Test the installation.\n1 docker compose version 以非 Root 用户身份执行 Docker 默认情况下，只有 root 或者 有 sudo 权限的用户可以执行 Docker 命令。\n想要以非 root 用户执行 Docker 命令，你需要将你的用户添加到 Docker 用户组，该用户组在 Docker CE 软件包安装过程中被创建。想要这么做，输入：\n1 sudo usermod -aG docker $USER $USER是一个环境变量，代表当前用户名。\n登出，并且重新登录，以便用户组信息刷新。\ndocker 开机启动 目前，在 wsl ubuntu 上安装docker后，已经支持 docker 开机启动了。\nwsl ubuntu 也支持使用 systemctl 命令了。\n开机启动\n1 systemctl enable docker 禁止开机启动\n1 systemctl disable docker 卸载 docker 在卸载 Docker 之前，移除所有的容器，镜像，卷和网络。\n运行下面的命令停止所有正在运行的容器，并且移除所有的 docker 对象：\n1 2 docker container stop $(docker container ls -aq) docker system prune -a --volumes 现在可以使用apt像卸载其他软件包一样来卸载 Docker：\n1 2 sudo apt purge docker-ce sudo apt autoremove 修改docker数据存储路径 wsl ubuntu 默认安装在 c 盘，希望将 docker 的数据存储路径（默认为 /var/lib/docker ）修改到 d 盘。\n添加 /etc/docker/daemon.json 文件，内容如下\n1 2 3 4 5 6 { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://registry.docker-cn.com\u0026#34;], \u0026#34;data-root\u0026#34;: \u0026#34;/mnt/d/data/docker\u0026#34;, \u0026#34;log-driver\u0026#34;:\u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: {\u0026#34;max-size\u0026#34;:\u0026#34;100m\u0026#34;} } docker 启动失败。wls ubuntu docker可能不支持将文件存储到 windows 磁盘。\n将 /var/lib/docker 拷贝到 d 盘，报错，应该是 windows 磁盘不支持这些特殊文件。\n1 2 3 4 5 hekai@thinkpad-l14:~$ sudo mv /var/lib/docker /mnt/d/data/docker mv: cannot create special file \u0026#39;/mnt/d/data/docker/volumes/backingFsBlockDev\u0026#39;: Operation not supported mv: cannot create special file \u0026#39;/mnt/d/data/docker/volumes/docker-centos7-slurm-cluster_mysql/_data/mysql.sock\u0026#39;: Operation not supported mv: cannot create special file \u0026#39;/mnt/d/data/docker/overlay2/3a272b47e6ae28aa475f3eea705bdb2bdeb83dc97c6feb91cc20e6c49bbc004b-init/work/work/#23d\u0026#39;: Operation not supported mv: cannot create special file \u0026#39;/mnt/d/data/docker/overlay2/2a012b89cc6a205c6c8a148abae32a5e735695b52a54e2e3e792c2a5e88a00af-init/work/work/#23f\u0026#39;: Operation not supported wsl ubuntu docker 暂不更改存储位置了。\n参考：\nhttps://docs.docker.com/engine/install/ubuntu/\nhttps://docs.docker.com/compose/install/linux/#install-the-plugin-manually\nhttps://zhuanlan.zhihu.com/p/143156163\nhttps://blog.csdn.net/m0_58684193/article/details/127554527\n","date":"2023-08-10T00:00:00Z","permalink":"https://msdemt.github.io/p/wsl-ubuntu-docker/","title":"wsl ubuntu 安装 docker"},{"content":"介绍 wsl 全称 The Windows Subsystem for Linux ，即适用于 Linux 的 Windows 子系统，可以让开发者在 windows 系统上按原样运行 GNU/Linux 环境 - 包括大多数命令行工具、实用工具和应用程序 - 且不会产生传统虚拟机或双启动设置开销。\nWSL 2 是适用于 Linux 的 Windows 子系统体系结构的一个新版本，它支持适用于 Linux 的 Windows 子系统在 Windows 上运行 ELF64 Linux 二进制文件。 它的主要目标是提高文件系统性能，以及添加完全的系统调用兼容性。\n安装 系统： windows 11\n在管理员模式下打开 PowerShell 或 Windows 命令提示符，方法是右键单击并选择“以管理员身份运行”，输入 wsl --install 命令，然后重启计算机。\n1 wsl --install 此命令将启用运行 WSL 并安装 Linux 的 Ubuntu 发行版所需的功能。\n更改默认安装的 Linux 发行版 默认情况下，安装的 Linux 分发版为 Ubuntu。 可以使用 -d 标志进行更改。\n若要更改安装的发行版，请输入：wsl --install -d \u0026lt;Distribution Name\u0026gt;。 将 \u0026lt;Distribution Name\u0026gt; 替换为要安装的发行版的名称。\n若要查看可通过在线商店下载的可用 Linux 发行版列表，请输入：wsl --list --online 或 wsl -l -o。\n若要在初始安装后安装其他 Linux 发行版，还可使用命令：wsl --install -d \u0026lt;Distribution Name\u0026gt;。\n检查正在运行的 WSL 版本 可列出已安装的 Linux 发行版，并通过在 PowerShell 或 Windows 命令提示符中输入以下命令来检查每个发行版的 WSL 版本：wsl -l -v。\n要在安装新的 Linux 发行版时将默认版本设置为 WSL 1 或 WSL 2，请使用命令 wsl --set-default-version \u0026lt;Version#\u0026gt;，将 \u0026lt;Version#\u0026gt; 替换为 1 或 2。\n要设置与 wsl 命令一起使用的默认 Linux 发行版，请输入 wsl -s \u0026lt;DistributionName\u0026gt; 或 wsl --setdefault \u0026lt;DistributionName\u0026gt;，将 \u0026lt;DistributionName\u0026gt; 替换为要使用的 Linux 发行版的名称。 例如，从 PowerShell/CMD 输入 wsl -s Debian，将默认发行版设置为 Debian。 现在从 Powershell 运行 wsl npm init 将在 Debian 中运行 npm init 命令。\n要在 PowerShell 或 Windows 命令提示符下运行特定的 WSL 发行版而不更改默认发行版，请使用命令 wsl -d \u0026lt;DistributionName\u0026gt;，将 \u0026lt;DistributionName\u0026gt; 替换为要使用的发行版的名称。\n参考：\nhttps://learn.microsoft.com/zh-cn/windows/wsl\n","date":"2023-08-10T00:00:00Z","permalink":"https://msdemt.github.io/p/wsl-install/","title":"wsl 安装"},{"content":"介绍 在使用云主机时，某个用户登录后，可以执行如下命令直接切换到 root 用户\n1 $ sudo su - root sudo 命令需要输入当前用户的密码，su 命令需要输入 root 用户的密码。另外一个区别是其默认行为，sudo 命令只允许使用提升的权限运行单个命令，而 su 命令会启动一个新的 shell，同时允许使用 root 权限运行尽可能多的命令，直到明确退出登录。\nsudo 命令 sudo 命令，全称为 super user do，允许非root用户执行root用户才可以执行的命令。\n要想使一个用户具有使用sudo的能力，需要让root用户将其名字、可以执行的特定命令、按照哪种用户或用户组的身份执行等信息注册到/etc/sudoers文件中，即完成对该用户的授权（此时该用户称为“sudoer”）才可以。\n当一般用户执行特殊权限时，在命令前加上 sudo，此时系统会让你输入密码以确认终端机前操作的是你本人，确认后系统会将该命令的进程以超级用户的权限运行。\n在一定的时间段内，再次执行sudo的命令时不再询问密码，超出此时间段（一般为5分钟）后需要再次输入密码。\n可以配置用户执行sudo时不需输入密码\nsudo配置无密码后，用户就可以使用 sudo su - root 直接免密切换到root 用户了\n无密码 sudo 配置 centos7 配置用户无密码 sudo 修改/etc/sudoers文件，从而让普通用户username支持无密码sudo\n方式一：\nsudo 相关的配置位于 /etc/sudoers 文件内，这个文件不建议直接编辑，而是使用以下命令\n1 sudo visudo 该命令会打开默认的编辑器编辑 /etc/sudoers 文件，并在保存时自动检查文件格式并设置到正确的文件权限。\n进入编辑状态后，在文件的最后面 添加以下内容\n1 username ALL=(ALL) NOPASSWD:ALL username 改成自己的用户名\nNOPASSWD 表示不需要输入密码\nALL 表示所有命令\n也就是，用户在执行所有的 sudo 命令时军不需要输入密码，如果要设置指定命令无需输入密码，只需要把后面的 ALL 替换为具体命令\n方式二：\n手动修改 /etc/sudoers 方式如下\n1 2 3 4 5 6 7 8 $ chmod u+w /etc/sudoers $ vim /etc/sudoers $ diff /etc/sudoers /etc/sudoers.bak 108c108 \u0026lt; username ALL=(ALL) NOPASSWD:ALL --- \u0026gt; $ chmod u-w /etc/sudoers 注意：username ALL=(ALL) NOPASSWD:ALL 需要添加到 # %wheel ALL=(ALL) NOPASSWD: ALL 下面（即文件最后面），否则sudo还是会需要密码的。\n然后，username用户就可以无需密码执行sudo命令了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 [root@centos7-desktop ~]# ll /etc/sudoers -r--r-----. 1 root root 4328 9月 30 2020 /etc/sudoers [root@centos7-desktop ~]# chmod u+w /etc/sudoers [root@centos7-desktop ~]# ll /etc/sudoers -rw-r-----. 1 root root 4328 9月 30 2020 /etc/sudoers [root@centos7-desktop ~]# vim /etc/sudoers [root@centos7-desktop ~]# diff /etc/sudoers /etc/sudoers.bak 108c108 \u0026lt; username ALL=(ALL) NOPASSWD:ALL --- \u0026gt; [root@centos7-desktop ~]# chmod u-w /etc/sudoers [root@centos7-desktop ~]# ll /etc/sudoers -r--r-----. 1 root root 4364 12月 20 15:17 /etc/sudoers [root@centos7-desktop ~]# cat /etc/sudoers ## Next comes the main part: which users can run what software on ## which machines (the sudoers file can be shared between multiple ## systems). ## Syntax: ## ## user MACHINE=COMMANDS ## ## The COMMANDS section may have other options added to it. ## ## Allow root to run any commands anywhere root ALL=(ALL) ALL ## Allows members of the \u0026#39;sys\u0026#39; group to run networking, software, ## service management apps and more. # %sys ALL = NETWORKING, SOFTWARE, SERVICES, STORAGE, DELEGATING, PROCESSES, LOCATE, DRIVERS ## Allows people in group wheel to run all commands %wheel ALL=(ALL) ALL ## Same thing without a password # %wheel ALL=(ALL) NOPASSWD: ALL username ALL=(ALL) NOPASSWD:ALL 配置用户有密码 sudo 若允许用户执行sudo命令（默认sudo命令需要输入用户密码），需将用户添加到 wheel 组，使用如下命令\n1 $ usermod -a -G username wheel 也可以使用\n1 $ gpasswd -a username wheel 此时，username用户执行 sudo ，还需要输入密码。加入wheel用户组，只是允许普通用户能够 sudo -s 切换到 root\n使用如下命令，将用户 username 从 wheel 组删除\n1 $ gpasswd -d username wheel 执行 usermod 或 gpasswd 命令，不会改变 /etc/sudoers 文件内容\n操作记录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 将username添加到wheel组 [root@centos7-desktop etc]# usermod -a -G username wheel # 也可以使用 gpasswd -a username wheel # 使用username用户执行sudo，还是需要输入密码 [username@centos7-desktop ~]$ sudo vi /etc/hosts [sudo] username 的密码： [username@centos7-desktop ~]$ [root@centos7-desktop etc]# diff /etc/sudoers /etc/sudoers.bak [root@centos7-desktop etc]# id username uid=1000(username) gid=1000(username) 组=1000(username),10(wheel) 将username从wheel用户组删除 [root@centos7-desktop etc]# gpasswd -d username wheel 正在将用户“username”从“wheel”组中删除 [root@centos7-desktop etc]# id username uid=1000(username) gid=1000(username) 组=1000(username) [root@centos7-desktop etc]# su 命令 su 是切换用户的命令，后面不加用户，默认切换到root，切换后不改变当前环境变量 su - 是切换用户的同时将环境变量修改为目标用户的环境变量\n使用su切换用户时，需要输入目标用户的密码\n参考：\nhttps://blog.csdn.net/chl183/article/details/108305842\nhttps://zhuanlan.zhihu.com/p/137332644\nhttps://zhuanlan.zhihu.com/p/252345791\n","date":"2023-08-09T00:00:00Z","permalink":"https://msdemt.github.io/p/sudo-su-root/","title":"sudo su - root 介绍"},{"content":"介绍 我们在 linux 上安装软件时,经常会使用如下命令\n1 2 3 ./configure make make install 这些命令是怎么工作的呢？\n这些命令有什么作用？ linux 上使用源码编译安装软件通常有如下三步\n配置软件（Configure the software） configure 脚本负责完成在指定系统上构建软件的准备工作，它确保后续的构建和安装过程中所有需要的依赖可以使用，并且找出使用这些依赖所需的任何信息。\nUnix/Linux 程序经常使用 C 语言编写，所以我们经常需要 C 编译器来构建这些程序。在这个场景下, configure 脚本会确保你的系统中确实存在一个 C 编译器，并且找到这个 C 编译器的名字和位置。\n构建软件（Build the software） 一旦 configure 命令执行完成，我们可以调用 make 命令来构建软件。这个步骤会执行定义在 Makefile 文件中的一系列任务来将软件从源码构建为最终可执行程序。\n你下载的软件源码 tar 包通常不包含最终的 Makefile 文件，而是包含名为 Makefile.in 的模板文件。然后利用 configure 脚本针对当前的系统利用 Makefile.in 文件生成的定制化的 Makefile 文件。\n安装软件（Install the software） 现在软件已经构建完成，可以运行了，相关文件可以被拷贝到它们的最终目录。 make install 命令会将构建出的可执行文件和它的依赖库、文档拷贝到正确的位置。\n这通常意味着软件的二进制文件会被拷贝到你的 PATH 路径下，软件的操作手册会被拷贝到你的 MANPATH 路径下，同时软件依赖的其他文件也会被安全地保存到相应的位置。\n因为安装步骤也是定义在 Makefile 文件中，所以软件的安装位置可以通过某个参数传递给 configure 脚本，或者由 configure 脚本利用某个系统变量来实现指定安装位置。\n根据软件的安装位置，您可能需要升级此步骤的权限，以便可以将文件复制到系统目录。 使用 sudo 通常可以达到目的。\n这些脚本是怎么产生的？ 上述步骤之所以能成功工作，是因为 configure 脚本会检查你的系统，并使用它找到的信息将 Makefile.in 模板转换为 Makefile 文件，但是 configure 脚本和 Makefile.in 模板是怎么产生的呢？\n如果你曾经打开过 configure 脚本，或者相关的 Makefile.in 文件，你会发现这些文件里包含几千行的脚本语句。有时候这些支持配置的脚本语句比要安装的程序的源代码还要长。\n即使利用已有的 configure 脚本文件开始编写，手动编写完成一个 configure 脚本也是非常艰巨的。不过不用担心：这些脚本不是手工构建的。\n以这种方式构建的软件通常使用一个叫做 autotools 的工具集进行打包。这个工具集包含 autoconf、automake 等工具，所有的这些工具使得维护软件生命周期变得很容易。最终用户不需要了解这些工具，同时让软件在不同的 Unix/Linux 系统的安装步骤变得简单。\nHello World 案例 我们以一个简单的 Hello World C 语言程序为例，来看看如何使用 autotools 工具集打包。\n下面是程序源代码，在一个名为 main.c 的文件中\n1 2 3 4 5 6 7 #include \u0026lt;stdio.h\u0026gt; int main(int argc, char* argv[]) { printf(\u0026#34;Hello World\\n\u0026#34;); return 0; } 创建 configure 脚本 不需要手动编写 configure 脚本，我们需要创建一个使用 m4sh 语言（m4 宏命令和 POSIX shell 脚本的组合）编写的 configure.ac 文件来描述 configure 脚本需要做的事情。\n我们需要第一个调用的 m4 宏为 AC_INIT，它会初始化 autoconf 并且设置一些关于打包软件的基本信息。我们的软件名为 helloworld，版本为 0.1，维护者为 george@thoughtbot.com：\n1 AC_INIT([helloworld], [0.1], [george@thoughtbot.com]) 这个项目中我们会使用 automake，所以我们需要使用 AM_INIT_AUTOMAKE 宏命令来初始化 automake\n1 AM_INIT_AUTOMAKE 下面，我们需要告诉 autoconf 让 configure 脚本需要寻找的相关依赖，在本例中， configure 脚本仅需要使用 C 编译器，我们可以使用 AC_PROG_CC 宏命令设置。\n1 AC_PROG_CC 如果有其他的依赖项，那我们可以使用其他的 m4 宏命令来设置，如使用 AC_PATH_PROG 宏表示在用户的 PATH 路径中搜索一个特定的程序。\n此时我们已经列出了使用的依赖，前面有提到，configure 脚本会根据用户系统的系统信息和 Makefile.in 模板文件生成 Makefile 文件。\n下面一行使用 AC_CONFIG_FILES 宏命令告诉 autoconf 工具 configure 脚本文件需要做这些工作：configure 脚本文件需要找到一个名为 Makefile.in 的文件，将文件内的站位符使用对应的值替换，例如将 @PACKAGE_VERSION@ 替换为 0.1，然后将结果写入到 Makefile 文件。\n1 AC_CONFIG_FILES([Makefile]) 最后，当我们告诉 autoconf 工具所有 configure 脚本需要做的工作后，可以调用 AC_OUTPUT 宏命令输出脚本内容\n1 AC_OUTPUT 下面是 configure.ac 中的所有代码，相比 4737 行的 configure 脚本文件，这些代码好多了。\n1 2 3 4 5 AC_INIT([helloworld], [0.1], [george@thoughtbot.com]) AM_INIT_AUTOMAKE AC_PROG_CC AC_CONFIG_FILES([Makefile]) AC_OUTPUT 还差一点我们就可以发布软件了，configure 脚本需要一个 Makefile.in 文件，将系统相关信息填充进去后，生成最终的 Makefile 文件。\n创建 Makefile 文件 与 configure 脚本文件相比，Makefile.in 模板文件非常长且复杂。因此，我们不是手工编写，而是编写一个较短的 Makefile.am 文件，然后利用automake 使用该文件为我们生成 Makefile.in 文件。\n首先，我们需要设置一些参数来告诉 automake 工具本项目的结构，因为这里的例子不是标准的 GNU 项目的结构，所以结构声明为 foreign 。\n1 AUTOMAKE_OPTIONS = foreign 接下来告诉 automake 我们希望 Makefile 编译的软件名为 helloworld:\n1 bin_PROGRAMS = helloworld 这行包含了很多打包信息，感谢 automake 的统一命名规则\nPROGRAMS 后缀成为 primary 主要信息，它告诉 automake 工具 helloworld 文件具有哪些属性。例如 PROGRAMS 需要被编译，相比 SCRIPTS 和 DATA 文件不需要被编译。\nbin 前缀告诉 automake 工具，这里列出的文件应该被安装到 bindir 变量指定的路径下。 autotools 工具还为我们定义了其他目录，包括 bindir , libdir , pkglibdir ，我们也可以自定义自己需要的目录。\n如果我们的程序有一部分是 Ruby 脚本，我们可以定义 rubydir 变量并且告诉 automake 安装我们的 ruby 文件到该路径。\n1 2 rubydir = $(datadir)/ruby ruby_DATA = my_script.rb my_other_script.rb 可以在安装目录之前添加其他前缀，以进一步区分 automake 的行为。\n因为我们已经定义了 RPOGRAM ，我们需要告诉 automake 在哪里可以找到它的源文件。 在这种情况下，前缀是这些源文件构建的程序的名称，而不是它们将安装的位置：\n1 helloworld_SOURCES = main.c 这是我们的 helloworld 程序的整个 Makefile.am 文件。 与 configure.ac 和 configure 脚本一样，它比它生成的 Makefile.in 要短得多：\n1 2 3 AUTOMAKE_OPTIONS = foreign bin_PROGRAMS = helloworld helloworld_SOURCES = main.c 把它们放在一起 现在我们已经编写了配置文件，我们可以运行 autotools 并生成完成的 configure 脚本和 Makefile.in 模板。\n首先，我们需要生成一个 m4 环境供 autotools 使用：\n1 aclocal 现在我们可以运行 autoconf 将 configure.ac转换为configure脚本，并运行automake将Makefile.am转换为Makefile.in`：\n1 2 autoconf automake --add-missing 分发程序 最终用户不需要查看我们的 autotools 工具的设置，因此我们可以分发 configure 脚本和 Makefile.in，而无需分发用于生成它们的所有文件。\n幸运的是，autotools 工具也将帮助我们进行分发。 Makefile 包含各种有趣的目标，包括构建项目 tarball 的目标，其中包含我们需要分发的所有文件：\n1 2 ./configure make dist 您甚至可以测试分发 tarball 是否可以在各种条件下安装：\n1 make distcheck 总览 现在我们知道编译安装命令从何而来以及它是如何运作的！\n在维护者的系统上：\n1 2 3 4 5 aclocal # Set up an m4 environment autoconf # Generate configure from configure.ac automake --add-missing # Generate Makefile.in from Makefile.am ./configure # Generate Makefile from Makefile.in make distcheck # Use Makefile to build and test a tarball to distribute 在最终用户的系统上：\n1 2 3 ./configure # Generate Makefile from Makefile.in make # Use Makefile to build the program make install # Use Makefile to install the program 参考：\nhttps://zhuanlan.zhihu.com/p/77813702\nhttps://thoughtbot.com/blog/the-magic-behind-configure-make-make-install\n","date":"2023-08-03T00:00:00Z","permalink":"https://msdemt.github.io/p/configure-make-makeinstall/","title":"configure、make、make install 如何工作?"},{"content":"介绍 本文在 centos7 系统上安装 nginx，nginx 有两种安装方式，yum 安装和源码编译安装。\nyum安装 yum 安装后会将 nginx 的文件放在系统的不同位置,可以使用 rpm -ql nginx 或 whereis nginx 查看安装路径\n卸载的话,使用yum remove nginx 命令来卸载\n安装 nginx\n1 $ sudo yum -y install nginx 卸载 nginx\n1 $ sudo yum remove nginx 使用 yum 安装 nginx 时, nginx 配置文件在 /etc/nginx 目录\n配置 nginx 服务\n1 2 3 4 5 6 7 8 9 10 # 设置开机启动 $ sudo systemctl enable nginx # 启动 nginx 服务 $ sudo service nginx start # 停止 nginx 服务 $ sudo service nginx stop # 重启 nginx 服务 $ sudo service nginx restart # 重新加载配置，一般是在修改过 nginx 配置文件时使用 $ sudo service nginx reload 此外,还有\n1 2 3 4 # 检查 nginx 配置是否正确 $ nginx -t # 重新加载配置 $ ngxin -s reload 源码编译安装 使用 rpm -qa | grep nginx 查询 nginx 安装包,然后使用 rpm -e nginx 卸载, 如果提示存在依赖无法卸载,可以使用 rpm -e --nodeps nginx 强制卸载\n安装依赖库 安装 gcc 环境\n1 2 # nginx编译时依赖 gcc 环境 $ sudo yum -y install gcc gcc-c++ 安装 pcre\n1 2 # 让 nginx 支持重写功能 $ sudo yum -y install pcre pcre-devel 安装 zlib\n1 2 # zlib 库提供了很多压缩和解压缩的方式，nginx 使用 zlib 对 http 包内容进行 gzip 压缩 $ sudo yum -y install zlib zlib-devel 安装 openssl\n1 2 # 安全套接字层密码库，用于通信加密 $ sudo yum -y install openssl openssl-devel 编译安装 下载 nginx 源码包\n1 $ sudo curl -O https://nginx.org/download/nginx-1.24.0.tar.gz 解压\n1 $ sudo tar -zxf nginx-1.24.0.tar.gz 进入解压后的目录,配置环境\n1 2 $ cd nginx-1.24.0 $ ./configure --prefix=/usr/local/nginx --prefix=/usr/local/nginx 指定 nginx 编译安装的目录,安装后会在此目录下生成 nginx 相关文件\n编译安装\n1 2 3 4 # 编译 $ make # 安装 $ make install 编译安装后的操作命令和 yum 安装的不同\n启动服务\n1 $ /usr/local/nginx/sbin/nginx 检查 nginx 配置\n1 $ /usr/local/nginx/sbin/nginx -t 重新加载服务\n1 $ /usr/local/nginx/sbin/nginx -s reload 停止服务\n1 $ /usr/local/nginx/sbin/nginx -s stop 查看 nginx 服务进程\n1 $ ps -ef|grep nginx 参考:\nhttps://juejin.cn/post/6844904134345228301\nhttps://blog.csdn.net/weixin_53187893/article/details/115090825\nhttps://segmentfault.com/a/1190000007116797\n","date":"2023-08-02T00:00:00Z","image":"https://msdemt.github.io/p/nginx-install/nginx-ar21.svg","permalink":"https://msdemt.github.io/p/nginx-install/","title":"centos7系统安装nginx"},{"content":"介绍 ssh 有三种方式可以跳转登录，分别是：ProxyJump、ProxyCommand、SSH Tunnel。\n在某些场景下，SSH无法直接访问服务器，需要通过其他服务器进行代理访问，比如外网服务器访问仅允许使用VPN或4A访问的内网服务器。在这种场景下，常用的方式是端口转发，使用端口转发建立连接，然后再做访问。如果面临更多服务器，就需要建立多个端口转发连接，比较麻烦。\nProxyJump 可以使用SSH提供的ProxyJump参数，进行代理服务跳转，简化登录流程，ProxyJump简写参数是 -J 。\n在 openssh7.3 以上的版本，开始支持 ProxyJump 。\nProxyJump可以在命令行执行，也可以写在配置文件（~/.ssh/config）中。\n命令行执行语法\n1 $ ssh -J user@proxyserver1,user@proxyserver2 user@targetserver 使用命令行时需要逐个输入代理服务器的密码。\n可以使用config配置文件和ssh密钥文件，简化登录流程，\n配置文件（~/.ssh/config）语法\n1 2 3 4 5 6 7 8 9 10 11 12 Host ProxyServer Hostname \u0026lt;jump_server ip\u0026gt; Port \u0026lt;jump_server port\u0026gt; User \u0026lt;jump_server user\u0026gt; IdentityFile \u0026lt;jump_server id_rsa\u0026gt; Host target HostName \u0026lt;target_server ip\u0026gt; Port \u0026lt;target_server port\u0026gt; User \u0026lt;target_server user\u0026gt; IdentityFile \u0026lt;target_server id_rsa\u0026gt; ProxyJump ProxyServer 配置之后，在终端执行 ssh target 即可ssh到目标服务器\nProxyCommand 若不支持ProxyJump，可以使用ProxyCommand\n-W host:port #将client过来的标准输入和输出forward到host和port指定的地方. 可以看到,这个选项直接就可以搭配上ProxyCommand的需求\nProxyCommand 命令行语法\n1 ssh username@target_server_ip -p 22 -o ProxyCommand=\u0026#39;ssh -p 22 username@jump_server_ip -W %h:%p\u0026#39; 同样可以在~/.ssh/config增加配置\n1 2 3 4 5 6 7 8 9 10 11 Host ProxyServer Hostname \u0026lt;jump_server ip\u0026gt; Port \u0026lt;jump_server port\u0026gt; User \u0026lt;jump_server user\u0026gt; IdentityFile \u0026lt;jump_server id_rsa\u0026gt; Host target HostName \u0026lt;target_server ip\u0026gt; Port \u0026lt;target_server port\u0026gt; User \u0026lt;target_server user\u0026gt; ProxyCommand ssh -p 22 -W %h:%p ProxyServer 参考：\nhttps://qusec.cn/posts/sssh/\nhttps://peirs.net/sshs-proxyjump-parameter/\nhttps://murphypei.github.io/blog/2021/12/ssh-proxyjump\nhttps://www.jianshu.com/p/199013854070\nhttps://zhuanlan.zhihu.com/p/74193910\nhttps://blog.csdn.net/wxqee/article/details/49234595\nhttps://www.jianshu.com/p/ad5aa9663d37\nhttps://juejin.cn/s/ssh%20config%20proxyjump%20windows\n","date":"2023-07-28T00:00:00Z","image":"https://msdemt.github.io/p/ssh-proxy/Linux-Symbole-2048x1158_hu6f8b26c03cc6e65572403f8d94a50599_544049_120x120_fill_box_smart1_3.png","permalink":"https://msdemt.github.io/p/ssh-proxy/","title":"SSH-ProxyJump跳转登录"},{"content":"介绍 在Linux系统上，常见的输入法有 IBus(Intelligent Input Bus)、XIM(X Input Method)、Fcitx(FlexibleInput Method Framework)。\nFcitx: 支持谷歌拼音、搜狗拼音、五笔 IBus: 支持只能拼音，五笔 XIM: 略（用的比较少） 安装 ubuntu18.04系统中，已自带IBus和XIM输入法框架\n本文在ubuntu18.04上安装fcitx输入法框架\n安装方法\n检查fcitx是否已安装 1 fcitx --version 安装fcitx框架 1 sudo apt install -y fcitx-bin 安装fcitx默认输入法，fcitx-table中包含了拼音输入法（fcitx-pinyin），可以安装fcitx-table-all，包含了五笔输入法。 1 sudo apt install -y fcitx-table 安装谷歌拼音输入法 1 sudo apt install -y fcitx-googlepinyin 配置fcitx ubuntu设置\u0026mdash;区域和语言\u0026mdash;管理已安装语言\u0026mdash;键盘输入法系统中选择fcitx 重启ubuntu系统\n安装记录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 test@00bafcjc-durwemo9n5:~$ fcitx --version Command \u0026#39;fcitx\u0026#39; not found, but can be installed with: sudo apt install fcitx-bin test@00bafcjc-durwemo9n5:~$ sudo apt install fcitx-bin ... ... test@00bafcjc-durwemo9n5:~$ sudo apt install -y fcitx-table 正在读取软件包列表... 完成 正在分析软件包的依赖关系树 正在读取状态信息... 完成 将会同时安装下列软件： fcitx-pinyin 建议安装： fcitx-table-all 下列【新】软件包将被安装： fcitx-pinyin fcitx-table 升级了 0 个软件包，新安装了 2 个软件包，要卸载 0 个软件包，有 0 个软件包未被升级。 test@00bafcjc-durwemo9n5:~$ sudo apt install -y fcitx-googlepinyin ... ... test@00bafcjc-durwemo9n5:~$ fcitx --version fcitx version: 4.2.9.6 问题 输入法图标问题 重启后，可以在ubuntu界面右上角看到fcitx的小键盘图标，如果之前配置使用过IBus输入法，此时右上角会有两个输入法图标。\n解决：ubuntu设置\u0026mdash;区域和语言\u0026mdash;输入源 中删除汉语，只保留英语(美国)，这样默认的输入法图标就消失了。\n参考：\nhttps://leimao.github.io/blog/Ubuntu-Gaming-Chinese-Input/\n中英文切换问题 fcitx使用中，无法shift切换中英文\n原因：点击右上角fcitx小键盘图标\u0026mdash;配置\u0026mdash;输入法 中只配置了 Google拼音 输入法。\nUbuntu下所谓的中英文切换就是一个输入法系统的中文输入法切换到其中的英文输入法，所以一定要保证输入法系统中既有中文输入法也要有英文输入法。 所以，添加 键盘-英语(美国) 输入法。 此外，在 全局配置\u0026mdash;快捷键 中，切换激活/非激活输入法 使用 Lshift ，额外的激活输入法快捷键 选择 左Shift\n参考：\nhttps://blog.csdn.net/yucicheung/article/details/79331529\nidea快捷键冲突问题 使用idea时，无法使用快捷键 Ctrl+Shift+F，原因该键被fcitx的简繁转换功能占用\n解决： 点击右上角fcitx小键盘图标\u0026mdash;配置\u0026mdash;附加组件，取消简繁转换\n参考：\nhttps://zhuanlan.zhihu.com/p/508797663\nhttps://zhuanlan.zhihu.com/p/529892064\nhttps://leimao.github.io/blog/Ubuntu-Gaming-Chinese-Input/\nhttps://blog.csdn.net/chen462488588/article/details/109290855\n","date":"2023-07-27T00:00:00Z","image":"https://msdemt.github.io/p/ubuntu-fcitx/ubuntu_logo_hu373a6c33440a9fb65cfc39e6a6372242_135517_120x120_fill_box_smart1_3.png","permalink":"https://msdemt.github.io/p/ubuntu-fcitx/","title":"ubuntu18.04安装fcitx输入法框架"},{"content":"介绍 工作中，生产环境的服务器是无法直接访问的，通常需要4A，访问比较麻烦，可以使用 ssh隧道 简化登录流程。\n如下图\nssh登录4A后，无法直接访问 server-2，可以通过 server-1 服务器代理访问。\n具体流程\nssh登录4A，新建隧道 使用4A的隧道作为代理，ssh访问server-1服务器,在server-1上新建隧道 使用server-1隧道代理访问server-2服务器 使用bitvise配置 安装bitvise ssh client，下载地址：https://www.bitvise.com/download-area\n新开一个bitvise页面，假设4A系统内网IP为192.168.15.45:10011，添加用户名、密码等登录信息，点击Save profile，将该配置保存。\n新开一个bitvise页面，填入server-1的IP、端口和登录信息，在 Proxy settings 中，选择第二步保存的4A配置文件，这样就可以使用4A作为代理访问server-1了。（第二步不需要登录了） 因为的目标服务器server-2还需要使用server-1代理才可以访问，所以还需要打开Services选项卡，勾选SOCKS/HTTP Proxy Forwarding，将本地空闲的端口如1079填入Listen Port；\n点击Login，登录到server-1服务器\n打开一个新的bitvise页面，填入目标服务器 server-2 的IP、端口和登录信息，Proxy Setting配置使用server-1服务器开放的1079代理端口。 为了能够访问 server-2 服务器上的网页服务，比如jenkins，还需要在Services标签页中开放代理，比如使用本地未使用的端口1080作为代理端口\n本地浏览器可以使用SwitchyOmega插件，将目标服务器上的jenkins等地址配置使用127.0.0.1:1080代理访问。 使用finalshell配置 bitvise仅支持windows系统，如果在linux（如：ubuntu）上访问目标服务器，可以使用finalshell\n建立4A SSH连接，配置隧道，类型：本地，监听端口：本地未占用的某个端口，如1078；绑定IP: 127.0.0.1，绑定本地IP；目标地址：使用该隧道访问的地址，此处为server-1服务器地址 10.246.100.5；目标端口：目标地址对应的端口，此处为 10000 建立server-1的SSH连接，主机和端口使用4A连接隧道中的绑定ip和监听端口，同时还需建立隧道，供访问server-2服务器代理。 建立目标服务器server-2的SSH连接，同理，主机和端口填入server-1隧道的绑定ip和监听端口，这样就能访问到目标服务器了（需要同时开启4A和server-1的ssh连接），为了访问目标服务器上的网页，还需要在该连接上新建socks5代理隧道 本地浏览器可以使用SwitchyOmega插件，将目标服务器上的jenkins等地址配置使用127.0.0.1:1080代理访问。 使用ProxyJump配置 在linux系统上，也可以使用ProxyJump实现访问server-2服务器，缺点：无法配置socks5代理实现访问目标服务器的网页服务。\n如果想在 Windows 上使用 ssh 的 proxyjump 功能，需要使用一个支持该功能的 ssh 客户端。推荐使用 OpenSSH 。\nWindows 安装 OpenSSH 参考：\nhttps://learn.microsoft.com/zh-cn/windows-server/administration/openssh/openssh_install_firstuse\n在 $HOME/.ssh/config 文件新增如下内容 1 2 3 4 5 6 7 8 9 10 11 12 13 Host 55.250.10.20 HostName 55.250.10.20 User test Port 10000 IdentityFile /opt/develop/ssh/id_rsa ProxyJump test@10.246.110.5:10000 Host 10.246.110.5 HostName 10.246.110.5 User test Port 10000 IdentityFile /opt/develop/ssh/id_rsa ProxyJump abc@192.168.15.45:10011 在终端输入 ssh 55.250.10.20，然后输入abc用户的密码，即可ssh连接到 server-2 服务器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 user@00bafcjc-durwemo9n5:~/.ssh$ ssh 55.250.10.20 abc@192.168.15.45\u0026#39;s password: The authenticity of host \u0026#39;[55.250.10.20]:10000 (\u0026lt;no hostip for proxy command\u0026gt;)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is SHA256:TJctlnqugvdS+y7uP9M6DPjoiFHjBBYS9FtwBKBmHFk. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;[55.250.10.20]:10000\u0026#39; (ECDSA) to the list of known hosts. Linux host-55 5.10.0-18-amd64 #1 SMP Debian 5.10.140-1 (2022-09-02) x86_64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Tue Jul 25 14:12:14 2023 from 10.63.143.23 secure@host-55:~$ ","date":"2023-07-19T00:00:00Z","image":"https://msdemt.github.io/p/ssh-tunnel/Linux-Symbole-2048x1158_hu6f8b26c03cc6e65572403f8d94a50599_544049_120x120_fill_box_smart1_3.png","permalink":"https://msdemt.github.io/p/ssh-tunnel/","title":"多级ssh访问内网服务器"},{"content":"问题 使用hugo-theme-stack主题时，将项目部署到github pages上后，发现categories图片无法显示\n解决 在静态网页项目根目录下新建名为 .nojekyll 的文件。\n或者在hugo项目中static目录下新建名为 .nojekyll 的文件。\n原因 Github Pages 默认是基于 Jekyll 构建，Jekyll 是一个将纯文本转换为静态网站的工具，它构建的网站下各种目录都是特定的以下划线开头命名的文件夹，例如 _layouts、_posts ，它会忽略掉其它的以下划线开头的文件夹和文件。\n.nojekyll 就是告诉 Github Pages 当前网站不是基于 Jekyll 构建的，不要忽略掉下划线开头的文件和文件夹。\n可见 .nojekyll 主要就是用于 Github Pages 这种有默认规则的网站部署平台，如果是部署在自己的服务器上，可以把它删掉。\n反之，如果你的网站不是 Jekyll 构建的，要部署到 Github Pages ，并且包含下划线开头的文件或文件夹，那么你就需要在根目录添加一个 .nojekyll 空文件。\n参考：\nhttps://github.com/CaiJimmy/hugo-theme-stack/issues/726\nhttps://www.cnblogs.com/babywhale/p/13560573.html\n","date":"2023-07-07T00:00:00Z","permalink":"https://msdemt.github.io/p/github-pages-image/","title":"github pages无法显示图片"},{"content":"git的4个区 工作区（Working Area） 相当于工作空间的目录，即代码的存放位置\n暂存区（Stage） 也称为 index ，用来跟踪已暂存文件，一般存在 .git 下的 index 文件，所以有时也称暂存区为索引。\n本地仓库（Local Repository）\n远程仓库（Remote Repository）\ngit文件的5种状态 未修改（Origin） 已修改（Modified） 已暂存（Staged） 已提交（Committed） 已推送（Pushed） 工作区中文件的初始状态是 未修改，当我们修改文件后，其状态变为 已修改，git diff 命令可以查看已修改但未暂存的文件。（git diff后输入 q 可以退出） 通过 git add 命令可以把已修改的文件添加到暂存区，git diff --cached 可以查看已暂存但未提交的文件。 通过 git commit 将代码提交到本地仓库，git diff [本地分支] [远程分支] 可以查看已提交本地，但未推送到远程分支的文件。 通过 git push 命令将本地分支推送到远程分支。 回退相关命令 git reset 命令 git reset 是进行回退的具体命令，参数介绍如下\n--soft: 仅仅将头指针恢复，已经 add 的暂存区及工作空间的文件修改不变。 --mixed: 将头指针恢复，已经 add 的暂存区也会恢复 ，工作空间的代码修改不变。 --hard: 头指针、暂存区和工作空间的修改都会恢复。 git log 命令 git log 命令查看git的提交记录，但无法查看已经删除的记录。\ngit reflog 命令 git reflog 命令可以查看所有分支的所有操作记录（包括commit和已被删除的commit记录）\n回退操作 回退操作命令\n将已修改或暂存但未提交的文件回退: git reset --hard 将已提交未推送的版本回退: git reset --hard origin/master 将已提交且推送的版本回退： 回退到某个版本：git reset --hard \u0026lt;版本号\u0026gt; 将回退的版本强制推送到远程仓库：git push -f --hard 可以替换为其他恢复等级，一般使用 --soft，这样修改的内容不会丢失\n版本号可以使用 git log 或 git reflog 查看，如 git reset --hard 811aesfi8\ngit reset --hard \u0026lt;版本号\u0026gt; 也可以替换为 git reset --hard HEAD\n回退到当前版本：git reset --hard HEAD 回退到上一个版本：git reset --hard HEAD^ 回退到上两个版本：git reset --hard HEAD^^ 回退到上三个版本：git reset --hard HEAD^^^ 回退到上十个版本：git reset --hard HEAD~10 git 远程覆盖本地 可以执行如下命令将远程仓库的代码直接覆盖本地仓库\ngit fetch \u0026ndash;all git reset \u0026ndash;hard origin/main git pull git fetch 是下载远程仓库的内容，不做任务的合并\ngit reset 把 HEAD 指向刚刚下载的最新版本\n参考：\nhttps://blog.csdn.net/qing040513/article/details/109150075 https://blog.csdn.net/gercke/article/details/119085963\n","date":"2023-07-07T00:00:00Z","image":"https://msdemt.github.io/p/git-rollback/1_Wjxx83j-qyiNvFBy1yOA1w_hufb4407888dbfcda01762496277a1213f_11862_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://msdemt.github.io/p/git-rollback/","title":"git回退版本"},{"content":"添加代理 1 2 3 4 5 6 7 //http || https git config --global http.proxy http://127.0.0.1:7890 git config --global https.proxy https://127.0.0.1:7890 //sock5代理 git config --global http.proxy socks5://127.0.0.1:7891 git config --global http.proxy socks5://127.0.0.1:7891 只针对github配置代理\n1 2 3 4 5 6 7 8 #使用socks5代理（推荐） git config --global http.https://github.com.proxy socks5://127.0.0.1:7890 #使用http代理（不推荐） git config --global http.https://github.com.proxy http://127.0.0.1:7890 #取消socks5代理 git config --global --unset http.https://github.com.proxy #取消http代理 git config --global --unset http.https://github.com.proxy 查看代理 1 2 git config --global --get http.proxy git config --global --get https.proxy 取消代理 1 2 git config --global --unset http.proxy git config --global --unset https.proxy clash for windows 代理 clash for windows 的 http 和 socks5 代理使用的是同一个端口。\n参考：\nhttps://blog.csdn.net/weimeibuqieryu/article/details/106793645 https://github.com/Fndroid/clash_for_windows_pkg/issues/1244\n","date":"2023-07-07T00:00:00Z","image":"https://msdemt.github.io/p/git-proxy/1_Wjxx83j-qyiNvFBy1yOA1w_hufb4407888dbfcda01762496277a1213f_11862_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://msdemt.github.io/p/git-proxy/","title":"git设置代理"},{"content":"添加子模块 1 git submodule add \u0026lt;url\u0026gt; \u0026lt;path\u0026gt; url为子模块git路径 path为子模块存储的目录路径\n如，将 hugo-theme-stack 项目作为子模块添加到本地项目的 themes 目录\n1 git submodule add https://github.com/CaiJimmy/hugo-theme-stack.git themes 子模块添加成功后，执行 git status 命令可以看到 .gitmodules 文件已被修改，并新增了一个子模块\n执行 git diff --cached 命令可以查看修改内容\n执行 git commit 命令可以将子模块添加到本地仓库\n添加子模块时使用 -b 参数指定分支\n1 git submodule add -b main [URL to Git repo]; 若子模块已添加，可以在 .gitmodules 中设置分支，其中 public 是主模块中安装子模块的名称， stable 是对应要设置的分支名称。\n1 git config -f .gitmodules submodule.public.branch stable 执行后，会在 .gitmodules 中的子模块添加分支（branch = main），如下\n1 2 3 4 [submodule \u0026#34;public\u0026#34;] path = public url = https://github.com/msdemt/msdemt.github.io.git branch = main 使用子模块 直接克隆包含子模块的项目时，子模块目录下没有任何文件，需要在项目的根目录下执行如下命令，完成子模块的下载\n1 2 git submodule init git submodule update 或者\n1 git submodule update --init 克隆项目的同时下载子模块\n1 git clone \u0026lt;url\u0026gt; --recursive 更新子模块 子模块的维护者更新子模块后，使用子模块的项目必须手动更新子模块才可以使用最新的子模块。\n在项目中，进入子模块目录下，执行 git pull 更新，执行 git log 可以查看子模块的更新内容。\n之后进入项目根目录，使用 git add 和 git commit 命令将子模块更新到项目中，然后使用 git push 命令将更新子模块的项目推送到远程仓库。\n如果自己要修改子模块内容，需要先在子模块根路径下执行 git checkout \u0026lt;分支名\u0026gt; ，然后才可以对该子模块进行修改和提交，否则git push提交时出现Everything up-to-date。\n将子模块修改提交后，如果希望将项目依赖的子模块更新到最新版本，需要在项目根路径下执行 git submodule update --remote，然后将项目提交到远程仓库。\n删除子模块 使用 git submodule deinit \u0026lt;子模块名称\u0026gt; 和 git rm \u0026lt;子模块名称\u0026gt; 命令卸载一个子模块。\n如果添加 \u0026ndash;force 参数，则子模块工作区内即使有本地的修改，也会被移除。\n例如，删除名为 test-submodule 子模块\n1 2 git submodule deinit test-submodule git rm test-submodule 如果完全删除子模块，还需要删除项目根路径下的 .gitmodules 文件和 .git/modules 目录下的子模块文件\n问题 子模块更新分支 添加子模块\n1 git submodule add https://github.com/msdemt/msdemt.github.io.git public 子模块更新后，在父模块中更新子模块到最新版本\n1 git submodule update --remote 更新失败，错误如下\n1 2 fatal: Needed a single revision 无法在子模组路径 \u0026#39;public\u0026#39; 中找到当前版本 origin/maste 发现父模块依赖的子模块分支为master，正确应该是main分支（子模块项目初始分支是master，后来我新增了main作为默认分支，删掉了master分支）\n参考：https://blog.csdn.net/weboof/article/details/108517187\n更新子模块的分支\n1 git config -f .gitmodules submodule.public.branch main 再执行更新子模块\n1 git submodule update --remote 参考：\nhttps://blog.csdn.net/guotianqing/article/details/82391665 https://blog.csdn.net/Lee_queenie/article/details/127386151\n","date":"2023-07-07T00:00:00Z","image":"https://msdemt.github.io/p/git-submodule/1_Wjxx83j-qyiNvFBy1yOA1w_hufb4407888dbfcda01762496277a1213f_11862_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://msdemt.github.io/p/git-submodule/","title":"git子模块操作"},{"content":"介绍 在 ubuntu 上使用 vscode 时，默认的字体（ Droid Sans Mono）很不好看。 Windows 上的 vscode 默认字体是微软的 Consolas ，比 Droid Sans Mono 好看很多，而且 JetBrains 出了免费字体 JetBrains Mono，也十分好看。\n本文将 JetBrains Mono 安装到 u`buntu 中，并且配置 vscode 使用该字体。\n安装字体 JetBrains Mono 字体下载地址： https://www.jetbrains.com/lp/mono/\n下载后，解压\n1 sudo unzip JetBrainsMono-2.242.zip -d /usr/share/fonts/JetBrains-Mono 字体目录的权限需要为 755\n1 sudo chmod -R 755 /usr/share/fonts/JetBrains-Mono 字体文件权限需要为644\n1 sudo chmod -R 644 /usr/share/fonts/JetBrains-Mono/* 更新系统字体缓存\n1 sudo fc-cache -fv 检查\n1 fc-list | grep JetBrains vscode添加字体 设置 - 文本编辑器 - 字体 - Font Family\n将Jetbrains Mono字体添加到行首，如下\n1 \u0026#39;Jetbrains Mono\u0026#39;, \u0026#39;Droid Sans Mono\u0026#39;, \u0026#39;monospace\u0026#39;, monospace 或直接在 settings.json 中添加\n1 \u0026#34;editor.fontFamily\u0026#34;: \u0026#34;\u0026#39;Jetbrains Mono\u0026#39;, \u0026#39;Droid Sans Mono\u0026#39;, \u0026#39;monospace\u0026#39;, monospace\u0026#34;, 重启 vscode ，就可以使用 Jetbrains Mono 字体了。\n对应 settings.json 中会设置如下\n1 2 3 \u0026#34;editor.fontLigatures\u0026#34;: true, // 是否启用字体连字 \u0026#34;editor.fontSize\u0026#34;: 18, // 设置字体大小 \u0026#34;editor.fontFamily\u0026#34;: \u0026#34;\u0026#39;Jetbrains Mono\u0026#39;,\u0026#39;Droid Sans Mono\u0026#39;, \u0026#39;monospace\u0026#39;, monospace\u0026#34;, vscode调整桌面字体大小\n1 \u0026#34;window.zoomLevel\u0026#34;: 1, 字体位置 ubuntu 字体位置\n用户字体文件：~/.local/share/fonts 系统字体文件：/usr/share/fonts 字体配置文件：/etc/fonts ","date":"2023-07-07T00:00:00Z","image":"https://msdemt.github.io/p/ubuntu-vscode-font/ubuntu_logo_hu373a6c33440a9fb65cfc39e6a6372242_135517_120x120_fill_box_smart1_3.png","permalink":"https://msdemt.github.io/p/ubuntu-vscode-font/","title":"ubuntu 配置 vscode 字体"},{"content":"题 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。\n你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。\n你可以按任意顺序返回答案。\n示例 1：\n输入：nums = [2,7,11,15], target = 9 输出：[0,1] 解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。\n解 暴力枚举法 1 2 3 4 5 6 7 8 9 10 11 public static int[] twoSum(int[] nums, int target) { int n = nums.length; for(int i=0; i\u0026lt;n; ++i){ for(int j=i+1; j\u0026lt;n; ++j){ if(nums[i] + nums[j] == target){ return new int[]{i, j}; } } } return new int[0]; } 复杂度分析\n时间复杂度：O(N^2)，其中 N 是数组中的元素数量。最坏情况下数组中任意两个数都要被匹配一次。 空间复杂度：O(1) 哈希表 1 2 3 4 5 6 7 8 9 10 public static int[] twoSum1(int[] nums, int target) { Map\u0026lt;Integer, Integer\u0026gt; hashtable = new HashMap\u0026lt;Integer, Integer\u0026gt;(); for(int i=0; i\u0026lt;nums.length; ++i){ if(hashtable.containsKey(target - nums[i])){ return new int[]{hashtable.get(target - nums[i]), i}; } hashtable.put(nums[i], i); } return new int[0]; } 复杂度分析：\n时间复杂度：O(N), 其中 N 是数组中的元素数量。对于每一个元素 x，我们可以 O(1) 地寻找 target - x。 空间复杂度：O(N)，其中 N 是数组中的元素数量。主要为哈希表的开销。 作者：LeetCode-Solution 链接：https://leetcode.cn/problems/two-sum/solution/liang-shu-zhi-he-by-leetcode-solution/ 来源：力扣（LeetCode） 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n","date":"2023-07-07T00:00:00Z","image":"https://msdemt.github.io/p/two_sum/1603980178-c305fb1df5f5fb7_hu61eb5bf94bba91376f0df83c72584e6c_90324_120x120_fill_box_smart1_3.png","permalink":"https://msdemt.github.io/p/two_sum/","title":"两数之和"},{"content":"ubuntu 安装后，默认没有root用户密码，所以，无法使用su命令切换到root用户\n配置ubuntu root用户密码\n1 sudo passwd 配置后，就可以使用su命令切换到root用户了\n","date":"2022-11-23T00:00:00Z","image":"https://msdemt.github.io/p/ubuntu-root-pwd/ubuntu_logo_hu373a6c33440a9fb65cfc39e6a6372242_135517_120x120_fill_box_smart1_3.png","permalink":"https://msdemt.github.io/p/ubuntu-root-pwd/","title":"ubuntu配置root密码"}]